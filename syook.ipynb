{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBbfL8q7H9rw",
        "outputId": "8191032e-ad58-47e2-9551-1df26b3d5396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.82-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.5-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.82-py3-none-any.whl (871 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m871.1/871.1 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.5-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.2.82 ultralytics-thop-2.0.5\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "# pip install torch torchvision torchaudio\n",
        "!pip install ultralytics\n",
        "!pip install opencv-python-headless\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvcfdoC2ocSU",
        "outputId": "fb74a612-0c33-41b0-9195-6475434e96fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX_EGySHSFUI",
        "outputId": "7d862c03-9940-4b86-a705-c01ee0e76887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.4.0+cu121\n",
            "Ultralytics YOLO version: 1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Ultralytics YOLO version:\", YOLO._version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvNjlriN8rKa",
        "outputId": "cef6cbd3-3c74-4e89-cf3b-caa661c4ac64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "0: 448x640 1 person, 7.5ms\n",
            "Speed: 1.6ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 10.8ms\n",
            "Speed: 1.1ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x448 1 person, 6.4ms\n",
            "Speed: 1.4ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 8.0ms\n",
            "Speed: 1.6ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 448x640 2 persons, 6.7ms\n",
            "Speed: 1.6ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x480 2 glovess, 2 vests, 1 ear-protector, 6.3ms\n",
            "Speed: 1.3ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x320 1 gloves, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 448x640 4 persons, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 mask, 6.6ms\n",
            "Speed: 1.4ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x320 (no detections), 6.2ms\n",
            "Speed: 1.0ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 001618.jpg\n",
            "\n",
            "0: 640x480 1 gloves, 2 masks, 9.1ms\n",
            "Speed: 1.4ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x512 1 gloves, 2 masks, 3 vests, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 448x640 5 persons, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x352 (no detections), 6.3ms\n",
            "Speed: 1.2ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 001486.jpg\n",
            "\n",
            "0: 640x416 (no detections), 6.1ms\n",
            "Speed: 1.3ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "No PPE detected in cropped image of 001486.jpg\n",
            "\n",
            "0: 640x448 1 gloves, 1 vest, 6.4ms\n",
            "Speed: 1.3ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x256 1 gloves, 1 vest, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x448 (no detections), 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "No PPE detected in cropped image of 001486.jpg\n",
            "\n",
            "0: 448x640 2 persons, 7.3ms\n",
            "Speed: 2.2ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x640 1 gloves, 1 mask, 2 vests, 1 ppe-suit, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 1 mask, 2 vests, 1 ppe-suit, 10.3ms\n",
            "Speed: 1.6ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 448x640 5 persons, 9.5ms\n",
            "Speed: 2.6ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 1 mask, 1 ear-protector, 11.1ms\n",
            "Speed: 1.3ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 1 gloves, 1 mask, 2 vests, 1 ear-protector, 11.0ms\n",
            "Speed: 1.6ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x384 1 gloves, 1 mask, 1 vest, 1 ear-protector, 11.4ms\n",
            "Speed: 1.7ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x416 1 mask, 1 ear-protector, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 11.3ms\n",
            "Speed: 1.5ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 480x640 2 persons, 8.9ms\n",
            "Speed: 2.7ms preprocess, 8.9ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 mask, 1 vest, 1 ear-protector, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x544 1 gloves, 1 mask, 9.3ms\n",
            "Speed: 3.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 448x640 1 person, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 544x640 1 gloves, 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 448x640 2 persons, 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x608 1 gloves, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x544 1 gloves, 9.7ms\n",
            "Speed: 2.6ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 512x640 2 persons, 11.7ms\n",
            "Speed: 2.8ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 1 mask, 10.8ms\n",
            "Speed: 1.6ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x288 1 gloves, 1 mask, 9.3ms\n",
            "Speed: 1.6ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 448x640 3 persons, 9.2ms\n",
            "Speed: 2.6ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 544x640 1 gloves, 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 640x320 2 glovess, 1 ear-protector, 9.8ms\n",
            "Speed: 1.7ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 544x640 1 gloves, 1 mask, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 448x640 2 persons, 8.4ms\n",
            "Speed: 2.6ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 2 vests, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x416 1 gloves, 1 mask, 1 ear-protector, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 480x640 8 persons, 11.6ms\n",
            "Speed: 2.8ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x192 1 gloves, 1 mask, 9.2ms\n",
            "Speed: 1.1ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x352 1 mask, 2 vests, 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x288 1 gloves, 1 mask, 9.3ms\n",
            "Speed: 1.5ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 gloves, 2 masks, 1 vest, 9.4ms\n",
            "Speed: 1.5ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 gloves, 1 mask, 8.4ms\n",
            "Speed: 1.4ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 2 masks, 1 vest, 8.7ms\n",
            "Speed: 1.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 gloves, 1 mask, 1 vest, 9.0ms\n",
            "Speed: 1.3ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 (no detections), 8.8ms\n",
            "Speed: 1.1ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001183.jpg\n",
            "\n",
            "0: 448x640 3 persons, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 8.9ms\n",
            "Speed: 1.2ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 gloves, 1 ear-protector, 13.3ms\n",
            "Speed: 1.2ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 gloves, 8.8ms\n",
            "Speed: 1.1ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x576 (no detections), 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "No PPE detected in cropped image of 001807.jpg\n",
            "\n",
            "0: 640x640 1 gloves, 1 mask, 4 vests, 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 1 vest, 1 ear-protector, 8.4ms\n",
            "Speed: 1.6ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 448x640 2 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 vest, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x448 (no detections), 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "No PPE detected in cropped image of 005164.jpg\n",
            "\n",
            "0: 416x640 1 person, 14.5ms\n",
            "Speed: 2.7ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x480 1 gloves, 1 ppe-suit, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 384x640 2 persons, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 8.5ms\n",
            "Speed: 1.2ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x448 1 gloves, 1 ear-protector, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 384x640 7 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x480 1 gloves, 1 ppe-suit, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x288 1 gloves, 8.8ms\n",
            "Speed: 1.5ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 8.9ms\n",
            "Speed: 1.3ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 gloves, 8.9ms\n",
            "Speed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x512 1 gloves, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x352 1 gloves, 8.3ms\n",
            "Speed: 1.6ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x384 (no detections), 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 005159.jpg\n",
            "\n",
            "0: 480x640 2 persons, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x256 1 mask, 9.2ms\n",
            "Speed: 1.5ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x448 1 gloves, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x448 1 person, 11.4ms\n",
            "Speed: 2.8ms preprocess, 11.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x352 1 gloves, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 448x640 3 persons, 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 mask, 2 ppe-suits, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x512 1 ppe-suit, 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 10.1ms\n",
            "Speed: 1.2ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 448x640 1 person, 8.6ms\n",
            "Speed: 2.6ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x640 1 gloves, 2 masks, 1 vest, 1 ear-protector, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 10.5ms\n",
            "Speed: 2.4ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 13.8ms\n",
            "Speed: 1.6ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 448x640 2 persons, 9.3ms\n",
            "Speed: 2.5ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 1 ear-protector, 13.1ms\n",
            "Speed: 1.5ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x384 1 gloves, 1 mask, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 448x640 3 persons, 8.4ms\n",
            "Speed: 2.6ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 3 masks, 2 vests, 8.7ms\n",
            "Speed: 1.5ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x256 1 gloves, 2 masks, 1 vest, 9.0ms\n",
            "Speed: 1.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 8.2ms\n",
            "Speed: 1.2ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x448 1 person, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x288 (no detections), 8.1ms\n",
            "Speed: 1.5ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001250.jpg\n",
            "\n",
            "0: 640x480 1 person, 10.4ms\n",
            "Speed: 4.0ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x416 1 gloves, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 480x640 2 persons, 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x640 (no detections), 8.8ms\n",
            "Speed: 2.6ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No PPE detected in cropped image of 001911.jpg\n",
            "\n",
            "0: 640x224 1 gloves, 8.6ms\n",
            "Speed: 1.1ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 384x640 10 persons, 8.8ms\n",
            "Speed: 7.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 1 vest, 1 ppe-suit, 8.9ms\n",
            "Speed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 1 mask, 3 vests, 1 ppe-suit, 8.4ms\n",
            "Speed: 1.2ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 gloves, 2 masks, 3 vests, 1 ppe-suit, 9.1ms\n",
            "Speed: 1.3ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x288 1 gloves, 1 mask, 2 vests, 1 ppe-suit, 8.3ms\n",
            "Speed: 1.4ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 1 mask, 2 vests, 1 ppe-suit, 8.3ms\n",
            "Speed: 1.1ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 gloves, 1 vest, 1 ppe-suit, 9.3ms\n",
            "Speed: 1.2ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 gloves, 1 mask, 3 vests, 1 ppe-suit, 8.6ms\n",
            "Speed: 1.1ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 1 gloves, 1 mask, 1 vest, 1 ppe-suit, 8.2ms\n",
            "Speed: 0.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x192 1 gloves, 1 mask, 1 vest, 1 ppe-suit, 8.5ms\n",
            "Speed: 1.0ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 1 gloves, 1 mask, 2 vests, 8.1ms\n",
            "Speed: 0.9ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 448x640 1 person, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 576x640 1 gloves, 1 mask, 9.0ms\n",
            "Speed: 2.6ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 416x640 2 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x192 1 gloves, 1 mask, 2 vests, 1 ear-protector, 8.5ms\n",
            "Speed: 1.0ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x384 1 gloves, 1 mask, 1 ear-protector, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 480x640 1 person, 8.5ms\n",
            "Speed: 2.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 1 mask, 1 vest, 8.4ms\n",
            "Speed: 1.4ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 448x640 4 persons, 8.5ms\n",
            "Speed: 2.5ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x448 1 gloves, 2 masks, 1 ear-protector, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x480 1 gloves, 2 masks, 12.6ms\n",
            "Speed: 3.2ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x544 1 gloves, 2 masks, 1 ppe-suit, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x480 1 gloves, 1 mask, 1 ear-protector, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 448x640 2 persons, 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 1 vest, 8.7ms\n",
            "Speed: 1.6ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x384 1 gloves, 8.6ms\n",
            "Speed: 3.4ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 448x640 1 person, 7.8ms\n",
            "Speed: 2.5ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 8.1ms\n",
            "Speed: 1.7ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 448x640 4 persons, 7.3ms\n",
            "Speed: 2.4ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 480x640 1 gloves, 7.8ms\n",
            "Speed: 2.0ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 1 vest, 7.9ms\n",
            "Speed: 1.3ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 gloves, 1 vest, 9.0ms\n",
            "Speed: 1.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 608x640 (no detections), 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 608, 640)\n",
            "No PPE detected in cropped image of 005280.jpg\n",
            "\n",
            "0: 480x640 1 person, 7.9ms\n",
            "Speed: 2.7ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x608 1 gloves, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 480x640 4 persons, 7.7ms\n",
            "Speed: 2.6ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x320 1 ppe-suit, 8.2ms\n",
            "Speed: 1.5ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x480 1 gloves, 2 vests, 1 ppe-suit, 7.7ms\n",
            "Speed: 2.1ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x576 1 gloves, 1 glasses, 1 vest, 1 ppe-suit, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x544 1 gloves, 1 vest, 1 ppe-suit, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x448 4 persons, 8.1ms\n",
            "Speed: 2.7ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x256 1 gloves, 1 ear-protector, 7.9ms\n",
            "Speed: 1.4ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x384 1 gloves, 1 vest, 1 ear-protector, 7.8ms\n",
            "Speed: 1.7ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x352 1 gloves, 2 vests, 7.7ms\n",
            "Speed: 1.6ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x256 1 gloves, 1 ear-protector, 7.7ms\n",
            "Speed: 1.2ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 448x640 4 persons, 8.1ms\n",
            "Speed: 2.5ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 8.0ms\n",
            "Speed: 1.4ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x512 1 gloves, 1 vest, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x128 (no detections), 7.8ms\n",
            "Speed: 0.9ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 001713.jpg\n",
            "\n",
            "0: 640x192 (no detections), 9.1ms\n",
            "Speed: 1.1ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001713.jpg\n",
            "\n",
            "0: 480x640 5 persons, 12.0ms\n",
            "Speed: 2.7ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 2 masks, 2 vests, 1 ear-protector, 10.9ms\n",
            "Speed: 1.3ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x192 1 gloves, 1 ear-protector, 11.3ms\n",
            "Speed: 1.1ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 2 glovess, 2 masks, 2 vests, 9.8ms\n",
            "Speed: 1.1ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 2 masks, 9.9ms\n",
            "Speed: 1.5ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x160 1 gloves, 1 vest, 13.2ms\n",
            "Speed: 1.1ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 512x640 2 persons, 14.3ms\n",
            "Speed: 2.8ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 2 vests, 1 ppe-suit, 11.5ms\n",
            "Speed: 1.4ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x160 1 gloves, 2 vests, 1 ppe-suit, 8.6ms\n",
            "Speed: 1.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 416x640 2 persons, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x544 1 gloves, 1 mask, 1 vest, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x288 (no detections), 16.3ms\n",
            "Speed: 1.3ms preprocess, 16.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001184.jpg\n",
            "\n",
            "0: 448x640 2 persons, 11.1ms\n",
            "Speed: 2.5ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 vest, 1 ppe-suit, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x416 1 gloves, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 448x640 2 persons, 11.8ms\n",
            "Speed: 3.0ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 mask, 11.0ms\n",
            "Speed: 1.7ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x224 1 ear-protector, 8.7ms\n",
            "Speed: 1.1ms preprocess, 8.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 448x640 5 persons, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 2 vests, 1 ear-protector, 8.0ms\n",
            "Speed: 1.7ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x352 2 glovess, 1 vest, 1 ear-protector, 9.9ms\n",
            "Speed: 1.6ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x288 1 gloves, 1 vest, 2 ear-protectors, 10.9ms\n",
            "Speed: 1.3ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x384 2 glovess, 1 vest, 2 ear-protectors, 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x96 (no detections), 9.9ms\n",
            "Speed: 0.7ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 001221.jpg\n",
            "\n",
            "0: 448x640 1 person, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 mask, 1 ear-protector, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 448x640 3 persons, 10.3ms\n",
            "Speed: 2.6ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 1 glasses, 11.3ms\n",
            "Speed: 1.5ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x416 1 gloves, 1 mask, 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x320 1 gloves, 1 ppe-suit, 11.4ms\n",
            "Speed: 1.5ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 448x640 1 person, 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x544 1 gloves, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 448x640 2 persons, 11.7ms\n",
            "Speed: 2.7ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x576 1 gloves, 1 mask, 14.6ms\n",
            "Speed: 2.9ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x352 (no detections), 10.1ms\n",
            "Speed: 1.7ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 005262.jpg\n",
            "\n",
            "0: 448x640 4 persons, 9.4ms\n",
            "Speed: 2.3ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 10.3ms\n",
            "Speed: 1.1ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 gloves, 1 vest, 10.0ms\n",
            "Speed: 1.2ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x352 (no detections), 11.0ms\n",
            "Speed: 1.5ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 001561.jpg\n",
            "\n",
            "0: 640x416 1 gloves, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 448x640 3 persons, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x224 1 ppe-suit, 9.6ms\n",
            "Speed: 1.2ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 1 ppe-suit, 8.7ms\n",
            "Speed: 1.2ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 448x640 5 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 2 vests, 9.5ms\n",
            "Speed: 1.5ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x352 1 gloves, 3 vests, 9.6ms\n",
            "Speed: 1.5ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x192 1 gloves, 1 vest, 9.2ms\n",
            "Speed: 1.0ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x288 1 gloves, 1 vest, 9.2ms\n",
            "Speed: 1.3ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 gloves, 2 vests, 8.5ms\n",
            "Speed: 1.2ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 448x640 1 person, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x320 2 masks, 9.3ms\n",
            "Speed: 1.5ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 448x640 1 person, 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 448x640 3 persons, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 glasses, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x608 (no detections), 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 608)\n",
            "No PPE detected in cropped image of 001188.jpg\n",
            "\n",
            "0: 480x640 (no detections), 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No PPE detected in cropped image of 001188.jpg\n",
            "\n",
            "0: 448x640 1 person, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 2 vests, 10.9ms\n",
            "Speed: 1.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 448x640 4 persons, 11.6ms\n",
            "Speed: 2.5ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x608 2 glovess, 2 masks, 3 ppe-suits, 11.0ms\n",
            "Speed: 3.5ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x320 1 gloves, 1 mask, 1 ppe-suit, 11.5ms\n",
            "Speed: 1.6ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 13.5ms\n",
            "Speed: 1.4ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 2 ppe-suits, 1 ear-protector, 11.5ms\n",
            "Speed: 1.5ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 448x640 5 persons, 13.0ms\n",
            "Speed: 3.1ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 (no detections), 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 001814.jpg\n",
            "\n",
            "0: 640x352 1 gloves, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x352 1 gloves, 12.6ms\n",
            "Speed: 1.6ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x224 1 gloves, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 1 gloves, 14.4ms\n",
            "Speed: 1.1ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 448x640 2 persons, 13.1ms\n",
            "Speed: 2.5ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 2 vests, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x416 1 gloves, 1 mask, 2 vests, 13.9ms\n",
            "Speed: 2.4ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 448x640 4 persons, 12.7ms\n",
            "Speed: 3.1ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x384 1 gloves, 1 ppe-suit, 13.1ms\n",
            "Speed: 1.7ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x352 1 gloves, 12.7ms\n",
            "Speed: 2.1ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x608 1 gloves, 14.1ms\n",
            "Speed: 2.8ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 480x640 2 persons, 14.7ms\n",
            "Speed: 3.4ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 1 ear-protector, 12.0ms\n",
            "Speed: 1.5ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x320 1 gloves, 15.5ms\n",
            "Speed: 1.7ms preprocess, 15.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 448x640 1 person, 14.5ms\n",
            "Speed: 3.0ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x640 1 gloves, 2 masks, 1 ppe-suit, 11.9ms\n",
            "Speed: 4.3ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 13.1ms\n",
            "Speed: 2.9ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 2 glovess, 1 mask, 14.1ms\n",
            "Speed: 1.6ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x416 2 glovess, 9.8ms\n",
            "Speed: 2.5ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x288 1 gloves, 14.0ms\n",
            "Speed: 1.4ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 448x640 1 person, 12.6ms\n",
            "Speed: 2.8ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x640 1 gloves, 2 masks, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 544x640 6 persons, 13.4ms\n",
            "Speed: 4.2ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 640x416 2 glovess, 14.1ms\n",
            "Speed: 1.9ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x320 1 gloves, 14.0ms\n",
            "Speed: 1.8ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x256 (no detections), 14.4ms\n",
            "Speed: 1.7ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001426.jpg\n",
            "\n",
            "0: 640x192 2 vests, 10.1ms\n",
            "Speed: 1.3ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x352 1 gloves, 1 vest, 1 ear-protector, 13.5ms\n",
            "Speed: 1.9ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x192 1 gloves, 1 vest, 1 ear-protector, 13.8ms\n",
            "Speed: 1.3ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 480x640 3 persons, 10.8ms\n",
            "Speed: 2.9ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x256 (no detections), 14.0ms\n",
            "Speed: 1.6ms preprocess, 14.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001546.jpg\n",
            "\n",
            "0: 640x416 1 gloves, 13.2ms\n",
            "Speed: 2.6ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 448x640 5 persons, 14.2ms\n",
            "Speed: 2.7ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 1 mask, 1 ear-protector, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x224 1 gloves, 16.3ms\n",
            "Speed: 1.4ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x480 1 gloves, 1 mask, 1 ear-protector, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x224 1 mask, 12.1ms\n",
            "Speed: 1.5ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 (no detections), 13.6ms\n",
            "Speed: 1.6ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001358.jpg\n",
            "\n",
            "0: 448x640 5 persons, 10.8ms\n",
            "Speed: 3.4ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 2 vests, 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x288 1 gloves, 2 masks, 2 vests, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 2 masks, 2 vests, 1 ear-protector, 14.4ms\n",
            "Speed: 1.5ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x352 1 mask, 2 vests, 12.6ms\n",
            "Speed: 1.7ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x288 1 gloves, 1 mask, 13.6ms\n",
            "Speed: 1.7ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 448x640 2 persons, 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x448 1 gloves, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x576 2 glovess, 1 ppe-suit, 10.3ms\n",
            "Speed: 2.7ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 448x640 7 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x192 1 gloves, 2 vests, 9.2ms\n",
            "Speed: 1.1ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 2 glovess, 2 vests, 10.5ms\n",
            "Speed: 1.0ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 gloves, 2 vests, 13.3ms\n",
            "Speed: 1.2ms preprocess, 13.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 gloves, 2 vests, 11.2ms\n",
            "Speed: 1.2ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 gloves, 11.6ms\n",
            "Speed: 1.1ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 1 vest, 12.1ms\n",
            "Speed: 1.0ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x96 (no detections), 12.1ms\n",
            "Speed: 0.8ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 005216.jpg\n",
            "\n",
            "0: 512x640 1 person, 8.6ms\n",
            "Speed: 2.8ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 2 masks, 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x480 6 persons, 7.9ms\n",
            "Speed: 1.2ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x288 2 glovess, 3 vests, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 gloves, 3 vests, 5.9ms\n",
            "Speed: 1.0ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 6.4ms\n",
            "Speed: 0.8ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x128 1 vest, 6.3ms\n",
            "Speed: 0.6ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x96 1 gloves, 6.3ms\n",
            "Speed: 0.5ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 96)\n",
            "\n",
            "0: 640x192 (no detections), 6.3ms\n",
            "Speed: 1.0ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001865.jpg\n",
            "\n",
            "0: 448x640 4 persons, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 1 mask, 1 vest, 8.5ms\n",
            "Speed: 0.8ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 6.0ms\n",
            "Speed: 0.8ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x608 1 gloves, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x256 1 gloves, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 480x640 6 persons, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 5.9ms\n",
            "Speed: 0.9ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 gloves, 10.6ms\n",
            "Speed: 1.2ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 6.6ms\n",
            "Speed: 1.0ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 gloves, 7.0ms\n",
            "Speed: 1.0ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 gloves, 6.7ms\n",
            "Speed: 0.9ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 5.9ms\n",
            "Speed: 0.9ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 384x640 4 persons, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 mask, 1 vest, 7.2ms\n",
            "Speed: 1.2ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x224 1 gloves, 7.5ms\n",
            "Speed: 1.0ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x608 1 gloves, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 288x640 1 gloves, 6.5ms\n",
            "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
            "\n",
            "0: 448x640 2 persons, 12.2ms\n",
            "Speed: 2.8ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 3 masks, 1 ear-protector, 6.9ms\n",
            "Speed: 1.3ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x480 2 glovess, 3 masks, 1 ear-protector, 6.7ms\n",
            "Speed: 1.4ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 448x640 3 persons, 6.5ms\n",
            "Speed: 1.7ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x128 (no detections), 6.8ms\n",
            "Speed: 0.6ms preprocess, 6.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 001147.jpg\n",
            "\n",
            "0: 640x192 1 gloves, 6.4ms\n",
            "Speed: 0.7ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 448x640 5 persons, 6.5ms\n",
            "Speed: 2.3ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 mask, 7.0ms\n",
            "Speed: 1.3ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x512 1 gloves, 1 mask, 1 ppe-suit, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x320 1 gloves, 6.2ms\n",
            "Speed: 1.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x480 1 gloves, 1 ppe-suit, 6.6ms\n",
            "Speed: 1.4ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x352 1 gloves, 1 ppe-suit, 6.1ms\n",
            "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 448x640 4 persons, 6.3ms\n",
            "Speed: 1.8ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 1 ppe-suit, 9.6ms\n",
            "Speed: 1.6ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x320 2 glovess, 1 ppe-suit, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x192 1 gloves, 12.3ms\n",
            "Speed: 1.4ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x448 1 ppe-suit, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 448x640 2 persons, 10.4ms\n",
            "Speed: 2.6ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 gloves, 1 mask, 1 ear-protector, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 480x640 1 person, 6.7ms\n",
            "Speed: 1.8ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 gloves, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 4 persons, 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x192 1 gloves, 7.1ms\n",
            "Speed: 0.7ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x288 1 gloves, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x480 1 gloves, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 480x640 2 persons, 6.6ms\n",
            "Speed: 2.4ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x288 1 mask, 1 vest, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 mask, 1 vest, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 480x640 4 persons, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 3 masks, 1 ear-protector, 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 gloves, 1 mask, 6.4ms\n",
            "Speed: 0.7ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 1 gloves, 2 masks, 2 vests, 1 ear-protector, 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 2 masks, 2 vests, 9.5ms\n",
            "Speed: 1.2ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 448x640 2 persons, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 1 ear-protector, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x288 1 gloves, 8.1ms\n",
            "Speed: 1.1ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 480x640 10 persons, 7.1ms\n",
            "Speed: 1.8ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x224 2 vests, 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 2 vests, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 (no detections), 6.3ms\n",
            "Speed: 0.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001391.jpg\n",
            "\n",
            "0: 640x192 1 vest, 6.0ms\n",
            "Speed: 0.7ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 (no detections), 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001391.jpg\n",
            "\n",
            "0: 640x224 3 vests, 6.6ms\n",
            "Speed: 0.8ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 vest, 6.3ms\n",
            "Speed: 0.7ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 vest, 5.9ms\n",
            "Speed: 0.7ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x128 1 vest, 6.3ms\n",
            "Speed: 0.6ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x384 (no detections), 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 001391.jpg\n",
            "\n",
            "0: 480x640 5 persons, 6.5ms\n",
            "Speed: 1.9ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x288 (no detections), 6.9ms\n",
            "Speed: 1.1ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001841.jpg\n",
            "\n",
            "0: 640x224 (no detections), 6.8ms\n",
            "Speed: 1.0ms preprocess, 6.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001841.jpg\n",
            "\n",
            "0: 640x288 1 vest, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x192 2 vests, 10.9ms\n",
            "Speed: 1.1ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 2 vests, 6.3ms\n",
            "Speed: 0.9ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 480x640 2 persons, 6.5ms\n",
            "Speed: 2.0ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x288 (no detections), 7.1ms\n",
            "Speed: 1.1ms preprocess, 7.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001921.jpg\n",
            "\n",
            "0: 640x320 (no detections), 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 001921.jpg\n",
            "\n",
            "0: 448x640 5 persons, 7.0ms\n",
            "Speed: 2.3ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x288 1 vest, 6.7ms\n",
            "Speed: 1.0ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 1 gloves, 6.5ms\n",
            "Speed: 1.0ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 gloves, 6.8ms\n",
            "Speed: 0.9ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 gloves, 1 vest, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 gloves, 2 vests, 7.7ms\n",
            "Speed: 0.8ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 320x640 14 persons, 6.9ms\n",
            "Speed: 1.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 2 vests, 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 gloves, 2 vests, 5.9ms\n",
            "Speed: 0.9ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 3 glovess, 1 mask, 2 vests, 5.9ms\n",
            "Speed: 0.8ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 6.4ms\n",
            "Speed: 0.8ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 2 glovess, 2 vests, 6.2ms\n",
            "Speed: 0.9ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 gloves, 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 6.2ms\n",
            "Speed: 0.8ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 gloves, 6.4ms\n",
            "Speed: 0.7ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 gloves, 5.8ms\n",
            "Speed: 0.7ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 gloves, 2 vests, 5.9ms\n",
            "Speed: 0.7ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 gloves, 1 vest, 5.8ms\n",
            "Speed: 0.6ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x128 1 gloves, 1 vest, 6.1ms\n",
            "Speed: 0.6ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x128 1 gloves, 6.1ms\n",
            "Speed: 0.5ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x160 1 gloves, 1 mask, 8.8ms\n",
            "Speed: 0.6ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 448x640 6 persons, 6.9ms\n",
            "Speed: 2.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 (no detections), 15.0ms\n",
            "Speed: 1.2ms preprocess, 15.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 005071.jpg\n",
            "\n",
            "0: 640x256 1 vest, 6.9ms\n",
            "Speed: 5.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 (no detections), 11.6ms\n",
            "Speed: 1.0ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 005071.jpg\n",
            "\n",
            "0: 640x224 (no detections), 11.4ms\n",
            "Speed: 1.2ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 005071.jpg\n",
            "\n",
            "0: 640x192 (no detections), 6.6ms\n",
            "Speed: 0.8ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 005071.jpg\n",
            "\n",
            "0: 640x64 (no detections), 6.6ms\n",
            "Speed: 0.5ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 64)\n",
            "No PPE detected in cropped image of 005071.jpg\n",
            "\n",
            "0: 448x640 8 persons, 6.5ms\n",
            "Speed: 2.3ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 (no detections), 6.6ms\n",
            "Speed: 1.3ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 005155.jpg\n",
            "\n",
            "0: 640x288 1 gloves, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 (no detections), 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 005155.jpg\n",
            "\n",
            "0: 640x288 (no detections), 6.7ms\n",
            "Speed: 1.0ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 005155.jpg\n",
            "\n",
            "0: 640x256 1 gloves, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x160 (no detections), 6.1ms\n",
            "Speed: 0.7ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 005155.jpg\n",
            "\n",
            "0: 640x64 (no detections), 6.2ms\n",
            "Speed: 0.4ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 64)\n",
            "No PPE detected in cropped image of 005155.jpg\n",
            "\n",
            "0: 640x128 (no detections), 6.2ms\n",
            "Speed: 0.6ms preprocess, 6.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 005155.jpg\n",
            "\n",
            "0: 480x640 5 persons, 6.9ms\n",
            "Speed: 2.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 6.6ms\n",
            "Speed: 0.8ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 gloves, 1 vest, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 6.9ms\n",
            "Speed: 0.8ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 2 glovess, 3 vests, 6.6ms\n",
            "Speed: 0.7ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x64 (no detections), 6.6ms\n",
            "Speed: 0.4ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 64)\n",
            "No PPE detected in cropped image of 005031.jpg\n",
            "\n",
            "0: 448x640 12 persons, 7.3ms\n",
            "Speed: 1.8ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 2 glovess, 5.7ms\n",
            "Speed: 0.9ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 gloves, 6.4ms\n",
            "Speed: 0.7ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x384 1 gloves, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x352 1 gloves, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x416 1 gloves, 6.7ms\n",
            "Speed: 1.3ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x320 1 gloves, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x288 2 glovess, 6.9ms\n",
            "Speed: 0.9ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 gloves, 5.9ms\n",
            "Speed: 0.9ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x192 1 gloves, 6.3ms\n",
            "Speed: 0.7ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 2 glovess, 6.1ms\n",
            "Speed: 0.8ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 (no detections), 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001042.jpg\n",
            "\n",
            "0: 448x640 4 persons, 7.1ms\n",
            "Speed: 2.3ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x288 1 gloves, 1 ear-protector, 6.8ms\n",
            "Speed: 1.0ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 1 gloves, 6.3ms\n",
            "Speed: 1.0ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 gloves, 6.2ms\n",
            "Speed: 0.8ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 448x640 9 persons, 6.5ms\n",
            "Speed: 2.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 2 vests, 6.3ms\n",
            "Speed: 1.0ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 gloves, 1 vest, 5.8ms\n",
            "Speed: 0.8ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 2 vests, 5.7ms\n",
            "Speed: 0.8ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 vest, 6.2ms\n",
            "Speed: 0.7ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 vest, 5.7ms\n",
            "Speed: 0.7ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 1 gloves, 6.6ms\n",
            "Speed: 0.6ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x192 (no detections), 6.4ms\n",
            "Speed: 0.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001305.jpg\n",
            "\n",
            "0: 640x512 (no detections), 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "No PPE detected in cropped image of 001305.jpg\n",
            "\n",
            "0: 448x640 2 persons, 6.9ms\n",
            "Speed: 1.7ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x192 (no detections), 6.4ms\n",
            "Speed: 0.8ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001479.jpg\n",
            "\n",
            "0: 640x256 (no detections), 6.2ms\n",
            "Speed: 0.9ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001479.jpg\n",
            "\n",
            "0: 448x640 13 persons, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 (no detections), 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001739.jpg\n",
            "\n",
            "0: 640x160 (no detections), 6.2ms\n",
            "Speed: 0.6ms preprocess, 6.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001739.jpg\n",
            "\n",
            "0: 640x288 1 gloves, 2 vests, 6.2ms\n",
            "Speed: 0.9ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x192 1 gloves, 2 vests, 10.7ms\n",
            "Speed: 0.8ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 (no detections), 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001739.jpg\n",
            "\n",
            "0: 640x192 2 vests, 7.0ms\n",
            "Speed: 0.8ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 (no detections), 6.8ms\n",
            "Speed: 1.4ms preprocess, 6.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001739.jpg\n",
            "\n",
            "0: 640x192 1 gloves, 1 vest, 6.4ms\n",
            "Speed: 0.8ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 vest, 5.8ms\n",
            "Speed: 0.8ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 vest, 5.9ms\n",
            "Speed: 0.8ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 (no detections), 6.2ms\n",
            "Speed: 0.6ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001739.jpg\n",
            "\n",
            "0: 640x192 (no detections), 6.1ms\n",
            "Speed: 0.7ms preprocess, 6.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001739.jpg\n",
            "\n",
            "0: 640x128 1 gloves, 1 vest, 6.2ms\n",
            "Speed: 0.6ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 448x640 5 persons, 6.5ms\n",
            "Speed: 1.6ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 576x640 (no detections), 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 576, 640)\n",
            "No PPE detected in cropped image of 005081.jpg\n",
            "\n",
            "0: 640x256 (no detections), 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 005081.jpg\n",
            "\n",
            "0: 640x608 (no detections), 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 608)\n",
            "No PPE detected in cropped image of 005081.jpg\n",
            "\n",
            "0: 640x288 (no detections), 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 005081.jpg\n",
            "\n",
            "0: 640x256 (no detections), 6.3ms\n",
            "Speed: 1.0ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 005081.jpg\n",
            "\n",
            "0: 512x640 5 persons, 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 6.3ms\n",
            "Speed: 1.2ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x288 1 gloves, 6.2ms\n",
            "Speed: 1.1ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 (no detections), 5.6ms\n",
            "Speed: 1.0ms preprocess, 5.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001647.jpg\n",
            "\n",
            "0: 640x288 1 gloves, 6.0ms\n",
            "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x192 (no detections), 6.2ms\n",
            "Speed: 0.8ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001647.jpg\n",
            "\n",
            "0: 480x640 8 persons, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 vest, 6.2ms\n",
            "Speed: 1.2ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x256 1 vest, 6.1ms\n",
            "Speed: 0.8ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 vest, 6.1ms\n",
            "Speed: 0.8ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 (no detections), 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 005237.jpg\n",
            "\n",
            "0: 640x224 1 vest, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 (no detections), 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 005237.jpg\n",
            "\n",
            "0: 640x192 1 vest, 6.4ms\n",
            "Speed: 0.8ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 vest, 9.4ms\n",
            "Speed: 0.8ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 480x640 4 persons, 6.6ms\n",
            "Speed: 2.0ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 7.0ms\n",
            "Speed: 0.9ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 1 vest, 6.8ms\n",
            "Speed: 0.7ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x224 1 vest, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 vest, 7.7ms\n",
            "Speed: 1.0ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 384x640 4 persons, 7.2ms\n",
            "Speed: 1.6ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x192 1 vest, 6.3ms\n",
            "Speed: 0.7ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 1 vest, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x288 (no detections), 6.3ms\n",
            "Speed: 1.1ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001303.jpg\n",
            "\n",
            "0: 640x192 1 vest, 6.8ms\n",
            "Speed: 0.7ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 448x640 9 persons, 7.8ms\n",
            "Speed: 2.0ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 10.1ms\n",
            "Speed: 0.9ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 2 vests, 12.0ms\n",
            "Speed: 1.4ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 vest, 7.0ms\n",
            "Speed: 0.8ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 2 vests, 6.6ms\n",
            "Speed: 0.8ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 2 vests, 7.0ms\n",
            "Speed: 0.9ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 2 vests, 6.5ms\n",
            "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x160 (no detections), 6.6ms\n",
            "Speed: 0.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001788.jpg\n",
            "\n",
            "0: 640x288 (no detections), 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001788.jpg\n",
            "\n",
            "0: 640x256 (no detections), 6.2ms\n",
            "Speed: 0.9ms preprocess, 6.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001788.jpg\n",
            "\n",
            "0: 448x640 10 persons, 6.4ms\n",
            "Speed: 2.2ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 (no detections), 6.7ms\n",
            "Speed: 1.3ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "No PPE detected in cropped image of 001908.jpg\n",
            "\n",
            "0: 640x256 (no detections), 6.9ms\n",
            "Speed: 1.0ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001908.jpg\n",
            "\n",
            "0: 640x256 (no detections), 6.2ms\n",
            "Speed: 1.0ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001908.jpg\n",
            "\n",
            "0: 640x256 1 vest, 5.9ms\n",
            "Speed: 1.0ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 (no detections), 10.5ms\n",
            "Speed: 0.8ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001908.jpg\n",
            "\n",
            "0: 640x256 (no detections), 7.2ms\n",
            "Speed: 1.4ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001908.jpg\n",
            "\n",
            "0: 640x160 1 vest, 6.5ms\n",
            "Speed: 0.7ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x224 (no detections), 7.3ms\n",
            "Speed: 0.8ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001908.jpg\n",
            "\n",
            "0: 640x128 (no detections), 6.6ms\n",
            "Speed: 0.6ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 001908.jpg\n",
            "\n",
            "0: 640x192 1 vest, 6.5ms\n",
            "Speed: 0.7ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 416x640 4 persons, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 1 vest, 6.8ms\n",
            "Speed: 0.9ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 2 glovess, 1 vest, 6.3ms\n",
            "Speed: 1.2ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x192 1 gloves, 6.7ms\n",
            "Speed: 0.8ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 gloves, 6.2ms\n",
            "Speed: 0.9ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 416x640 10 persons, 7.4ms\n",
            "Speed: 1.8ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 6.9ms\n",
            "Speed: 1.0ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 gloves, 2 vests, 7.0ms\n",
            "Speed: 0.9ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 1 gloves, 1 vest, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x512 1 gloves, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x224 1 vest, 7.0ms\n",
            "Speed: 0.8ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 (no detections), 6.0ms\n",
            "Speed: 0.9ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 005097.jpg\n",
            "\n",
            "0: 640x224 1 gloves, 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 6.0ms\n",
            "Speed: 0.8ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x64 (no detections), 6.3ms\n",
            "Speed: 0.5ms preprocess, 6.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 64)\n",
            "No PPE detected in cropped image of 005097.jpg\n",
            "\n",
            "0: 480x640 7 persons, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 2 vests, 6.8ms\n",
            "Speed: 1.0ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 gloves, 2 vests, 6.3ms\n",
            "Speed: 1.0ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 vest, 7.0ms\n",
            "Speed: 0.8ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x288 1 gloves, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x160 2 vests, 6.6ms\n",
            "Speed: 0.6ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x224 (no detections), 7.3ms\n",
            "Speed: 0.8ms preprocess, 7.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001930.jpg\n",
            "\n",
            "0: 640x256 1 gloves, 9.5ms\n",
            "Speed: 1.2ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 480x640 14 persons, 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x192 2 vests, 6.7ms\n",
            "Speed: 0.7ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 1 vest, 6.9ms\n",
            "Speed: 0.9ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 3 vests, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 (no detections), 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001837.jpg\n",
            "\n",
            "0: 640x288 2 vests, 6.5ms\n",
            "Speed: 1.0ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x192 2 vests, 6.4ms\n",
            "Speed: 0.7ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 vest, 5.9ms\n",
            "Speed: 0.7ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 2 vests, 6.7ms\n",
            "Speed: 0.8ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 1 vest, 6.9ms\n",
            "Speed: 0.7ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x128 (no detections), 6.3ms\n",
            "Speed: 0.6ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 001837.jpg\n",
            "\n",
            "0: 640x160 1 vest, 6.2ms\n",
            "Speed: 0.6ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x256 2 vests, 6.2ms\n",
            "Speed: 1.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x160 (no detections), 6.0ms\n",
            "Speed: 0.7ms preprocess, 6.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001837.jpg\n",
            "\n",
            "0: 640x480 (no detections), 6.1ms\n",
            "Speed: 1.3ms preprocess, 6.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "No PPE detected in cropped image of 001837.jpg\n",
            "\n",
            "0: 480x640 3 persons, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 1 vest, 6.7ms\n",
            "Speed: 1.0ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 6.2ms\n",
            "Speed: 0.8ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 6.3ms\n",
            "Speed: 1.0ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 480x640 6 persons, 6.8ms\n",
            "Speed: 2.3ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x224 1 vest, 6.1ms\n",
            "Speed: 0.8ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 2 vests, 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 vest, 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x384 3 vests, 6.5ms\n",
            "Speed: 1.3ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x160 1 vest, 6.9ms\n",
            "Speed: 0.7ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x64 (no detections), 6.2ms\n",
            "Speed: 0.5ms preprocess, 6.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 64)\n",
            "No PPE detected in cropped image of 001345.jpg\n",
            "\n",
            "0: 448x640 6 persons, 7.8ms\n",
            "Speed: 2.4ms preprocess, 7.8ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 2 vests, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 8.0ms\n",
            "Speed: 1.2ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 gloves, 2 vests, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 1 gloves, 2 vests, 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 2 glovess, 2 vests, 6.2ms\n",
            "Speed: 1.0ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 1 ear-protector, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 480x640 6 persons, 7.4ms\n",
            "Speed: 2.1ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x224 1 vest, 6.3ms\n",
            "Speed: 0.9ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 2 vests, 7.7ms\n",
            "Speed: 1.0ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 (no detections), 6.8ms\n",
            "Speed: 1.1ms preprocess, 6.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001514.jpg\n",
            "\n",
            "0: 640x192 2 vests, 6.6ms\n",
            "Speed: 0.8ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 vest, 6.2ms\n",
            "Speed: 0.8ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 2 vests, 6.5ms\n",
            "Speed: 0.7ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 480x640 3 persons, 7.2ms\n",
            "Speed: 2.7ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x256 2 vests, 6.9ms\n",
            "Speed: 1.0ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x288 1 gloves, 2 vests, 6.9ms\n",
            "Speed: 1.1ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x160 1 vest, 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 480x640 6 persons, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x320 1 gloves, 1 vest, 6.6ms\n",
            "Speed: 1.1ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x288 2 glovess, 2 vests, 7.5ms\n",
            "Speed: 1.0ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x192 1 gloves, 1 vest, 6.4ms\n",
            "Speed: 0.7ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 gloves, 1 vest, 5.8ms\n",
            "Speed: 0.7ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x96 (no detections), 6.3ms\n",
            "Speed: 0.5ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 001932.jpg\n",
            "\n",
            "0: 448x640 10 persons, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 2 glovess, 2 vests, 10.6ms\n",
            "Speed: 1.2ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 6.0ms\n",
            "Speed: 0.8ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 gloves, 1 vest, 6.9ms\n",
            "Speed: 0.8ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 gloves, 2 vests, 5.9ms\n",
            "Speed: 0.7ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 2 glovess, 2 vests, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 2 glovess, 2 vests, 5.8ms\n",
            "Speed: 0.8ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 1 vest, 6.4ms\n",
            "Speed: 0.6ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 gloves, 5.7ms\n",
            "Speed: 0.7ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x128 2 glovess, 1 vest, 6.2ms\n",
            "Speed: 0.5ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x160 1 gloves, 6.5ms\n",
            "Speed: 0.7ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 480x640 6 persons, 7.1ms\n",
            "Speed: 2.0ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x384 (no detections), 6.7ms\n",
            "Speed: 1.3ms preprocess, 6.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 005113.jpg\n",
            "\n",
            "0: 480x640 (no detections), 7.6ms\n",
            "Speed: 1.5ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No PPE detected in cropped image of 005113.jpg\n",
            "\n",
            "0: 640x544 (no detections), 7.8ms\n",
            "Speed: 1.7ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
            "No PPE detected in cropped image of 005113.jpg\n",
            "\n",
            "0: 640x352 (no detections), 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 005113.jpg\n",
            "\n",
            "0: 640x384 (no detections), 6.5ms\n",
            "Speed: 1.3ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 005113.jpg\n",
            "\n",
            "0: 640x288 (no detections), 6.8ms\n",
            "Speed: 0.9ms preprocess, 6.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 005113.jpg\n",
            "\n",
            "0: 448x640 10 persons, 7.2ms\n",
            "Speed: 2.3ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x352 (no detections), 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 001360.jpg\n",
            "\n",
            "0: 640x384 2 vests, 6.4ms\n",
            "Speed: 1.3ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x224 2 vests, 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 2 vests, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 vest, 6.4ms\n",
            "Speed: 0.7ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 1 vest, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 vest, 6.1ms\n",
            "Speed: 0.8ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 (no detections), 6.4ms\n",
            "Speed: 0.6ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001360.jpg\n",
            "\n",
            "0: 640x224 (no detections), 6.9ms\n",
            "Speed: 0.8ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001360.jpg\n",
            "\n",
            "0: 640x96 (no detections), 6.3ms\n",
            "Speed: 0.5ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 001360.jpg\n",
            "\n",
            "0: 448x640 9 persons, 6.1ms\n",
            "Speed: 1.8ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 2 vests, 9.8ms\n",
            "Speed: 1.1ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 2 vests, 6.7ms\n",
            "Speed: 0.9ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 6.2ms\n",
            "Speed: 0.8ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 2 glovess, 3 vests, 6.0ms\n",
            "Speed: 0.8ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 5.6ms\n",
            "Speed: 0.7ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 vest, 5.6ms\n",
            "Speed: 0.7ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 2 vests, 6.1ms\n",
            "Speed: 0.7ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 (no detections), 5.9ms\n",
            "Speed: 0.7ms preprocess, 5.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001282.jpg\n",
            "\n",
            "0: 448x640 6 persons, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 2 vests, 6.6ms\n",
            "Speed: 0.8ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x288 1 vest, 6.1ms\n",
            "Speed: 0.9ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 2 vests, 6.3ms\n",
            "Speed: 0.9ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 vest, 6.6ms\n",
            "Speed: 1.1ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 (no detections), 6.4ms\n",
            "Speed: 0.6ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001687.jpg\n",
            "\n",
            "0: 640x192 (no detections), 5.6ms\n",
            "Speed: 0.7ms preprocess, 5.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001687.jpg\n",
            "\n",
            "0: 480x640 9 persons, 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x256 3 vests, 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 2 vests, 6.1ms\n",
            "Speed: 0.9ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 2 vests, 5.7ms\n",
            "Speed: 0.8ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 2 vests, 5.9ms\n",
            "Speed: 0.9ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 2 vests, 6.8ms\n",
            "Speed: 0.7ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 vest, 5.8ms\n",
            "Speed: 0.7ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 1 vest, 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 vest, 5.9ms\n",
            "Speed: 0.8ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 vest, 6.2ms\n",
            "Speed: 0.8ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 448x640 2 persons, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x544 (no detections), 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
            "No PPE detected in cropped image of 001395.jpg\n",
            "\n",
            "0: 640x352 (no detections), 11.6ms\n",
            "Speed: 1.2ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 001395.jpg\n",
            "\n",
            "0: 480x640 12 persons, 7.7ms\n",
            "Speed: 1.9ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 1 vest, 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 vest, 6.2ms\n",
            "Speed: 0.9ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 (no detections), 6.4ms\n",
            "Speed: 0.8ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001205.jpg\n",
            "\n",
            "0: 640x192 2 vests, 6.3ms\n",
            "Speed: 0.7ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 2 vests, 6.8ms\n",
            "Speed: 0.9ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 2 vests, 6.0ms\n",
            "Speed: 0.8ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 2 vests, 6.1ms\n",
            "Speed: 0.8ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 (no detections), 7.3ms\n",
            "Speed: 0.8ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001205.jpg\n",
            "\n",
            "0: 640x192 (no detections), 6.1ms\n",
            "Speed: 0.8ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001205.jpg\n",
            "\n",
            "0: 640x192 1 ear-protector, 8.5ms\n",
            "Speed: 0.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 1 vest, 7.3ms\n",
            "Speed: 0.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x64 (no detections), 6.7ms\n",
            "Speed: 0.5ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 64)\n",
            "No PPE detected in cropped image of 001205.jpg\n",
            "\n",
            "0: 448x640 6 persons, 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x320 1 ppe-suit, 6.9ms\n",
            "Speed: 1.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x256 (no detections), 6.9ms\n",
            "Speed: 1.1ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001363.jpg\n",
            "\n",
            "0: 640x192 1 vest, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 2 vests, 6.9ms\n",
            "Speed: 0.8ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 2 vests, 6.8ms\n",
            "Speed: 0.8ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x96 (no detections), 6.7ms\n",
            "Speed: 0.6ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 001363.jpg\n",
            "\n",
            "0: 448x640 8 persons, 7.0ms\n",
            "Speed: 1.7ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 2 vests, 1 ear-protector, 7.8ms\n",
            "Speed: 0.9ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 8.1ms\n",
            "Speed: 1.1ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 vest, 7.5ms\n",
            "Speed: 1.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 gloves, 1 ear-protector, 7.0ms\n",
            "Speed: 1.0ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 gloves, 2 vests, 7.3ms\n",
            "Speed: 0.9ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 vest, 11.3ms\n",
            "Speed: 0.8ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 2 vests, 8.1ms\n",
            "Speed: 1.1ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x96 1 gloves, 7.3ms\n",
            "Speed: 0.6ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 96)\n",
            "\n",
            "0: 448x640 5 persons, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 (no detections), 6.6ms\n",
            "Speed: 1.3ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "No PPE detected in cropped image of 005240.jpg\n",
            "\n",
            "0: 640x352 (no detections), 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 005240.jpg\n",
            "\n",
            "0: 640x288 (no detections), 7.3ms\n",
            "Speed: 1.1ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 005240.jpg\n",
            "\n",
            "0: 640x224 (no detections), 7.0ms\n",
            "Speed: 1.0ms preprocess, 7.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 005240.jpg\n",
            "\n",
            "0: 640x224 (no detections), 9.4ms\n",
            "Speed: 1.0ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 005240.jpg\n",
            "\n",
            "0: 448x640 5 persons, 11.7ms\n",
            "Speed: 2.9ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x256 (no detections), 6.9ms\n",
            "Speed: 1.1ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001971.jpg\n",
            "\n",
            "0: 640x224 1 vest, 6.9ms\n",
            "Speed: 1.0ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 (no detections), 7.3ms\n",
            "Speed: 0.9ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001971.jpg\n",
            "\n",
            "0: 640x256 1 vest, 7.6ms\n",
            "Speed: 1.1ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 vest, 7.4ms\n",
            "Speed: 0.9ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 448x640 11 persons, 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x448 (no detections), 8.0ms\n",
            "Speed: 1.7ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "No PPE detected in cropped image of 001124.jpg\n",
            "\n",
            "0: 640x320 (no detections), 7.6ms\n",
            "Speed: 1.1ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 001124.jpg\n",
            "\n",
            "0: 640x224 (no detections), 7.5ms\n",
            "Speed: 1.2ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001124.jpg\n",
            "\n",
            "0: 640x576 (no detections), 7.9ms\n",
            "Speed: 2.1ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "No PPE detected in cropped image of 001124.jpg\n",
            "\n",
            "0: 608x640 (no detections), 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 608, 640)\n",
            "No PPE detected in cropped image of 001124.jpg\n",
            "\n",
            "0: 640x512 (no detections), 6.6ms\n",
            "Speed: 1.6ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "No PPE detected in cropped image of 001124.jpg\n",
            "\n",
            "0: 640x352 (no detections), 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 001124.jpg\n",
            "\n",
            "0: 640x352 (no detections), 6.3ms\n",
            "Speed: 1.3ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 001124.jpg\n",
            "\n",
            "0: 640x160 (no detections), 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001124.jpg\n",
            "\n",
            "0: 640x64 (no detections), 6.5ms\n",
            "Speed: 0.4ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 64)\n",
            "No PPE detected in cropped image of 001124.jpg\n",
            "\n",
            "0: 640x64 (no detections), 7.5ms\n",
            "Speed: 0.5ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 64)\n",
            "No PPE detected in cropped image of 001124.jpg\n",
            "\n",
            "0: 448x640 11 persons, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x256 2 vests, 6.9ms\n",
            "Speed: 0.9ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 2 vests, 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 2 vests, 5.9ms\n",
            "Speed: 0.8ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 1 vest, 7.0ms\n",
            "Speed: 1.0ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 2 vests, 6.4ms\n",
            "Speed: 1.0ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x160 1 vest, 6.5ms\n",
            "Speed: 0.7ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 (no detections), 5.9ms\n",
            "Speed: 0.7ms preprocess, 5.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001388.jpg\n",
            "\n",
            "0: 640x224 2 vests, 7.3ms\n",
            "Speed: 0.9ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 (no detections), 6.2ms\n",
            "Speed: 0.9ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001388.jpg\n",
            "\n",
            "0: 640x160 1 vest, 6.7ms\n",
            "Speed: 0.7ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x128 (no detections), 6.5ms\n",
            "Speed: 0.6ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 001388.jpg\n",
            "\n",
            "0: 480x640 5 persons, 7.1ms\n",
            "Speed: 1.9ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x288 (no detections), 7.8ms\n",
            "Speed: 1.0ms preprocess, 7.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001637.jpg\n",
            "\n",
            "0: 640x288 1 gloves, 6.4ms\n",
            "Speed: 1.0ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 (no detections), 5.9ms\n",
            "Speed: 1.0ms preprocess, 5.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001637.jpg\n",
            "\n",
            "0: 640x224 1 gloves, 6.3ms\n",
            "Speed: 0.9ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x128 (no detections), 6.4ms\n",
            "Speed: 0.6ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 001637.jpg\n",
            "\n",
            "0: 384x640 14 persons, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x448 (no detections), 6.1ms\n",
            "Speed: 1.4ms preprocess, 6.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 640x288 (no detections), 7.9ms\n",
            "Speed: 1.0ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 640x512 (no detections), 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 640x448 (no detections), 6.2ms\n",
            "Speed: 1.4ms preprocess, 6.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 640x224 (no detections), 6.2ms\n",
            "Speed: 0.8ms preprocess, 6.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 544x640 (no detections), 7.9ms\n",
            "Speed: 1.5ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 640x416 (no detections), 6.3ms\n",
            "Speed: 1.2ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 416)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 640x640 (no detections), 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 640x352 (no detections), 6.8ms\n",
            "Speed: 1.1ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 640x384 (no detections), 10.6ms\n",
            "Speed: 1.1ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 640x480 (no detections), 6.8ms\n",
            "Speed: 2.0ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 640x608 (no detections), 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 608)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 640x640 (no detections), 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 640x480 (no detections), 6.6ms\n",
            "Speed: 1.3ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "No PPE detected in cropped image of 001792.jpg\n",
            "\n",
            "0: 448x640 8 persons, 7.0ms\n",
            "Speed: 1.8ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x288 (no detections), 6.8ms\n",
            "Speed: 0.9ms preprocess, 6.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001547.jpg\n",
            "\n",
            "0: 640x608 (no detections), 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 608)\n",
            "No PPE detected in cropped image of 001547.jpg\n",
            "\n",
            "0: 640x512 (no detections), 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "No PPE detected in cropped image of 001547.jpg\n",
            "\n",
            "0: 640x640 (no detections), 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No PPE detected in cropped image of 001547.jpg\n",
            "\n",
            "0: 640x608 (no detections), 8.8ms\n",
            "Speed: 1.6ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 608)\n",
            "No PPE detected in cropped image of 001547.jpg\n",
            "\n",
            "0: 640x608 (no detections), 8.2ms\n",
            "Speed: 1.6ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 608)\n",
            "No PPE detected in cropped image of 001547.jpg\n",
            "\n",
            "0: 640x416 (no detections), 6.6ms\n",
            "Speed: 1.3ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "No PPE detected in cropped image of 001547.jpg\n",
            "\n",
            "0: 640x416 (no detections), 6.0ms\n",
            "Speed: 1.3ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "No PPE detected in cropped image of 001547.jpg\n",
            "\n",
            "0: 448x640 5 persons, 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 6.5ms\n",
            "Speed: 1.3ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x352 1 gloves, 5.9ms\n",
            "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x384 2 glovess, 6.6ms\n",
            "Speed: 1.3ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x224 1 gloves, 7.1ms\n",
            "Speed: 0.9ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 gloves, 1 vest, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 480x640 8 persons, 7.3ms\n",
            "Speed: 2.7ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x224 (no detections), 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001146.jpg\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 5.8ms\n",
            "Speed: 0.8ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 (no detections), 5.7ms\n",
            "Speed: 0.9ms preprocess, 5.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001146.jpg\n",
            "\n",
            "0: 640x224 1 gloves, 4 vests, 5.7ms\n",
            "Speed: 0.8ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 gloves, 1 vest, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 vest, 6.2ms\n",
            "Speed: 0.7ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 gloves, 1 vest, 5.7ms\n",
            "Speed: 0.7ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 vest, 9.7ms\n",
            "Speed: 0.7ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 352x640 8 persons, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
            "\n",
            "0: 640x224 (no detections), 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 005275.jpg\n",
            "\n",
            "0: 640x320 (no detections), 6.9ms\n",
            "Speed: 1.1ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 005275.jpg\n",
            "\n",
            "0: 640x224 (no detections), 8.4ms\n",
            "Speed: 1.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 005275.jpg\n",
            "\n",
            "0: 640x416 (no detections), 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "No PPE detected in cropped image of 005275.jpg\n",
            "\n",
            "0: 640x480 (no detections), 6.2ms\n",
            "Speed: 1.4ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "No PPE detected in cropped image of 005275.jpg\n",
            "\n",
            "0: 640x256 (no detections), 6.2ms\n",
            "Speed: 0.9ms preprocess, 6.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 005275.jpg\n",
            "\n",
            "0: 640x256 (no detections), 5.7ms\n",
            "Speed: 0.9ms preprocess, 5.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 005275.jpg\n",
            "\n",
            "0: 640x352 (no detections), 6.6ms\n",
            "Speed: 1.1ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 005275.jpg\n",
            "\n",
            "0: 448x640 9 persons, 7.1ms\n",
            "Speed: 1.8ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 7.1ms\n",
            "Speed: 0.9ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x288 2 glovess, 1 vest, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 1 gloves, 6.3ms\n",
            "Speed: 0.9ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x320 1 vest, 6.2ms\n",
            "Speed: 1.0ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x192 1 gloves, 6.2ms\n",
            "Speed: 0.7ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 1 gloves, 2 vests, 6.2ms\n",
            "Speed: 0.7ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x256 1 gloves, 1 vest, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 2 glovess, 6.7ms\n",
            "Speed: 0.8ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 vest, 7.7ms\n",
            "Speed: 0.8ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 448x640 9 persons, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 2 vests, 11.6ms\n",
            "Speed: 1.2ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 4 vests, 7.1ms\n",
            "Speed: 1.5ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 2 vests, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 2 vests, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 3 vests, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 6.8ms\n",
            "Speed: 0.9ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 1 vest, 12.3ms\n",
            "Speed: 0.6ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x192 1 vest, 7.1ms\n",
            "Speed: 0.8ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 (no detections), 6.2ms\n",
            "Speed: 0.7ms preprocess, 6.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 005129.jpg\n",
            "\n",
            "0: 480x640 6 persons, 6.6ms\n",
            "Speed: 1.8ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x320 (no detections), 6.5ms\n",
            "Speed: 1.0ms preprocess, 6.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 001453.jpg\n",
            "\n",
            "0: 640x320 (no detections), 5.9ms\n",
            "Speed: 1.0ms preprocess, 5.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 001453.jpg\n",
            "\n",
            "0: 640x256 (no detections), 6.3ms\n",
            "Speed: 0.9ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001453.jpg\n",
            "\n",
            "0: 640x288 (no detections), 6.3ms\n",
            "Speed: 0.9ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001453.jpg\n",
            "\n",
            "0: 640x256 (no detections), 6.0ms\n",
            "Speed: 0.9ms preprocess, 6.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001453.jpg\n",
            "\n",
            "0: 640x96 (no detections), 6.1ms\n",
            "Speed: 0.5ms preprocess, 6.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 001453.jpg\n",
            "\n",
            "0: 448x640 2 persons, 6.6ms\n",
            "Speed: 1.6ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x288 1 vest, 6.2ms\n",
            "Speed: 1.1ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 vest, 5.9ms\n",
            "Speed: 1.0ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 448x640 5 persons, 6.4ms\n",
            "Speed: 2.1ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 6.1ms\n",
            "Speed: 0.9ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 gloves, 5.8ms\n",
            "Speed: 0.9ms preprocess, 5.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 gloves, 5.6ms\n",
            "Speed: 0.9ms preprocess, 5.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x192 1 gloves, 6.0ms\n",
            "Speed: 0.7ms preprocess, 6.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x320 1 gloves, 6.1ms\n",
            "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 576x640 14 persons, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 640x192 1 gloves, 3 vests, 1 ear-protector, 6.2ms\n",
            "Speed: 0.8ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 4 vests, 5.8ms\n",
            "Speed: 0.7ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 2 vests, 5.9ms\n",
            "Speed: 0.7ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 2 vests, 6.1ms\n",
            "Speed: 0.8ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 2 vests, 6.0ms\n",
            "Speed: 0.7ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 (no detections), 6.3ms\n",
            "Speed: 0.9ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001661.jpg\n",
            "\n",
            "0: 640x256 3 vests, 1 ear-protector, 6.0ms\n",
            "Speed: 0.9ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 2 vests, 6.2ms\n",
            "Speed: 0.7ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x352 (no detections), 6.2ms\n",
            "Speed: 1.0ms preprocess, 6.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 001661.jpg\n",
            "\n",
            "0: 640x192 2 vests, 6.7ms\n",
            "Speed: 0.6ms preprocess, 6.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 2 vests, 7.4ms\n",
            "Speed: 1.3ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 vest, 5.9ms\n",
            "Speed: 0.7ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 (no detections), 7.5ms\n",
            "Speed: 0.6ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001661.jpg\n",
            "\n",
            "0: 640x160 (no detections), 5.6ms\n",
            "Speed: 0.6ms preprocess, 5.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001661.jpg\n",
            "\n",
            "0: 640x640 2 persons, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x448 2 masks, 6.6ms\n",
            "Speed: 1.9ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x640 2 persons, 7.6ms\n",
            "Speed: 1.7ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 7.0ms\n",
            "Speed: 0.9ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 1 gloves, 6.3ms\n",
            "Speed: 0.7ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 1 person, 7.5ms\n",
            "Speed: 1.4ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x448 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 1 ear-protector, 6.2ms\n",
            "Speed: 1.6ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x640 3 persons, 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 1 ppe-suit, 1 ear-protector, 6.2ms\n",
            "Speed: 0.9ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x160 1 gloves, 2 vests, 1 ppe-suit, 1 ear-protector, 6.1ms\n",
            "Speed: 0.7ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x288 1 gloves, 1 ppe-suit, 6.2ms\n",
            "Speed: 0.9ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x640 3 persons, 7.5ms\n",
            "Speed: 1.4ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 mask, 1 ear-protector, 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 gloves, 6.3ms\n",
            "Speed: 1.1ms preprocess, 6.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x448 1 gloves, 6.2ms\n",
            "Speed: 1.5ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x640 2 persons, 7.6ms\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 2 glovess, 6.2ms\n",
            "Speed: 1.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 576x640 1 gloves, 7.8ms\n",
            "Speed: 1.6ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 640x640 2 persons, 8.5ms\n",
            "Speed: 2.1ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x352 (no detections), 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-34_jpg.rf.01d6349eabce5613415c586a543c9f0b.jpg\n",
            "\n",
            "0: 640x288 (no detections), 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-34_jpg.rf.01d6349eabce5613415c586a543c9f0b.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.7ms\n",
            "Speed: 1.6ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 mask, 2 vests, 1 ppe-suit, 6.4ms\n",
            "Speed: 1.3ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x640 7 persons, 7.7ms\n",
            "Speed: 1.6ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 gloves, 6.9ms\n",
            "Speed: 0.8ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 416x640 1 gloves, 1 ppe-suit, 6.5ms\n",
            "Speed: 1.3ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x256 2 glovess, 1 ppe-suit, 6.2ms\n",
            "Speed: 1.1ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x544 1 ppe-suit, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x224 1 gloves, 1 ppe-suit, 7.1ms\n",
            "Speed: 1.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 384x640 1 gloves, 1 ppe-suit, 6.9ms\n",
            "Speed: 1.3ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x640 5 persons, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 1 mask, 3 ear-protectors, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 1 gloves, 2 masks, 2 vests, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 gloves, 2 masks, 9.5ms\n",
            "Speed: 1.5ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 1 gloves, 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 1 vest, 6.2ms\n",
            "Speed: 0.7ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 (no detections), 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in ppe_1189_jpg.rf.f6977c81a4c10b70e7d36a5b90956b94.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 1 ppe-suit, 6.0ms\n",
            "Speed: 0.8ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 1 person, 7.5ms\n",
            "Speed: 1.8ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x352 (no detections), 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of YouTube-FreeStockFootage-PersonThinkingDeeply-h-HC-hj-Zo-720p_mp4-7_jpg.rf.4d6b125dc1fa9f9970e29a35bab61c9a.jpg\n",
            "\n",
            "0: 640x640 5 persons, 7.7ms\n",
            "Speed: 1.5ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 10.6ms\n",
            "Speed: 1.1ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 gloves, 1 ear-protector, 10.4ms\n",
            "Speed: 1.2ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 gloves, 1 ear-protector, 6.0ms\n",
            "Speed: 0.8ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 gloves, 5.9ms\n",
            "Speed: 0.8ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x320 (no detections), 6.7ms\n",
            "Speed: 0.9ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of -2082-_png_jpg.rf.7b89e77b67643cd28c0ce52ed7e588e3.jpg\n",
            "\n",
            "0: 640x640 6 persons, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 vest, 6.7ms\n",
            "Speed: 1.0ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 2 vests, 5.8ms\n",
            "Speed: 0.7ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x192 (no detections), 6.3ms\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001056_jpg.rf.fb5d9fbc2ccfa43ca89d84be6d2a98ea.jpg\n",
            "\n",
            "0: 640x160 2 vests, 6.4ms\n",
            "Speed: 0.7ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 vest, 5.9ms\n",
            "Speed: 0.7ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x128 2 vests, 6.3ms\n",
            "Speed: 0.7ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x640 (no detections), 7.5ms\n",
            "Speed: 1.6ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in YouTube-FREE-AerialStockFootage_CityUrban-YKY3Mm5P1tE-720p_mp4-7_jpg.rf.3ad1e4933e697179f9d54d06d31830e4.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No PPE detected in cropped image of -1477-_png_jpg.rf.bac8d06edca64da17ced23797d0e2339.jpg\n",
            "\n",
            "0: 640x640 5 persons, 7.8ms\n",
            "Speed: 1.6ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 2 glovess, 2 vests, 6.9ms\n",
            "Speed: 0.7ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 gloves, 2 vests, 6.0ms\n",
            "Speed: 0.6ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 gloves, 2 vests, 5.5ms\n",
            "Speed: 0.6ms preprocess, 5.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x128 1 gloves, 2 vests, 6.3ms\n",
            "Speed: 0.5ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x128 1 gloves, 1 vest, 5.5ms\n",
            "Speed: 0.5ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x640 1 person, 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 2 masks, 6.4ms\n",
            "Speed: 1.1ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 2 vests, 1 ear-protector, 6.1ms\n",
            "Speed: 0.7ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 (no detections), 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in ppe_1130_jpg.rf.88358e5b86cdc4d55d4689abe5cb87e4.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 8.6ms\n",
            "Speed: 4.2ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No PPE detected in cropped image of RPReplay_Final1667001201_MP4-459_jpg.rf.352ca04a4c2cc5df8bf2dd3d8c01c120.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 1 mask, 1 vest, 1 ppe-suit, 6.6ms\n",
            "Speed: 1.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x640 1 person, 7.7ms\n",
            "Speed: 1.7ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 7.1ms\n",
            "Speed: 1.0ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 3 persons, 7.5ms\n",
            "Speed: 1.6ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 6.5ms\n",
            "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x608 1 gloves, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 1.1ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "No PPE detected in cropped image of -4216-_png_jpg.rf.881e17f72716e3cbdaa9d20cf9558142.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.8ms\n",
            "Speed: 1.6ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ear-protector, 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x640 1 person, 7.7ms\n",
            "Speed: 1.5ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 6.8ms\n",
            "Speed: 0.8ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 3 masks, 2 vests, 1 ppe-suit, 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 2 persons, 7.6ms\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x256 1 gloves, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x640 1 person, 7.7ms\n",
            "Speed: 1.5ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x640 (no detections), 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in -1571-_png_jpg.rf.ccf919d5ea025ddc24cf0a707b331249.jpg\n",
            "\n",
            "0: 640x640 (no detections), 7.6ms\n",
            "Speed: 1.7ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in youtube-6_jpg.rf.a9f31f242ee7d731c625ed07f6002b9b.jpg\n",
            "\n",
            "0: 640x640 3 persons, 7.6ms\n",
            "Speed: 1.7ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 2 glovess, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x640 1 gloves, 1 vest, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 6.6ms\n",
            "Speed: 1.0ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x640 3 persons, 7.9ms\n",
            "Speed: 1.5ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 6.5ms\n",
            "Speed: 1.0ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 gloves, 2 vests, 8.9ms\n",
            "Speed: 0.9ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 1 person, 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 2 masks, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x640 6 persons, 7.7ms\n",
            "Speed: 1.6ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x288 2 glovess, 1 vest, 6.7ms\n",
            "Speed: 1.0ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 5.7ms\n",
            "Speed: 0.8ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 5.9ms\n",
            "Speed: 0.8ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 1 gloves, 1 vest, 6.2ms\n",
            "Speed: 0.7ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 gloves, 6.1ms\n",
            "Speed: 0.7ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x448 1 gloves, 1 mask, 1 vest, 1 ear-protector, 7.1ms\n",
            "Speed: 1.4ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x640 3 persons, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 gloves, 6.4ms\n",
            "Speed: 0.8ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x128 (no detections), 6.7ms\n",
            "Speed: 0.6ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of -4100-_png_jpg.rf.aebfe87c2b4f556f03d14fc3cc6facf7.jpg\n",
            "\n",
            "0: 640x640 2 persons, 9.7ms\n",
            "Speed: 1.7ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x448 1 gloves, 1 mask, 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x512 1 gloves, 1 mask, 1 ear-protector, 6.6ms\n",
            "Speed: 1.6ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x640 1 person, 7.8ms\n",
            "Speed: 1.6ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 mask, 1 vest, 1 ppe-suit, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.5ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 6.4ms\n",
            "Speed: 0.8ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.3ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 2 masks, 2 vests, 1 ppe-suit, 6.0ms\n",
            "Speed: 0.8ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 4 persons, 7.6ms\n",
            "Speed: 1.7ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x192 1 gloves, 6.8ms\n",
            "Speed: 0.8ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 gloves, 5.9ms\n",
            "Speed: 0.9ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 1 gloves, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x128 1 gloves, 6.6ms\n",
            "Speed: 0.6ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x640 4 persons, 7.5ms\n",
            "Speed: 1.4ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 1 ear-protector, 6.3ms\n",
            "Speed: 1.1ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x160 1 ear-protector, 6.5ms\n",
            "Speed: 0.7ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 gloves, 1 ear-protector, 5.9ms\n",
            "Speed: 0.7ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x224 (no detections), 10.1ms\n",
            "Speed: 0.8ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001302_jpg.rf.6e51fb4e9255ceda9bca16f35d4ae32b.jpg\n",
            "\n",
            "0: 640x640 3 persons, 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 6.3ms\n",
            "Speed: 1.3ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x320 1 gloves, 6.2ms\n",
            "Speed: 1.2ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x192 1 gloves, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x640 2 persons, 7.6ms\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 1 mask, 1 ppe-suit, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x192 1 ppe-suit, 6.2ms\n",
            "Speed: 0.8ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x640 2 persons, 7.6ms\n",
            "Speed: 1.3ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x544 1 gloves, 7.8ms\n",
            "Speed: 1.7ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x352 1 gloves, 1 vest, 6.1ms\n",
            "Speed: 1.2ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x640 2 persons, 7.9ms\n",
            "Speed: 1.3ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x448 (no detections), 6.4ms\n",
            "Speed: 1.8ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "No PPE detected in cropped image of ppe_1166_jpg.rf.ccad8bba387168ec13aa4f3ce7848f27.jpg\n",
            "\n",
            "0: 640x352 (no detections), 6.7ms\n",
            "Speed: 1.3ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of ppe_1166_jpg.rf.ccad8bba387168ec13aa4f3ce7848f27.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.9ms\n",
            "Speed: 1.7ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 1 mask, 1 vest, 1 ppe-suit, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x640 2 persons, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x192 1 gloves, 1 ppe-suit, 6.6ms\n",
            "Speed: 0.8ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 2 glovess, 5.9ms\n",
            "Speed: 0.7ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x640 (no detections), 7.7ms\n",
            "Speed: 1.5ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in -2390-_png_jpg.rf.fa4cf091a0bc051c044e2505719d3971.jpg\n",
            "\n",
            "0: 640x640 4 persons, 7.9ms\n",
            "Speed: 1.8ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 6.7ms\n",
            "Speed: 1.0ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 gloves, 1 vest, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x320 1 gloves, 1 vest, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x224 2 glovess, 1 vest, 6.3ms\n",
            "Speed: 1.0ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 2 persons, 7.6ms\n",
            "Speed: 1.5ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 1 vest, 6.6ms\n",
            "Speed: 1.0ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x160 1 gloves, 1 vest, 6.3ms\n",
            "Speed: 0.7ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 2 persons, 7.7ms\n",
            "Speed: 1.5ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 (no detections), 7.5ms\n",
            "Speed: 1.2ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-35_jpg.rf.d03a2efbca9287a52d02a3d428d2aaf5.jpg\n",
            "\n",
            "0: 640x352 (no detections), 8.1ms\n",
            "Speed: 1.2ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-35_jpg.rf.d03a2efbca9287a52d02a3d428d2aaf5.jpg\n",
            "\n",
            "0: 640x640 2 persons, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x224 (no detections), 6.4ms\n",
            "Speed: 0.8ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of -1943-_png_jpg.rf.fe8693f39c8d2c4be6615a63edd3550d.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x192 1 gloves, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x640 1 person, 11.0ms\n",
            "Speed: 1.8ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 8.5ms\n",
            "Speed: 1.2ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 2 persons, 7.6ms\n",
            "Speed: 1.7ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ear-protector, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x288 1 ear-protector, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x640 1 person, 7.8ms\n",
            "Speed: 1.7ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 mask, 7.2ms\n",
            "Speed: 1.5ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x640 2 persons, 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 mask, 1 ear-protector, 6.6ms\n",
            "Speed: 1.6ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ppe-suit, 5.8ms\n",
            "Speed: 1.5ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x640 8 persons, 7.6ms\n",
            "Speed: 1.5ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 2 glovess, 6.6ms\n",
            "Speed: 1.3ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x192 4 glovess, 1 mask, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x384 2 glovess, 9.6ms\n",
            "Speed: 1.5ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x320 4 glovess, 1 mask, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x160 1 gloves, 6.4ms\n",
            "Speed: 0.8ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x192 1 gloves, 6.2ms\n",
            "Speed: 0.9ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 1 gloves, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x384 (no detections), 6.7ms\n",
            "Speed: 1.3ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 001353_jpg.rf.c0abf8e966961dd3c902dce35a401240.jpg\n",
            "\n",
            "0: 640x640 1 person, 9.9ms\n",
            "Speed: 1.6ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 gloves, 11.6ms\n",
            "Speed: 4.0ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x640 (no detections), 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in YouTube-FREE-AerialStockFootage_CityUrban-YKY3Mm5P1tE-720p_mp4-31_jpg.rf.c88b23a01eb99ef16b5208d11dd5764f.jpg\n",
            "\n",
            "0: 640x640 3 persons, 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x352 (no detections), 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 001107_jpg.rf.ddc4b21edf46aaa9518dfe33a381ff29.jpg\n",
            "\n",
            "0: 640x288 1 gloves, 1 mask, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 6.3ms\n",
            "Speed: 0.9ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 1 person, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 576x640 1 gloves, 8.0ms\n",
            "Speed: 1.6ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.5ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 2 vests, 1 ppe-suit, 6.9ms\n",
            "Speed: 1.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.7ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.5ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 7.8ms\n",
            "Speed: 1.1ms preprocess, 7.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x640 1 person, 7.7ms\n",
            "Speed: 1.6ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 2 masks, 1 vest, 1 ppe-suit, 6.0ms\n",
            "Speed: 1.1ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.5ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 2 masks, 1 glasses, 2 vests, 3 ear-protectors, 6.8ms\n",
            "Speed: 1.4ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x640 1 person, 7.8ms\n",
            "Speed: 1.6ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 2 vests, 1 ppe-suit, 7.3ms\n",
            "Speed: 1.4ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x640 1 person, 7.7ms\n",
            "Speed: 1.5ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 2 masks, 1 glasses, 2 vests, 1 ppe-suit, 6.5ms\n",
            "Speed: 1.3ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 2 glovess, 2 masks, 1 glasses, 2 vests, 1 ppe-suit, 7.4ms\n",
            "Speed: 1.6ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x640 1 person, 8.0ms\n",
            "Speed: 1.7ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 vest, 1 ppe-suit, 9.9ms\n",
            "Speed: 1.2ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 1 person, 7.7ms\n",
            "Speed: 1.7ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x352 2 masks, 1 vest, 1 ppe-suit, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 2 masks, 2 vests, 1 ear-protector, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.5ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 2 glovess, 2 masks, 2 vests, 1 ppe-suit, 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x640 (no detections), 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in TsirinTu0018_jpg.rf.3fe2fc0fdb3a31434f1bac91d61e53be.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.8ms\n",
            "Speed: 1.5ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 mask, 1 vest, 1 ppe-suit, 5.8ms\n",
            "Speed: 1.3ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x640 1 person, 7.8ms\n",
            "Speed: 1.5ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x640 1 person, 8.7ms\n",
            "Speed: 1.6ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x128 1 gloves, 1 mask, 2 vests, 6.6ms\n",
            "Speed: 0.8ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 2 masks, 1 ppe-suit, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x640 1 person, 7.7ms\n",
            "Speed: 1.6ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 ppe-suit, 6.8ms\n",
            "Speed: 1.3ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x640 1 person, 11.2ms\n",
            "Speed: 1.5ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 1 mask, 1 glasses, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.5ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 2 glovess, 1 mask, 2 vests, 1 ppe-suit, 6.3ms\n",
            "Speed: 1.5ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x640 1 person, 7.9ms\n",
            "Speed: 1.4ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 2 masks, 1 vest, 7.1ms\n",
            "Speed: 1.4ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x640 3 persons, 7.6ms\n",
            "Speed: 1.5ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 1 vest, 1 ppe-suit, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x352 1 gloves, 1 vest, 1 ppe-suit, 6.2ms\n",
            "Speed: 1.3ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 1 ppe-suit, 6.3ms\n",
            "Speed: 0.9ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x544 2 glovess, 1 mask, 2 vests, 1 ear-protector, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x640 1 person, 7.8ms\n",
            "Speed: 1.3ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 6.5ms\n",
            "Speed: 1.3ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x640 1 person, 8.5ms\n",
            "Speed: 1.9ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 544x640 1 mask, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 640x640 1 person, 8.0ms\n",
            "Speed: 1.4ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 6.8ms\n",
            "Speed: 1.4ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x640 2 persons, 7.7ms\n",
            "Speed: 1.5ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 2 masks, 2 vests, 1 ear-protector, 9.8ms\n",
            "Speed: 1.2ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x192 1 gloves, 2 masks, 3 vests, 1 ear-protector, 11.3ms\n",
            "Speed: 1.3ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x640 7 persons, 7.6ms\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 6.4ms\n",
            "Speed: 0.7ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 gloves, 1 mask, 2 vests, 1 ppe-suit, 5.8ms\n",
            "Speed: 0.7ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 gloves, 2 masks, 1 glasses, 1 vest, 1 ppe-suit, 5.6ms\n",
            "Speed: 0.7ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x192 2 masks, 3 vests, 1 ear-protector, 6.4ms\n",
            "Speed: 0.7ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 gloves, 1 mask, 1 ppe-suit, 5.9ms\n",
            "Speed: 0.7ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 6.1ms\n",
            "Speed: 0.7ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 gloves, 1 mask, 6.0ms\n",
            "Speed: 0.6ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 5 persons, 7.6ms\n",
            "Speed: 1.7ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 2 masks, 2 vests, 6.5ms\n",
            "Speed: 1.0ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x224 1 gloves, 1 mask, 6.4ms\n",
            "Speed: 1.0ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x128 1 gloves, 2 masks, 1 vest, 1 ppe-suit, 6.6ms\n",
            "Speed: 0.7ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x160 1 gloves, 1 mask, 2 vests, 1 ppe-suit, 6.5ms\n",
            "Speed: 0.7ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 gloves, 2 vests, 1 ppe-suit, 6.0ms\n",
            "Speed: 0.7ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 (no detections), 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in ppe_1202_jpg.rf.c2963de6cf48426e058b866f008b72f0_aug_0_aug_0.jpg\n",
            "\n",
            "0: 640x640 (no detections), 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in ppe_1202_jpg.rf.c2963de6cf48426e058b866f008b72f0_aug_0_aug_1.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 (no detections), 6.4ms\n",
            "Speed: 1.5ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of ppe_1202_jpg.rf.c2963de6cf48426e058b866f008b72f0_aug_0_aug_2.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 (no detections), 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of ppe_1202_jpg.rf.c2963de6cf48426e058b866f008b72f0_aug_0_aug_3.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 (no detections), 6.2ms\n",
            "Speed: 1.9ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of ppe_1202_jpg.rf.c2963de6cf48426e058b866f008b72f0_aug_0_aug_4.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.6ms\n",
            "Speed: 1.5ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x448 1 gloves, 1 ppe-suit, 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x640 1 person, 7.8ms\n",
            "Speed: 1.5ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x192 1 gloves, 6.7ms\n",
            "Speed: 0.8ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x640 1 person, 9.3ms\n",
            "Speed: 1.6ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 1 ppe-suit, 8.0ms\n",
            "Speed: 1.1ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 1 person, 9.7ms\n",
            "Speed: 1.6ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 1 ppe-suit, 10.4ms\n",
            "Speed: 1.2ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 1 person, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 1 ppe-suit, 11.4ms\n",
            "Speed: 1.5ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 (no detections), 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in ppe_1202_jpg.rf.c2963de6cf48426e058b866f008b72f0_aug_2_aug_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x192 1 gloves, 1 ppe-suit, 8.8ms\n",
            "Speed: 1.4ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x640 1 person, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 1 ppe-suit, 15.7ms\n",
            "Speed: 1.2ms preprocess, 15.7ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 1 person, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 1 ppe-suit, 10.9ms\n",
            "Speed: 1.2ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 1 person, 8.5ms\n",
            "Speed: 2.1ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 1 ppe-suit, 13.5ms\n",
            "Speed: 1.3ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 (no detections), 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in ppe_1202_jpg.rf.c2963de6cf48426e058b866f008b72f0_aug_3_aug_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 1 ppe-suit, 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x640 1 person, 8.1ms\n",
            "Speed: 2.0ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 1 ppe-suit, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x640 1 person, 8.1ms\n",
            "Speed: 2.0ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 ppe-suit, 8.5ms\n",
            "Speed: 3.6ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 1 ppe-suit, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x640 1 person, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 1 ppe-suit, 8.8ms\n",
            "Speed: 1.2ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 (no detections), 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in ppe_1202_jpg.rf.c2963de6cf48426e058b866f008b72f0_aug_4_aug_1.jpg\n",
            "\n",
            "0: 640x640 1 person, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 1 ppe-suit, 9.0ms\n",
            "Speed: 1.2ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 1 person, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x160 1 gloves, 1 ppe-suit, 10.2ms\n",
            "Speed: 1.3ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 (no detections), 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in ppe_1202_jpg.rf.c2963de6cf48426e058b866f008b72f0_aug_4_aug_4.jpg\n",
            "\n",
            "0: 448x640 4 persons, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x576 2 glovess, 2 masks, 3 ppe-suits, 15.7ms\n",
            "Speed: 3.1ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 1 ppe-suit, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 9.6ms\n",
            "Speed: 1.4ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 ppe-suit, 8.7ms\n",
            "Speed: 1.4ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 448x640 4 persons, 8.2ms\n",
            "Speed: 2.7ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x576 2 glovess, 2 masks, 3 ppe-suits, 8.8ms\n",
            "Speed: 3.3ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 1 ppe-suit, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 8.6ms\n",
            "Speed: 1.3ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 ppe-suit, 8.7ms\n",
            "Speed: 1.4ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 448x640 4 persons, 8.2ms\n",
            "Speed: 2.6ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x576 2 glovess, 2 masks, 3 ppe-suits, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 1 ppe-suit, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 10.9ms\n",
            "Speed: 1.3ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 ppe-suit, 9.0ms\n",
            "Speed: 1.5ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 448x640 4 persons, 8.2ms\n",
            "Speed: 2.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x640 2 glovess, 2 masks, 3 ppe-suits, 9.2ms\n",
            "Speed: 3.5ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 mask, 1 ppe-suit, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x224 1 ppe-suit, 12.1ms\n",
            "Speed: 1.3ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x288 1 ppe-suit, 16.3ms\n",
            "Speed: 1.7ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 448x640 4 persons, 11.5ms\n",
            "Speed: 2.8ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x576 2 glovess, 2 masks, 3 ppe-suits, 12.7ms\n",
            "Speed: 3.1ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 1 ppe-suit, 12.4ms\n",
            "Speed: 1.8ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 11.8ms\n",
            "Speed: 1.4ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 ppe-suit, 9.7ms\n",
            "Speed: 1.3ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 448x640 4 persons, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 9.0ms\n",
            "Speed: 1.4ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x608 2 glovess, 2 masks, 3 ppe-suits, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x224 1 ppe-suit, 13.0ms\n",
            "Speed: 1.4ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 1 ppe-suit, 10.6ms\n",
            "Speed: 1.5ms preprocess, 10.6ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 448x640 4 persons, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 1 ppe-suit, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x608 2 glovess, 2 masks, 3 ppe-suits, 9.6ms\n",
            "Speed: 3.4ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x288 1 ppe-suit, 13.2ms\n",
            "Speed: 1.8ms preprocess, 13.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 9.4ms\n",
            "Speed: 1.5ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 448x640 2 persons, 9.4ms\n",
            "Speed: 1.9ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 mask, 4 ppe-suits, 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x512 1 gloves, 1 mask, 1 ppe-suit, 8.2ms\n",
            "Speed: 2.6ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 448x640 4 persons, 7.5ms\n",
            "Speed: 2.5ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x576 2 glovess, 2 masks, 3 ppe-suits, 14.2ms\n",
            "Speed: 2.7ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 1 ppe-suit, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 8.5ms\n",
            "Speed: 1.3ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 ppe-suit, 8.7ms\n",
            "Speed: 1.2ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 448x640 4 persons, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 1 ppe-suit, 7.9ms\n",
            "Speed: 1.3ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x608 2 glovess, 2 masks, 3 ppe-suits, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 8.8ms\n",
            "Speed: 1.3ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x320 1 gloves, 1 mask, 1 ppe-suit, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 448x640 4 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x608 2 glovess, 2 masks, 3 ppe-suits, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x320 1 gloves, 1 mask, 1 ppe-suit, 8.4ms\n",
            "Speed: 1.6ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x224 2 ppe-suits, 1 ear-protector, 8.2ms\n",
            "Speed: 1.2ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 8.5ms\n",
            "Speed: 1.2ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 448x640 4 persons, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x608 2 glovess, 1 mask, 3 ppe-suits, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x256 (no detections), 12.9ms\n",
            "Speed: 1.2ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 005055_aug_2_aug_1.jpg\n",
            "\n",
            "0: 640x224 1 gloves, 1 ppe-suit, 11.0ms\n",
            "Speed: 1.4ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 448x640 4 persons, 12.5ms\n",
            "Speed: 5.0ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x608 2 glovess, 2 masks, 3 ppe-suits, 1 ear-protector, 12.4ms\n",
            "Speed: 2.9ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x224 1 ppe-suit, 8.3ms\n",
            "Speed: 1.2ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 1 ppe-suit, 8.3ms\n",
            "Speed: 1.5ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x224 1 ppe-suit, 9.1ms\n",
            "Speed: 1.1ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 448x640 5 persons, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x320 1 ppe-suit, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x640 2 glovess, 2 masks, 2 ppe-suits, 9.4ms\n",
            "Speed: 3.4ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 mask, 1 ppe-suit, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x160 1 ppe-suit, 7.9ms\n",
            "Speed: 1.0ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x256 1 gloves, 1 ppe-suit, 8.2ms\n",
            "Speed: 1.4ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 448x640 4 persons, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x576 2 glovess, 2 masks, 3 ppe-suits, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 1 ppe-suit, 7.7ms\n",
            "Speed: 1.6ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 8.8ms\n",
            "Speed: 1.2ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 ppe-suit, 7.9ms\n",
            "Speed: 1.2ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 448x640 5 persons, 7.6ms\n",
            "Speed: 2.5ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x640 2 glovess, 2 masks, 2 ppe-suits, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 (no detections), 7.7ms\n",
            "Speed: 1.7ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 005055_aug_3_aug_0.jpg\n",
            "\n",
            "0: 640x192 (no detections), 11.3ms\n",
            "Speed: 1.0ms preprocess, 11.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 005055_aug_3_aug_0.jpg\n",
            "\n",
            "0: 640x320 1 gloves, 1 mask, 1 ppe-suit, 8.6ms\n",
            "Speed: 1.5ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x128 (no detections), 8.0ms\n",
            "Speed: 0.9ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 005055_aug_3_aug_0.jpg\n",
            "\n",
            "0: 448x640 3 persons, 8.1ms\n",
            "Speed: 2.7ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x640 2 glovess, 1 mask, 3 ppe-suits, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 2 glovess, 1 mask, 1 ppe-suit, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x96 (no detections), 7.7ms\n",
            "Speed: 0.7ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 005055_aug_3_aug_1.jpg\n",
            "\n",
            "0: 448x640 4 persons, 7.3ms\n",
            "Speed: 2.4ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x640 2 glovess, 2 masks, 3 ppe-suits, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 ppe-suit, 7.8ms\n",
            "Speed: 1.1ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x384 1 gloves, 1 mask, 1 ppe-suit, 7.6ms\n",
            "Speed: 1.7ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 7.8ms\n",
            "Speed: 1.3ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 448x640 3 persons, 7.3ms\n",
            "Speed: 2.5ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x544 1 ppe-suit, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 608x640 2 glovess, 1 mask, 1 ppe-suit, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 640x96 (no detections), 12.1ms\n",
            "Speed: 0.6ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 005055_aug_3_aug_3.jpg\n",
            "\n",
            "0: 448x640 2 persons, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 608x640 2 glovess, 3 masks, 2 ppe-suits, 1 ear-protector, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 640x448 1 gloves, 1 mask, 1 ppe-suit, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 448x640 (no detections), 14.3ms\n",
            "Speed: 2.7ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "No persons detected in 005055_aug_4_aug_0.jpg\n",
            "\n",
            "0: 448x640 2 persons, 12.8ms\n",
            "Speed: 2.5ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x640 2 glovess, 1 mask, 3 ppe-suits, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 1 ppe-suit, 8.4ms\n",
            "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 448x640 4 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x608 2 glovess, 2 masks, 3 ppe-suits, 9.8ms\n",
            "Speed: 4.9ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 9.1ms\n",
            "Speed: 1.3ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 1 ppe-suit, 8.4ms\n",
            "Speed: 1.6ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x256 2 ppe-suits, 7.9ms\n",
            "Speed: 1.4ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 448x640 2 persons, 10.6ms\n",
            "Speed: 2.6ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ppe-suit, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x608 1 gloves, 1 mask, 1 ppe-suit, 11.2ms\n",
            "Speed: 2.7ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 448x640 4 persons, 10.5ms\n",
            "Speed: 2.4ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 10.9ms\n",
            "Speed: 1.4ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x608 2 glovess, 2 masks, 3 ppe-suits, 1 ear-protector, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x320 1 gloves, 1 mask, 1 ppe-suit, 8.8ms\n",
            "Speed: 1.5ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x256 1 ppe-suit, 14.4ms\n",
            "Speed: 1.4ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x640 1 person, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x448 1 gloves, 1 mask, 2 vests, 1 ppe-suit, 10.8ms\n",
            "Speed: 2.5ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x640 1 person, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 11.6ms\n",
            "Speed: 1.5ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 12.1ms\n",
            "Speed: 1.5ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 1 person, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 10.5ms\n",
            "Speed: 2.4ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x640 1 person, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 1 mask, 2 vests, 1 ppe-suit, 9.4ms\n",
            "Speed: 1.3ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 1 person, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x640 1 person, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 mask, 2 vests, 1 ppe-suit, 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x640 1 person, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x640 1 person, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 mask, 2 vests, 1 ppe-suit, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x640 1 person, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 gloves, 2 vests, 9.7ms\n",
            "Speed: 3.5ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x480 1 gloves, 2 vests, 1 ppe-suit, 9.3ms\n",
            "Speed: 2.7ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x640 1 person, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 mask, 2 vests, 1 ppe-suit, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x640 1 person, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x480 1 gloves, 2 vests, 1 ppe-suit, 14.9ms\n",
            "Speed: 3.4ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x640 1 person, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x480 1 gloves, 2 vests, 1 ppe-suit, 9.8ms\n",
            "Speed: 2.6ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x640 2 persons, 12.3ms\n",
            "Speed: 1.9ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x608 1 vest, 1 ppe-suit, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 160x640 (no detections), 10.4ms\n",
            "Speed: 0.9ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 160, 640)\n",
            "No PPE detected in cropped image of image_237_jpg.rf.353ad34ef2718e9f9e14f8a21bc5afa6_aug_2_aug_4.jpg\n",
            "\n",
            "0: 640x640 1 person, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x480 1 gloves, 1 mask, 2 vests, 1 ppe-suit, 15.1ms\n",
            "Speed: 3.5ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x640 1 person, 15.3ms\n",
            "Speed: 2.6ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 12.9ms\n",
            "Speed: 1.6ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 1 person, 48.8ms\n",
            "Speed: 2.6ms preprocess, 48.8ms inference, 8.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x256 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 36.6ms\n",
            "Speed: 2.1ms preprocess, 36.6ms inference, 10.6ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x640 1 person, 14.7ms\n",
            "Speed: 2.5ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 2 vests, 1 ppe-suit, 13.7ms\n",
            "Speed: 2.3ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x640 1 person, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 13.8ms\n",
            "Speed: 1.8ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 1 person, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x544 1 gloves, 2 vests, 1 ppe-suit, 14.0ms\n",
            "Speed: 3.7ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x640 1 person, 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 18.0ms\n",
            "Speed: 1.8ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 1 person, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 2 vests, 1 ppe-suit, 14.0ms\n",
            "Speed: 2.6ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x640 1 person, 14.9ms\n",
            "Speed: 2.5ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 2 vests, 1 ppe-suit, 13.8ms\n",
            "Speed: 2.6ms preprocess, 13.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x640 1 person, 14.5ms\n",
            "Speed: 2.9ms preprocess, 14.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 masks, 2 vests, 1 ppe-suit, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 384x640 7 persons, 15.4ms\n",
            "Speed: 2.9ms preprocess, 15.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 14.2ms\n",
            "Speed: 3.0ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x576 2 glovess, 11.1ms\n",
            "Speed: 3.6ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 512x640 1 gloves, 13.6ms\n",
            "Speed: 2.7ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 640x448 2 glovess, 13.4ms\n",
            "Speed: 2.4ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x544 2 glovess, 18.3ms\n",
            "Speed: 3.0ms preprocess, 18.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x416 2 glovess, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 480x640 6 glovess, 14.0ms\n",
            "Speed: 3.1ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 384x640 8 persons, 13.8ms\n",
            "Speed: 2.9ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x288 1 ear-protector, 13.8ms\n",
            "Speed: 1.5ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x384 1 gloves, 15.0ms\n",
            "Speed: 2.1ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x224 (no detections), 14.3ms\n",
            "Speed: 1.4ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 005159_aug_1_aug_1.jpg\n",
            "\n",
            "0: 640x480 1 gloves, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x384 (no detections), 13.5ms\n",
            "Speed: 1.7ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 005159_aug_1_aug_1.jpg\n",
            "\n",
            "0: 640x288 1 gloves, 1 ear-protector, 15.5ms\n",
            "Speed: 1.8ms preprocess, 15.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x544 1 gloves, 14.6ms\n",
            "Speed: 3.1ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x320 1 gloves, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 384x640 7 persons, 13.3ms\n",
            "Speed: 3.0ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x288 1 vest, 14.0ms\n",
            "Speed: 1.7ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x416 1 gloves, 17.6ms\n",
            "Speed: 2.4ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x448 1 gloves, 12.4ms\n",
            "Speed: 2.0ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x544 2 glovess, 14.2ms\n",
            "Speed: 2.9ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x384 1 gloves, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x512 (no detections), 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
            "No PPE detected in cropped image of 005159_aug_1_aug_2.jpg\n",
            "\n",
            "0: 640x384 1 gloves, 11.3ms\n",
            "Speed: 2.3ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 384x640 7 persons, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 1 ear-protector, 14.7ms\n",
            "Speed: 2.2ms preprocess, 14.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x544 2 glovess, 1 ppe-suit, 13.4ms\n",
            "Speed: 2.9ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x352 1 gloves, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x288 1 gloves, 2 vests, 10.2ms\n",
            "Speed: 1.4ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x512 1 gloves, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x416 1 gloves, 10.1ms\n",
            "Speed: 1.7ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x384 1 gloves, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 384x640 7 persons, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 ear-protector, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x352 1 vest, 16.2ms\n",
            "Speed: 1.8ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ear-protector, 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x544 2 glovess, 1 ppe-suit, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x448 2 glovess, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x512 1 gloves, 7.8ms\n",
            "Speed: 1.5ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x512 1 gloves, 7.2ms\n",
            "Speed: 1.4ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 384x640 7 persons, 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 10.9ms\n",
            "Speed: 1.6ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 7.0ms\n",
            "Speed: 0.9ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x352 1 gloves, 6.9ms\n",
            "Speed: 1.1ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x256 1 gloves, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x512 1 gloves, 8.0ms\n",
            "Speed: 1.4ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ppe-suit, 7.3ms\n",
            "Speed: 1.9ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x352 1 gloves, 7.0ms\n",
            "Speed: 1.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 384x640 7 persons, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 7.3ms\n",
            "Speed: 1.1ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 7.2ms\n",
            "Speed: 0.9ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x352 1 gloves, 6.9ms\n",
            "Speed: 1.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x256 1 gloves, 6.5ms\n",
            "Speed: 1.0ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x512 1 gloves, 7.7ms\n",
            "Speed: 1.5ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ppe-suit, 7.1ms\n",
            "Speed: 1.5ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x352 1 gloves, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 384x640 7 persons, 9.7ms\n",
            "Speed: 1.4ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 7.5ms\n",
            "Speed: 1.6ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x512 2 glovess, 1 ppe-suit, 7.7ms\n",
            "Speed: 1.5ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x352 1 gloves, 6.2ms\n",
            "Speed: 1.1ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x288 1 gloves, 1 ear-protector, 6.2ms\n",
            "Speed: 1.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x384 1 gloves, 6.1ms\n",
            "Speed: 1.3ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x480 1 gloves, 6.3ms\n",
            "Speed: 1.3ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 384x640 7 persons, 6.5ms\n",
            "Speed: 2.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 2 vests, 1 ear-protector, 6.9ms\n",
            "Speed: 0.9ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x512 2 glovess, 1 ppe-suit, 6.3ms\n",
            "Speed: 1.5ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x352 1 gloves, 6.2ms\n",
            "Speed: 1.1ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x352 1 gloves, 5.7ms\n",
            "Speed: 1.1ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x384 1 gloves, 6.9ms\n",
            "Speed: 1.1ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x480 1 gloves, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 1 gloves, 6.6ms\n",
            "Speed: 1.4ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 384x640 7 persons, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ppe-suit, 6.7ms\n",
            "Speed: 1.6ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 7.2ms\n",
            "Speed: 0.8ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x288 1 gloves, 6.5ms\n",
            "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 1 gloves, 6.6ms\n",
            "Speed: 0.9ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x512 1 gloves, 8.3ms\n",
            "Speed: 1.4ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x352 1 gloves, 6.6ms\n",
            "Speed: 1.1ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x384 1 gloves, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 384x640 8 persons, 6.5ms\n",
            "Speed: 1.6ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 1 vest, 7.0ms\n",
            "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x544 2 glovess, 1 ppe-suit, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x480 1 gloves, 6.2ms\n",
            "Speed: 1.4ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x512 1 gloves, 6.4ms\n",
            "Speed: 1.5ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x448 1 gloves, 6.2ms\n",
            "Speed: 1.3ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x512 1 gloves, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x544 1 gloves, 8.0ms\n",
            "Speed: 1.5ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x160 1 gloves, 6.0ms\n",
            "Speed: 0.6ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 384x640 7 persons, 6.5ms\n",
            "Speed: 2.0ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x288 1 gloves, 6.6ms\n",
            "Speed: 1.0ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x352 1 gloves, 7.0ms\n",
            "Speed: 1.3ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 6.7ms\n",
            "Speed: 0.9ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 gloves, 1 ear-protector, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ppe-suit, 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x512 1 gloves, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x352 1 gloves, 6.3ms\n",
            "Speed: 1.1ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 384x640 7 persons, 6.5ms\n",
            "Speed: 1.6ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x480 1 gloves, 1 ppe-suit, 6.5ms\n",
            "Speed: 1.6ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x224 1 gloves, 2 vests, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x288 1 gloves, 6.4ms\n",
            "Speed: 1.0ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 1 gloves, 6.4ms\n",
            "Speed: 0.9ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x352 1 gloves, 6.2ms\n",
            "Speed: 1.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x512 1 gloves, 6.9ms\n",
            "Speed: 1.4ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x384 1 gloves, 6.5ms\n",
            "Speed: 1.3ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 384x640 7 persons, 6.3ms\n",
            "Speed: 1.4ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ppe-suit, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x288 1 gloves, 6.7ms\n",
            "Speed: 0.9ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 gloves, 1 vest, 6.2ms\n",
            "Speed: 0.8ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 gloves, 8.9ms\n",
            "Speed: 0.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x512 1 gloves, 6.5ms\n",
            "Speed: 2.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x352 1 gloves, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x384 (no detections), 6.2ms\n",
            "Speed: 1.2ms preprocess, 6.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 005159_aug_3_aug_3.jpg\n",
            "\n",
            "0: 384x640 8 persons, 6.7ms\n",
            "Speed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ppe-suit, 6.7ms\n",
            "Speed: 1.6ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x288 2 glovess, 1 vest, 6.5ms\n",
            "Speed: 0.9ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x448 1 gloves, 1 ear-protector, 6.3ms\n",
            "Speed: 1.5ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x416 1 gloves, 6.3ms\n",
            "Speed: 1.2ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x416 1 gloves, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x384 1 gloves, 1 ear-protector, 6.7ms\n",
            "Speed: 1.3ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x544 1 gloves, 8.1ms\n",
            "Speed: 1.6ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x128 1 gloves, 6.5ms\n",
            "Speed: 0.6ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 384x640 7 persons, 6.6ms\n",
            "Speed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ppe-suit, 6.2ms\n",
            "Speed: 1.4ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x256 1 gloves, 1 ear-protector, 6.4ms\n",
            "Speed: 0.8ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x512 1 gloves, 6.4ms\n",
            "Speed: 1.4ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x192 1 vest, 6.8ms\n",
            "Speed: 0.7ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x352 1 gloves, 6.2ms\n",
            "Speed: 1.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x480 1 gloves, 1 ear-protector, 6.3ms\n",
            "Speed: 1.4ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 384x640 5 persons, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x608 1 gloves, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x448 1 vest, 6.8ms\n",
            "Speed: 1.3ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x608 1 gloves, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x640 2 glovess, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 10.4ms\n",
            "Speed: 1.4ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 384x640 8 persons, 7.0ms\n",
            "Speed: 1.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 6.8ms\n",
            "Speed: 1.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x288 1 gloves, 1 ear-protector, 6.8ms\n",
            "Speed: 1.1ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x512 1 gloves, 6.4ms\n",
            "Speed: 1.4ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x384 1 gloves, 6.4ms\n",
            "Speed: 1.1ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x224 1 vest, 6.1ms\n",
            "Speed: 0.7ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x512 2 glovess, 1 ppe-suit, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x448 1 gloves, 6.2ms\n",
            "Speed: 1.4ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x352 1 gloves, 1 vest, 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 384x640 5 persons, 7.0ms\n",
            "Speed: 2.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x608 1 gloves, 8.2ms\n",
            "Speed: 2.0ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x448 1 vest, 6.6ms\n",
            "Speed: 1.3ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x608 2 glovess, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x608 1 gloves, 7.9ms\n",
            "Speed: 1.7ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x512 1 gloves, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 384x640 6 persons, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 1 vest, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x480 1 gloves, 6.3ms\n",
            "Speed: 1.4ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x512 2 glovess, 6.4ms\n",
            "Speed: 1.5ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x448 1 gloves, 6.4ms\n",
            "Speed: 1.3ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x576 1 gloves, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 512x640 3 glovess, 7.0ms\n",
            "Speed: 1.7ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 416x640 (no detections), 7.0ms\n",
            "Speed: 1.8ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 416, 640)\n",
            "No persons detected in 001990_aug_0_aug_0.jpg\n",
            "\n",
            "0: 416x640 2 persons, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x448 1 gloves, 7.2ms\n",
            "Speed: 2.2ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x256 1 gloves, 6.3ms\n",
            "Speed: 0.9ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 416x640 2 persons, 6.5ms\n",
            "Speed: 1.7ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x256 1 gloves, 8.2ms\n",
            "Speed: 1.2ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 416x640 1 person, 6.8ms\n",
            "Speed: 2.3ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x448 1 gloves, 6.4ms\n",
            "Speed: 1.4ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 416x640 1 person, 7.0ms\n",
            "Speed: 2.0ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 6.8ms\n",
            "Speed: 1.8ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 448x640 3 persons, 7.5ms\n",
            "Speed: 1.8ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ppe-suit, 6.1ms\n",
            "Speed: 1.6ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 608x640 1 gloves, 1 ppe-suit, 7.9ms\n",
            "Speed: 2.0ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 640x192 1 gloves, 6.5ms\n",
            "Speed: 0.8ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 448x640 2 persons, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x576 2 glovess, 1 ppe-suit, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 gloves, 1 ppe-suit, 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 448x640 2 persons, 6.4ms\n",
            "Speed: 2.2ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x576 2 glovess, 1 ppe-suit, 7.5ms\n",
            "Speed: 1.8ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 gloves, 1 ppe-suit, 7.4ms\n",
            "Speed: 1.8ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 448x640 3 persons, 6.6ms\n",
            "Speed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x640 1 gloves, 1 ppe-suit, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 glovess, 1 ppe-suit, 7.9ms\n",
            "Speed: 1.9ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x192 1 gloves, 6.3ms\n",
            "Speed: 0.7ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 448x640 2 persons, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x544 1 gloves, 1 ppe-suit, 8.1ms\n",
            "Speed: 2.0ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x544 1 gloves, 1 ppe-suit, 7.4ms\n",
            "Speed: 1.7ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 416x640 1 person, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x480 1 gloves, 1 ppe-suit, 6.4ms\n",
            "Speed: 1.4ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 416x640 1 person, 6.8ms\n",
            "Speed: 2.0ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 ppe-suit, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 416x640 1 person, 6.4ms\n",
            "Speed: 1.5ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x480 1 gloves, 1 ppe-suit, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 416x640 1 person, 6.7ms\n",
            "Speed: 2.1ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x480 1 gloves, 1 ppe-suit, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 416x640 1 person, 6.2ms\n",
            "Speed: 2.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x608 1 gloves, 1 ppe-suit, 10.8ms\n",
            "Speed: 1.7ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 416x640 1 person, 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 ppe-suit, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 416x640 1 person, 6.0ms\n",
            "Speed: 1.5ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 480x640 1 gloves, 1 ppe-suit, 6.6ms\n",
            "Speed: 1.4ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 416x640 1 person, 6.5ms\n",
            "Speed: 1.6ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x480 1 gloves, 1 ppe-suit, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 416x640 1 person, 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 448x640 1 gloves, 1 ppe-suit, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 416x640 2 persons, 6.3ms\n",
            "Speed: 1.6ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 10.7ms\n",
            "Speed: 1.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x128 (no detections), 12.9ms\n",
            "Speed: 0.9ms preprocess, 12.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 001990_aug_2_aug_4.jpg\n",
            "\n",
            "0: 416x640 2 persons, 6.9ms\n",
            "Speed: 1.7ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x128 (no detections), 9.3ms\n",
            "Speed: 1.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 001990_aug_3_aug_0.jpg\n",
            "\n",
            "0: 416x640 1 person, 6.6ms\n",
            "Speed: 1.6ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ppe-suit, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 416x640 1 person, 6.8ms\n",
            "Speed: 1.8ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 6.7ms\n",
            "Speed: 1.8ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 416x640 1 person, 7.1ms\n",
            "Speed: 2.2ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ear-protector, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 416x640 1 person, 6.4ms\n",
            "Speed: 1.6ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 544x640 1 gloves, 8.0ms\n",
            "Speed: 1.6ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 448x640 2 persons, 7.1ms\n",
            "Speed: 2.2ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ppe-suit, 6.2ms\n",
            "Speed: 1.4ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x480 1 gloves, 1 ppe-suit, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 448x640 2 persons, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ppe-suit, 6.2ms\n",
            "Speed: 1.3ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x384 1 gloves, 1 ppe-suit, 6.2ms\n",
            "Speed: 1.4ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 448x640 2 persons, 6.2ms\n",
            "Speed: 1.8ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ppe-suit, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ppe-suit, 5.7ms\n",
            "Speed: 1.6ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 448x640 2 persons, 6.0ms\n",
            "Speed: 1.6ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 6.4ms\n",
            "Speed: 1.3ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x352 1 gloves, 1 ppe-suit, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 448x640 2 persons, 6.7ms\n",
            "Speed: 3.0ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ppe-suit, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x608 1 gloves, 1 ppe-suit, 8.0ms\n",
            "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 416x640 1 person, 7.1ms\n",
            "Speed: 2.3ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x608 1 gloves, 7.7ms\n",
            "Speed: 1.9ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 416x640 1 person, 6.6ms\n",
            "Speed: 2.1ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 7.1ms\n",
            "Speed: 1.2ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 416x640 3 persons, 6.8ms\n",
            "Speed: 2.1ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x320 1 gloves, 7.1ms\n",
            "Speed: 1.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x160 (no detections), 6.6ms\n",
            "Speed: 0.8ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001990_aug_4_aug_2.jpg\n",
            "\n",
            "0: 640x192 1 gloves, 1 ear-protector, 6.9ms\n",
            "Speed: 0.8ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 416x640 1 person, 6.6ms\n",
            "Speed: 2.2ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 ppe-suit, 6.6ms\n",
            "Speed: 1.3ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 416x640 1 person, 7.1ms\n",
            "Speed: 2.1ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x480 1 gloves, 6.7ms\n",
            "Speed: 1.9ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 448x640 2 persons, 7.3ms\n",
            "Speed: 2.2ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 ppe-suit, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ppe-suit, 6.7ms\n",
            "Speed: 1.3ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 448x640 2 persons, 6.5ms\n",
            "Speed: 2.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ppe-suit, 6.1ms\n",
            "Speed: 1.3ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x384 1 gloves, 1 ppe-suit, 8.5ms\n",
            "Speed: 1.3ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 448x640 2 persons, 6.5ms\n",
            "Speed: 1.9ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x512 1 gloves, 1 ppe-suit, 7.3ms\n",
            "Speed: 1.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x576 2 glovess, 1 ppe-suit, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 448x640 2 persons, 6.5ms\n",
            "Speed: 1.8ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ppe-suit, 6.9ms\n",
            "Speed: 1.4ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x448 1 gloves, 1 ppe-suit, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 448x640 2 persons, 6.4ms\n",
            "Speed: 1.9ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ppe-suit, 7.3ms\n",
            "Speed: 1.5ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x448 1 gloves, 1 ppe-suit, 6.3ms\n",
            "Speed: 1.4ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 448x640 2 persons, 6.3ms\n",
            "Speed: 1.7ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x480 1 gloves, 1 ppe-suit, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 gloves, 1 ppe-suit, 5.9ms\n",
            "Speed: 1.5ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 448x640 2 persons, 6.4ms\n",
            "Speed: 1.7ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ppe-suit, 6.4ms\n",
            "Speed: 1.3ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ppe-suit, 5.7ms\n",
            "Speed: 1.4ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 448x640 2 persons, 6.3ms\n",
            "Speed: 2.2ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x576 2 glovess, 1 ppe-suit, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 gloves, 1 ppe-suit, 7.4ms\n",
            "Speed: 1.8ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 448x640 2 persons, 6.4ms\n",
            "Speed: 2.2ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x608 2 glovess, 1 ppe-suit, 8.6ms\n",
            "Speed: 1.9ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x576 1 gloves, 1 ppe-suit, 8.3ms\n",
            "Speed: 1.8ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 448x640 2 persons, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x576 2 glovess, 1 ppe-suit, 7.5ms\n",
            "Speed: 2.4ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 gloves, 1 ppe-suit, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 448x640 2 persons, 6.9ms\n",
            "Speed: 1.9ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x608 2 glovess, 1 ppe-suit, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x576 1 gloves, 1 ppe-suit, 11.7ms\n",
            "Speed: 2.6ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 448x640 2 persons, 7.4ms\n",
            "Speed: 1.7ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 ppe-suit, 6.7ms\n",
            "Speed: 1.4ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x416 1 gloves, 6.3ms\n",
            "Speed: 1.3ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 448x640 2 persons, 6.1ms\n",
            "Speed: 1.7ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ppe-suit, 6.0ms\n",
            "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x384 1 gloves, 1 ppe-suit, 6.4ms\n",
            "Speed: 1.3ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 448x640 2 persons, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 gloves, 1 ppe-suit, 6.4ms\n",
            "Speed: 1.3ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x384 1 gloves, 1 ppe-suit, 6.4ms\n",
            "Speed: 1.3ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 448x640 2 persons, 6.2ms\n",
            "Speed: 1.7ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x576 2 glovess, 1 ppe-suit, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x544 1 gloves, 1 ppe-suit, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x640 1 person, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 gloves, 8.4ms\n",
            "Speed: 2.6ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 8.2ms\n",
            "Speed: 1.5ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x224 1 gloves, 2 masks, 1 ppe-suit, 6.7ms\n",
            "Speed: 1.0ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 (no detections), 7.7ms\n",
            "Speed: 1.4ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in images-2022-07-04T013042_jpg.rf.b978dadc52cedd1622e4ef2c8cd1489d_aug_0_aug_2.jpg\n",
            "\n",
            "0: 640x640 (no detections), 7.6ms\n",
            "Speed: 2.1ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in images-2022-07-04T013042_jpg.rf.b978dadc52cedd1622e4ef2c8cd1489d_aug_0_aug_3.jpg\n",
            "\n",
            "0: 640x640 (no detections), 7.5ms\n",
            "Speed: 1.6ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in images-2022-07-04T013042_jpg.rf.b978dadc52cedd1622e4ef2c8cd1489d_aug_0_aug_4.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.5ms\n",
            "Speed: 1.4ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 mask, 1 ppe-suit, 10.5ms\n",
            "Speed: 1.4ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x640 (no detections), 7.6ms\n",
            "Speed: 1.5ms preprocess, 7.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No persons detected in images-2022-07-04T013042_jpg.rf.b978dadc52cedd1622e4ef2c8cd1489d_aug_1_aug_1.jpg\n",
            "\n",
            "0: 640x640 1 person, 7.8ms\n",
            "Speed: 1.8ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 2 masks, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x640 1 person, 7.9ms\n",
            "Speed: 1.5ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x352 1 gloves, 1 mask, 6.4ms\n",
            "Speed: 1.4ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x640 1 person, 7.7ms\n",
            "Speed: 1.7ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x384 1 gloves, 1 mask, 7.5ms\n",
            "Speed: 1.6ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/Syook/inference.py /content/drive/MyDrive/Syook/datasets /content/results /content/drive/MyDrive/Syook/weights/yolov8_person_detection/weights/best.pt /content/drive/MyDrive/Syook/weights/yolov8_ppe_detection/weights/best.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqSpw-wM6wOD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0zNNlskYSyOg",
        "outputId": "cfc0a2eb-5f92-44da-cc08-16a4b22a60f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.2.82 🚀 Python-3.10.12 torch-2.4.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/drive/MyDrive/Syook/person_detection.yaml, epochs=200, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolov8_person_detection2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8_person_detection2\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
            "Model summary: 225 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolov8_person_detection2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py:268: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1G6XwMABU-R-y_mct2BbnuWg3F_uHx6_-/Syook/datasets/partitioned/train/labels... 10 images, 0 backgrounds, 0 corrupt: 100%|██████████| 10/10 [00:00<00:00, 81.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1G6XwMABU-R-y_mct2BbnuWg3F_uHx6_-/Syook/datasets/partitioned/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "\u001b[34m\u001b[1mval: \u001b[0mError loading data from /content/drive/.shortcut-targets-by-id/1G6XwMABU-R-y_mct2BbnuWg3F_uHx6_-/Syook/datasets/partitioned/val/images\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36mget_img_files\u001b[0;34m(self, img_path)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS])  # pathlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mim_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{self.prefix}No images found in {img_path}. {FORMATS_HELP_MSG}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \u001b[34m\u001b[1mval: \u001b[0mNo images found in /content/drive/.shortcut-targets-by-id/1G6XwMABU-R-y_mct2BbnuWg3F_uHx6_-/Syook/datasets/partitioned/val/images. Supported formats are:\nimages: {'tif', 'tiff', 'png', 'pfm', 'jpg', 'webp', 'dng', 'bmp', 'jpeg', 'mpo'}\nvideos: {'mov', 'mp4', 'mpeg', 'gif', 'webm', 'avi', 'mkv', 'm4v', 'mpg', 'wmv', 'asf', 'ts'}",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-bb0d06900670>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m model.train(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Syook/person_detection.yaml'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# path to the dataset config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0;31m# total number of epochs you want to train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;31m# Note: When training DOTA dataset, double batch size could get OOM on images with >2000 objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             self.test_loader = self.get_dataloader(\n\u001b[0m\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"obb\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Mode must be 'train' or 'val', not {mode}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# init dataset *.cache only once if DDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \"\"\"\n\u001b[1;32m     42\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_yolo_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mbuild_yolo_dataset\u001b[0;34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;34m\"\"\"Build YOLO Dataset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLOMultiModalDataset\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmulti_modal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mYOLODataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     return dataset(\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, task, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_segments\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_keypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Can not use both segments and keypoints.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcache_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./labels.cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_img_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# single_cls and include_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36mget_img_files\u001b[0;34m(self, img_path)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mim_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{self.prefix}No images found in {img_path}. {FORMATS_HELP_MSG}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.prefix}Error loading data from {img_path}\\n{HELP_URL}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfraction\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# retain a fraction of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: \u001b[34m\u001b[1mval: \u001b[0mError loading data from /content/drive/.shortcut-targets-by-id/1G6XwMABU-R-y_mct2BbnuWg3F_uHx6_-/Syook/datasets/partitioned/val/images\nSee https://docs.ultralytics.com/datasets for dataset formatting guidance."
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a YOLOv8 model (YOLOv8s in this case)\n",
        "model = YOLO('yolov8s.pt')\n",
        "\n",
        "# Train the model\n",
        "model.train(\n",
        "    data='person_detection.yaml',  # path to the dataset config file\n",
        "    epochs=200,                    # total number of epochs you want to train\n",
        "    imgsz=640,                     # image size for training\n",
        "    batch=16,                      # batch size\n",
        "    name='yolov8_person_detection',# name of the training session\n",
        "\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USaa3MMj12FL",
        "outputId": "04f55e54-75ee-4edb-e3a2-805ae11a4282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\\\hello\n"
          ]
        }
      ],
      "source": [
        "print(\"\\\\\\\\hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfGiLZKq14a7"
      },
      "outputs": [],
      "source": [
        "! rm -r runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9qRxSuEieD1",
        "outputId": "57916536-c811-46f3-95c0-5fecefcbc0ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 640x448 2 persons, 44.9ms\n",
            "Speed: 5.1ms preprocess, 44.9ms inference, 587.3ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[226.3017,  92.2671, 637.7177, 951.5977],\n",
            "        [ 68.7315,  82.9683, 560.8398, 959.0000]], device='cuda:0')\n",
            "001951_person_0.jpg\n",
            "001951_person_1.jpg\n",
            "\n",
            "0: 640x448 2 persons, 11.9ms\n",
            "Speed: 4.4ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[ 83.4625, 117.3235, 122.7768, 221.8815],\n",
            "        [ 59.2974, 123.8986,  94.8665, 223.7171]], device='cuda:0')\n",
            "001451_person_0.jpg\n",
            "001451_person_1.jpg\n",
            "\n",
            "0: 416x640 1 person, 40.1ms\n",
            "Speed: 2.7ms preprocess, 40.1ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[145.7556, 149.0988, 228.7084, 224.7316]], device='cuda:0')\n",
            "001242_person_0.jpg\n",
            "\n",
            "0: 640x448 3 persons, 12.7ms\n",
            "Speed: 3.5ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[357.7787, 494.3582, 492.6126, 960.0000],\n",
            "        [ 58.2754, 445.4326, 206.0511, 856.8214],\n",
            "        [128.9772, 513.8921, 355.5239, 840.0179]], device='cuda:0')\n",
            "001059_person_0.jpg\n",
            "001059_person_1.jpg\n",
            "001059_person_2.jpg\n",
            "\n",
            "0: 448x640 2 persons, 39.4ms\n",
            "Speed: 3.6ms preprocess, 39.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[  0.0000, 164.5451, 341.3173, 397.7030],\n",
            "        [464.7197,  92.7476, 581.2424, 342.9554]], device='cuda:0')\n",
            "001060_person_0.jpg\n",
            "001060_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.0ms\n",
            "Speed: 2.3ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[171.7613,  67.5465, 459.2823, 422.7434],\n",
            "        [ 88.3359,  56.5702, 316.6129, 425.6238]], device='cuda:0')\n",
            "001321_person_0.jpg\n",
            "001321_person_1.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[197.2093,   0.0000, 638.6311, 423.0447]], device='cuda:0')\n",
            "001727_person_0.jpg\n",
            "\n",
            "0: 640x480 2 persons, 39.0ms\n",
            "Speed: 3.2ms preprocess, 39.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "tensor([[226.5444, 262.3213, 362.0032, 832.1123],\n",
            "        [ 20.2577, 241.0178, 282.1161, 791.0173]], device='cuda:0')\n",
            "001809_person_0.jpg\n",
            "001809_person_1.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.7ms\n",
            "Speed: 2.6ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[  8.3030,  64.0877,  99.9021, 332.0000],\n",
            "        [360.7545,  75.4324, 458.2926, 331.3987],\n",
            "        [110.3976,  71.3770, 196.6405, 332.0000],\n",
            "        [199.9327,  74.7157, 278.4095, 332.0000],\n",
            "        [279.9427,  90.7103, 362.8359, 330.5755]], device='cuda:0')\n",
            "001597_person_0.jpg\n",
            "001597_person_1.jpg\n",
            "001597_person_2.jpg\n",
            "001597_person_3.jpg\n",
            "001597_person_4.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 3.2ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 85.0840,  62.7765, 313.6000, 333.3593]], device='cuda:0')\n",
            "001295_person_0.jpg\n",
            "\n",
            "0: 544x640 2 persons, 41.1ms\n",
            "Speed: 3.7ms preprocess, 41.1ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
            "tensor([[254.9118,  88.8352, 408.3298, 422.2754],\n",
            "        [277.9944, 106.9996, 479.9708, 419.0934]], device='cuda:0')\n",
            "001037_person_0.jpg\n",
            "001037_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.8ms\n",
            "Speed: 3.3ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[  0.5198,  68.9728, 205.5588, 331.6927],\n",
            "        [293.2797, 110.8775, 409.4536, 332.5852],\n",
            "        [295.9846,   1.8852, 499.9502, 330.1869]], device='cuda:0')\n",
            "001893_person_0.jpg\n",
            "001893_person_1.jpg\n",
            "001893_person_2.jpg\n",
            "\n",
            "0: 448x640 4 persons, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[163.6615,  45.9117, 336.6752, 299.6313],\n",
            "        [ 44.2582,  25.1287, 189.4859, 272.2081],\n",
            "        [309.9659,  65.1160, 430.7041, 297.6042],\n",
            "        [162.9272,  49.4444, 258.8110, 292.6280]], device='cuda:0')\n",
            "001628_person_0.jpg\n",
            "001628_person_1.jpg\n",
            "001628_person_2.jpg\n",
            "001628_person_3.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 3.4ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 54.7580,  60.9566, 290.7924, 332.9828]], device='cuda:0')\n",
            "001738_person_0.jpg\n",
            "\n",
            "0: 448x640 2 persons, 14.5ms\n",
            "Speed: 3.9ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[205.3749,   2.3259, 500.0000, 330.8395],\n",
            "        [157.1601, 204.8978, 214.0627, 260.8116]], device='cuda:0')\n",
            "001487_person_0.jpg\n",
            "001487_person_1.jpg\n",
            "\n",
            "0: 640x448 1 person, 12.7ms\n",
            "Speed: 3.8ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[212.7612,   0.0000, 500.0000, 749.0000]], device='cuda:0')\n",
            "001846_person_0.jpg\n",
            "\n",
            "0: 640x480 1 person, 15.1ms\n",
            "Speed: 3.9ms preprocess, 15.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "tensor([[ 14.7950,  73.3454, 500.0000, 663.6088]], device='cuda:0')\n",
            "001686_person_0.jpg\n",
            "\n",
            "0: 448x640 2 persons, 14.2ms\n",
            "Speed: 2.8ms preprocess, 14.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[101.2326,  90.5174, 195.3579, 299.0617],\n",
            "        [179.5416,  24.6840, 334.8925, 298.2462]], device='cuda:0')\n",
            "001812_person_0.jpg\n",
            "001812_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.1ms\n",
            "Speed: 5.0ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[323.4881,  20.0687, 499.3203, 332.6134],\n",
            "        [175.9302,  62.9681, 336.7082, 331.6198]], device='cuda:0')\n",
            "001213_person_0.jpg\n",
            "001213_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 12.9ms\n",
            "Speed: 3.1ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[200.1327,  61.2666, 315.8890, 299.8564],\n",
            "        [ 80.6413,  66.3604, 180.5449, 299.2097]], device='cuda:0')\n",
            "001842_person_0.jpg\n",
            "001842_person_1.jpg\n",
            "\n",
            "0: 448x640 9 persons, 13.1ms\n",
            "Speed: 4.1ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[202.4365, 148.3364, 302.0244, 297.5738],\n",
            "        [ 21.3629,  86.8943,  79.4172, 288.6518],\n",
            "        [119.0088, 124.2484, 200.5750, 286.7405],\n",
            "        [195.6042,  87.0571, 234.2150, 255.2761],\n",
            "        [218.6796, 102.7783, 262.5417, 273.6555],\n",
            "        [168.2872,  92.9435, 211.4913, 260.8777],\n",
            "        [218.6223, 102.3427, 262.6812, 182.8208],\n",
            "        [141.0026,  89.5679, 181.3311, 265.5197],\n",
            "        [166.9207, 123.9284, 204.8948, 272.6915]], device='cuda:0')\n",
            "001910_person_0.jpg\n",
            "001910_person_1.jpg\n",
            "001910_person_2.jpg\n",
            "001910_person_3.jpg\n",
            "001910_person_4.jpg\n",
            "001910_person_5.jpg\n",
            "001910_person_6.jpg\n",
            "001910_person_7.jpg\n",
            "001910_person_8.jpg\n",
            "\n",
            "0: 640x448 2 persons, 12.6ms\n",
            "Speed: 1.8ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[ 45.1070,   7.3478, 174.9538, 282.8845],\n",
            "        [  1.5977, 105.7148, 101.6880, 280.9626]], device='cuda:0')\n",
            "001331_person_0.jpg\n",
            "001331_person_1.jpg\n",
            "\n",
            "0: 640x448 3 persons, 11.9ms\n",
            "Speed: 3.6ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[297.2312, 359.9084, 460.4385, 562.2527],\n",
            "        [328.6103,  86.7006, 417.9611, 236.5439],\n",
            "        [121.1997, 425.5139, 238.8365, 543.7935]], device='cuda:0')\n",
            "001092_person_0.jpg\n",
            "001092_person_1.jpg\n",
            "001092_person_2.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.9ms\n",
            "Speed: 2.6ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[204.8171,  27.2529, 337.9175, 221.6994]], device='cuda:0')\n",
            "001190_person_0.jpg\n",
            "\n",
            "0: 448x640 8 persons, 12.9ms\n",
            "Speed: 3.3ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[  0.7253, 104.0914, 122.5537, 333.9688],\n",
            "        [365.1670,  95.4244, 416.5281, 266.3077],\n",
            "        [300.4025,  91.5966, 358.1203, 310.8466],\n",
            "        [262.7407, 104.4679, 317.8941, 286.6380],\n",
            "        [ 98.2637,  90.1666, 178.5886, 333.4110],\n",
            "        [183.4380, 107.6540, 243.8989, 292.7500],\n",
            "        [339.6754, 114.2850, 389.6093, 289.0845],\n",
            "        [145.7270, 115.5810, 200.2026, 321.0419]], device='cuda:0')\n",
            "001222_person_0.jpg\n",
            "001222_person_1.jpg\n",
            "001222_person_2.jpg\n",
            "001222_person_3.jpg\n",
            "001222_person_4.jpg\n",
            "001222_person_5.jpg\n",
            "001222_person_6.jpg\n",
            "001222_person_7.jpg\n",
            "\n",
            "0: 608x640 5 persons, 55.1ms\n",
            "Speed: 4.1ms preprocess, 55.1ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 640)\n",
            "tensor([[218.1703, 106.8783, 282.1848, 255.0600],\n",
            "        [ 82.9384, 108.8209, 147.7479, 253.9662],\n",
            "        [354.7558,  60.1868, 417.7041, 261.9049],\n",
            "        [  7.4584, 111.7495,  73.3976, 249.9196],\n",
            "        [403.3197,  70.1225, 443.0000, 260.7998]], device='cuda:0')\n",
            "001365_person_0.jpg\n",
            "001365_person_1.jpg\n",
            "001365_person_2.jpg\n",
            "001365_person_3.jpg\n",
            "001365_person_4.jpg\n",
            "\n",
            "0: 480x640 7 persons, 46.1ms\n",
            "Speed: 2.0ms preprocess, 46.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[2.4063e+02, 1.6924e+02, 2.9505e+02, 3.3518e+02],\n",
            "        [1.1450e+02, 1.6652e+02, 1.9384e+02, 3.7497e+02],\n",
            "        [4.7320e-02, 1.5926e+02, 5.3243e+01, 3.7500e+02],\n",
            "        [2.9968e+02, 1.7349e+02, 3.4963e+02, 3.1570e+02],\n",
            "        [3.7952e+02, 1.6883e+02, 4.2400e+02, 3.0666e+02],\n",
            "        [3.4135e+02, 1.7171e+02, 3.7382e+02, 2.8780e+02],\n",
            "        [4.6518e+02, 1.7508e+02, 4.9994e+02, 3.0693e+02]], device='cuda:0')\n",
            "001096_person_0.jpg\n",
            "001096_person_1.jpg\n",
            "001096_person_2.jpg\n",
            "001096_person_3.jpg\n",
            "001096_person_4.jpg\n",
            "001096_person_5.jpg\n",
            "001096_person_6.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.9ms\n",
            "Speed: 2.9ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[100.2575,  44.1011, 163.9080, 200.2289],\n",
            "        [ 47.6096,  50.4222,  89.3422,  96.8275]], device='cuda:0')\n",
            "001224_person_0.jpg\n",
            "001224_person_1.jpg\n",
            "\n",
            "0: 640x480 2 persons, 12.9ms\n",
            "Speed: 3.7ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "tensor([[230.2696,   1.3799, 392.6253, 500.1966],\n",
            "        [446.3885,  57.8569, 500.0000, 269.0638]], device='cuda:0')\n",
            "001631_person_0.jpg\n",
            "001631_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.7ms\n",
            "Speed: 4.2ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[143.7030,  22.2953, 360.1281, 335.0000],\n",
            "        [130.9344,  44.2890, 213.0273, 266.2181],\n",
            "        [190.3601,  53.4952, 219.7569, 198.6609]], device='cuda:0')\n",
            "001989_person_0.jpg\n",
            "001989_person_1.jpg\n",
            "001989_person_2.jpg\n",
            "\n",
            "0: 640x512 2 persons, 44.0ms\n",
            "Speed: 3.2ms preprocess, 44.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
            "tensor([[  0.0000,  36.0877, 189.7794, 527.8434],\n",
            "        [165.1622,  41.2194, 452.0277, 597.0225]], device='cuda:0')\n",
            "001291_person_0.jpg\n",
            "001291_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.9ms\n",
            "Speed: 3.5ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[362.0222, 155.0177, 600.0000, 398.8446],\n",
            "        [ 52.9383,  42.5296, 348.0993, 397.3694]], device='cuda:0')\n",
            "005242_person_0.jpg\n",
            "005242_person_1.jpg\n",
            "\n",
            "0: 640x640 2 persons, 17.4ms\n",
            "Speed: 4.6ms preprocess, 17.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 10.8012, 250.1001, 263.0713, 449.2184],\n",
            "        [229.7484, 192.9484, 448.5638, 448.8519]], device='cuda:0')\n",
            "005212_person_0.jpg\n",
            "005212_person_1.jpg\n",
            "\n",
            "0: 448x640 1 person, 14.0ms\n",
            "Speed: 2.9ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[305.3230,  61.7464, 438.3438, 332.9803]], device='cuda:0')\n",
            "005166_person_0.jpg\n",
            "\n",
            "0: 512x640 3 persons, 52.3ms\n",
            "Speed: 4.0ms preprocess, 52.3ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "tensor([[160.4868, 121.6436, 270.6591, 386.0000],\n",
            "        [371.2704, 132.0430, 499.4345, 382.6932],\n",
            "        [ 79.4539, 185.8292, 127.8684, 293.2745]], device='cuda:0')\n",
            "005009_person_0.jpg\n",
            "005009_person_1.jpg\n",
            "005009_person_2.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.6ms\n",
            "Speed: 2.6ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[215.4351,  33.5425, 390.1624, 263.0000],\n",
            "        [  0.0000,   8.7646, 173.7356, 263.0000]], device='cuda:0')\n",
            "005012_person_0.jpg\n",
            "005012_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.0ms\n",
            "Speed: 3.2ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[172.8138,  39.7764, 248.7913, 198.6800],\n",
            "        [ 36.5606,  26.0652, 122.1151, 198.7723],\n",
            "        [ 94.4376,  40.3928, 141.8125, 198.5862]], device='cuda:0')\n",
            "005003_person_0.jpg\n",
            "005003_person_1.jpg\n",
            "005003_person_2.jpg\n",
            "\n",
            "0: 480x640 3 persons, 14.1ms\n",
            "Speed: 3.1ms preprocess, 14.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[332.1714, 121.1956, 385.9619, 300.0000],\n",
            "        [226.7836, 156.0666, 256.5484, 206.8820],\n",
            "        [307.4196, 126.4878, 350.8292, 300.0000]], device='cuda:0')\n",
            "005219_person_0.jpg\n",
            "005219_person_1.jpg\n",
            "005219_person_2.jpg\n",
            "\n",
            "0: 640x544 1 person, 42.3ms\n",
            "Speed: 4.5ms preprocess, 42.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
            "tensor([[ 82.2124, 186.4036, 363.6074, 613.0000]], device='cuda:0')\n",
            "005222_person_0.jpg\n",
            "\n",
            "0: 640x640 4 persons, 17.2ms\n",
            "Speed: 4.5ms preprocess, 17.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 42.8741, 229.1940, 226.5093, 491.4110],\n",
            "        [227.8080, 181.8395, 304.0407, 389.9954],\n",
            "        [122.1894, 145.5435, 214.7223, 271.8156],\n",
            "        [308.9021, 117.3872, 466.0660, 357.3808]], device='cuda:0')\n",
            "005154_person_0.jpg\n",
            "005154_person_1.jpg\n",
            "005154_person_2.jpg\n",
            "005154_person_3.jpg\n",
            "\n",
            "0: 416x640 2 persons, 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[199.0418,  85.2132, 238.2899, 168.9241],\n",
            "        [126.7245, 105.5820, 183.3841, 184.3197]], device='cuda:0')\n",
            "001969_person_0.jpg\n",
            "001969_person_1.jpg\n",
            "\n",
            "0: 448x640 4 persons, 14.1ms\n",
            "Speed: 3.1ms preprocess, 14.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[212.2270, 223.3913, 225.2353, 255.9809],\n",
            "        [362.8125, 185.0403, 400.0000, 265.3360],\n",
            "        [287.8134, 219.4246, 305.0197, 257.5466],\n",
            "        [318.1918,  96.8434, 340.5911, 155.4891]], device='cuda:0')\n",
            "001338_person_0.jpg\n",
            "001338_person_1.jpg\n",
            "001338_person_2.jpg\n",
            "001338_person_3.jpg\n",
            "\n",
            "0: 480x640 3 persons, 14.3ms\n",
            "Speed: 3.9ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[262.0979,  66.7034, 405.5360, 208.6492],\n",
            "        [231.9554,  29.0557, 285.4058,  91.1850],\n",
            "        [ 31.7437,   9.9687, 104.5160,  76.8700]], device='cuda:0')\n",
            "001509_person_0.jpg\n",
            "001509_person_1.jpg\n",
            "001509_person_2.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.7ms\n",
            "Speed: 3.1ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[269.1685,  55.4311, 383.5589, 290.3014],\n",
            "        [ 74.1663, 118.2880, 158.6638, 205.8145]], device='cuda:0')\n",
            "001397_person_0.jpg\n",
            "001397_person_1.jpg\n",
            "\n",
            "0: 416x640 4 persons, 13.5ms\n",
            "Speed: 3.1ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[369.6713, 125.8377, 450.7757, 198.9971],\n",
            "        [165.0675,  35.2676, 457.9241, 314.0000],\n",
            "        [413.2856, 103.8500, 456.0142, 196.0771],\n",
            "        [ 95.4763, 137.7858, 136.0270, 184.3199]], device='cuda:0')\n",
            "001747_person_0.jpg\n",
            "001747_person_1.jpg\n",
            "001747_person_2.jpg\n",
            "001747_person_3.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.8ms\n",
            "Speed: 2.3ms preprocess, 13.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[108.3614,  89.2282, 222.2193, 279.8647],\n",
            "        [333.2997,  61.5292, 400.1234, 241.3852],\n",
            "        [466.6364, 151.9525, 500.0000, 217.9767]], device='cuda:0')\n",
            "001054_person_0.jpg\n",
            "001054_person_1.jpg\n",
            "001054_person_2.jpg\n",
            "\n",
            "0: 448x640 6 persons, 13.0ms\n",
            "Speed: 3.0ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[1.6109e+02, 1.4520e+02, 2.4182e+02, 2.0586e+02],\n",
            "        [2.1807e+02, 1.3603e+02, 2.5155e+02, 2.0536e+02],\n",
            "        [7.4245e+01, 1.4007e+02, 1.5259e+02, 2.0576e+02],\n",
            "        [2.8605e-01, 1.2118e+02, 3.6599e+01, 1.7611e+02],\n",
            "        [2.4214e+02, 1.3490e+02, 3.0997e+02, 2.0565e+02],\n",
            "        [0.0000e+00, 1.2139e+02, 1.5093e+02, 2.0600e+02]], device='cuda:0')\n",
            "001702_person_0.jpg\n",
            "001702_person_1.jpg\n",
            "001702_person_2.jpg\n",
            "001702_person_3.jpg\n",
            "001702_person_4.jpg\n",
            "001702_person_5.jpg\n",
            "\n",
            "0: 640x416 1 person, 40.8ms\n",
            "Speed: 2.8ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 416)\n",
            "tensor([[ 28.1612,  68.4539,  98.9719, 288.4536]], device='cuda:0')\n",
            "001320_person_0.jpg\n",
            "\n",
            "0: 448x640 3 persons, 14.0ms\n",
            "Speed: 2.6ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 17.9131,   5.5526, 296.9887, 333.0000],\n",
            "        [256.5246,   0.0000, 500.0000, 332.8602],\n",
            "        [212.0898,   0.0000, 349.8732, 331.7216]], device='cuda:0')\n",
            "005145_person_0.jpg\n",
            "005145_person_1.jpg\n",
            "005145_person_2.jpg\n",
            "\n",
            "0: 480x640 3 persons, 13.9ms\n",
            "Speed: 3.2ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[ 87.7614,  54.6289, 283.1006, 273.1839],\n",
            "        [161.4712, 103.5832, 252.3740, 223.4903],\n",
            "        [ 87.6379, 100.1390, 254.2635, 230.4823]], device='cuda:0')\n",
            "005284_person_0.jpg\n",
            "005284_person_1.jpg\n",
            "005284_person_2.jpg\n",
            "\n",
            "0: 512x640 2 persons, 14.2ms\n",
            "Speed: 3.2ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "tensor([[179.5106, 223.5642, 236.1224, 350.2472],\n",
            "        [374.8460, 358.0270, 423.5849, 391.0000]], device='cuda:0')\n",
            "001152_person_0.jpg\n",
            "001152_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.8ms\n",
            "Speed: 3.2ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[188.0562,  80.1068, 362.5648, 331.8022],\n",
            "        [320.5495, 127.6683, 385.1539, 227.0173]], device='cuda:0')\n",
            "001418_person_0.jpg\n",
            "001418_person_1.jpg\n",
            "\n",
            "0: 512x640 1 person, 14.1ms\n",
            "Speed: 3.0ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "tensor([[4.9663e+01, 3.1616e-01, 4.3021e+02, 3.3592e+02]], device='cuda:0')\n",
            "001083_person_0.jpg\n",
            "\n",
            "0: 448x640 2 persons, 14.1ms\n",
            "Speed: 3.8ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[286.5251, 158.4712, 343.2581, 314.8901],\n",
            "        [216.1146, 156.3840, 260.1037, 314.6120]], device='cuda:0')\n",
            "001280_person_0.jpg\n",
            "001280_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.1ms\n",
            "Speed: 3.8ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 39.2354,  73.1894, 199.4104, 291.1650],\n",
            "        [384.4387,  30.8745, 499.9653, 333.0000],\n",
            "        [362.3996, 136.8546, 447.3071, 268.4987]], device='cuda:0')\n",
            "001836_person_0.jpg\n",
            "001836_person_1.jpg\n",
            "001836_person_2.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[  1.5490, 190.0340, 191.3021, 331.7631],\n",
            "        [206.8525, 205.6944, 341.4297, 331.0797]], device='cuda:0')\n",
            "001297_person_0.jpg\n",
            "001297_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.0ms\n",
            "Speed: 4.2ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[287.4630,  40.3408, 378.4211, 227.7975],\n",
            "        [176.9700,  43.1736, 279.9314, 233.7285],\n",
            "        [ 70.0259,  46.4805, 175.8382, 235.1221]], device='cuda:0')\n",
            "005141_person_0.jpg\n",
            "005141_person_1.jpg\n",
            "005141_person_2.jpg\n",
            "\n",
            "0: 640x384 3 persons, 42.4ms\n",
            "Speed: 3.1ms preprocess, 42.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "tensor([[325.3035, 355.3823, 483.2537, 720.9351],\n",
            "        [  5.0798, 232.1621, 109.9669, 620.5697],\n",
            "        [ 72.9764, 133.5772, 334.5916, 886.5667]], device='cuda:0')\n",
            "005278_person_0.jpg\n",
            "005278_person_1.jpg\n",
            "005278_person_2.jpg\n",
            "\n",
            "0: 416x640 1 person, 13.6ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[159.3829,  75.2665, 281.1708, 291.4842]], device='cuda:0')\n",
            "001442_person_0.jpg\n",
            "\n",
            "0: 416x640 2 persons, 12.6ms\n",
            "Speed: 2.5ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[219.3533, 105.8113, 304.8472, 204.7252],\n",
            "        [150.4128,  85.6765, 240.2364, 194.2950]], device='cuda:0')\n",
            "001611_person_0.jpg\n",
            "001611_person_1.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.7ms\n",
            "Speed: 3.3ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[1.2823e+02, 5.4533e+01, 2.5023e+02, 2.6419e+02],\n",
            "        [2.8494e+02, 7.8144e+01, 3.9344e+02, 2.6583e+02],\n",
            "        [6.9477e+01, 8.8914e+01, 1.2891e+02, 1.7999e+02],\n",
            "        [6.7368e-02, 9.4896e+01, 4.0832e+01, 2.4467e+02],\n",
            "        [5.8584e-01, 9.3812e+01, 4.1372e+01, 1.9936e+02]], device='cuda:0')\n",
            "001085_person_0.jpg\n",
            "001085_person_1.jpg\n",
            "001085_person_2.jpg\n",
            "001085_person_3.jpg\n",
            "001085_person_4.jpg\n",
            "\n",
            "0: 448x640 2 persons, 14.3ms\n",
            "Speed: 3.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[339.9329,  31.6533, 434.3116, 290.0533],\n",
            "        [ 74.8091, 102.9071, 138.5985, 221.5561]], device='cuda:0')\n",
            "001367_person_0.jpg\n",
            "001367_person_1.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.1ms\n",
            "Speed: 2.5ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[104.3210,  70.8247, 500.0000, 343.0000]], device='cuda:0')\n",
            "001568_person_0.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[164.2929, 109.6866, 245.3080, 179.7117]], device='cuda:0')\n",
            "005225_person_0.jpg\n",
            "\n",
            "0: 448x640 7 persons, 12.9ms\n",
            "Speed: 3.6ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[263.1723, 120.2927, 341.8669, 236.3905],\n",
            "        [192.8999, 109.9007, 274.2437, 257.9333],\n",
            "        [335.6417, 119.3876, 406.3970, 253.9131],\n",
            "        [ 37.6002, 124.1327,  96.7717, 264.1746],\n",
            "        [126.0778, 106.8564, 204.7213, 268.0326],\n",
            "        [116.4901, 126.2588, 145.8800, 262.2204],\n",
            "        [161.6333, 141.7635, 198.9509, 259.0991]], device='cuda:0')\n",
            "001393_person_0.jpg\n",
            "001393_person_1.jpg\n",
            "001393_person_2.jpg\n",
            "001393_person_3.jpg\n",
            "001393_person_4.jpg\n",
            "001393_person_5.jpg\n",
            "001393_person_6.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.4ms\n",
            "Speed: 3.2ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 15.2801,  89.2221, 161.1906, 300.0197],\n",
            "        [310.1668,   6.7550, 456.3447, 333.0000],\n",
            "        [185.7645,  21.3906, 302.8463, 192.4389]], device='cuda:0')\n",
            "005197_person_0.jpg\n",
            "005197_person_1.jpg\n",
            "005197_person_2.jpg\n",
            "\n",
            "0: 448x640 6 persons, 13.1ms\n",
            "Speed: 3.3ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 15.8913,  95.6302, 103.0890, 307.2682],\n",
            "        [216.1286, 132.5472, 258.6797, 256.8189],\n",
            "        [144.1706, 100.3757, 193.0371, 284.0007],\n",
            "        [256.0078, 126.6215, 306.0885, 255.1191],\n",
            "        [436.6533, 174.9807, 461.0974, 228.4375],\n",
            "        [279.0714, 191.8681, 323.7646, 251.8482]], device='cuda:0')\n",
            "001225_person_0.jpg\n",
            "001225_person_1.jpg\n",
            "001225_person_2.jpg\n",
            "001225_person_3.jpg\n",
            "001225_person_4.jpg\n",
            "001225_person_5.jpg\n",
            "\n",
            "0: 512x640 3 persons, 14.1ms\n",
            "Speed: 3.0ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "tensor([[251.8823, 122.5028, 373.6312, 359.9841],\n",
            "        [122.0360,  58.1912, 240.4072, 283.3797],\n",
            "        [ 46.6517,  67.7618, 132.4182, 286.5610]], device='cuda:0')\n",
            "001974_person_0.jpg\n",
            "001974_person_1.jpg\n",
            "001974_person_2.jpg\n",
            "\n",
            "0: 640x448 2 persons, 14.4ms\n",
            "Speed: 2.8ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[127.9164, 262.0227, 243.4957, 541.1225],\n",
            "        [170.5242, 172.3209, 299.6086, 334.3005]], device='cuda:0')\n",
            "001232_person_0.jpg\n",
            "001232_person_1.jpg\n",
            "\n",
            "0: 448x640 1 person, 14.6ms\n",
            "Speed: 3.0ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[238.6542,  59.4235, 357.5659, 219.5872]], device='cuda:0')\n",
            "001392_person_0.jpg\n",
            "\n",
            "0: 480x640 1 person, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[ 22.1346,  51.1861, 167.8558, 203.2649]], device='cuda:0')\n",
            "001531_person_0.jpg\n",
            "\n",
            "0: 384x640 3 persons, 78.1ms\n",
            "Speed: 2.5ms preprocess, 78.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "tensor([[204.4678,  70.6119, 267.7963, 253.7725],\n",
            "        [ 90.5490,  27.5938, 209.9279, 267.3735],\n",
            "        [144.3881,  52.2850, 218.5755, 262.9700]], device='cuda:0')\n",
            "001142_person_0.jpg\n",
            "001142_person_1.jpg\n",
            "001142_person_2.jpg\n",
            "\n",
            "0: 448x640 1 person, 15.6ms\n",
            "Speed: 5.8ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[235.5199, 145.4813, 257.3246, 202.4361]], device='cuda:0')\n",
            "001209_person_0.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 3.8ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[  5.1054,   0.0000, 287.3121, 332.3241]], device='cuda:0')\n",
            "001231_person_0.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.3ms\n",
            "Speed: 6.2ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[173.5875, 109.0522, 235.1586, 267.0695],\n",
            "        [444.7540, 127.0149, 500.0000, 333.0000],\n",
            "        [215.2572,  82.7990, 343.9887, 316.4849]], device='cuda:0')\n",
            "001913_person_0.jpg\n",
            "001913_person_1.jpg\n",
            "001913_person_2.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.9ms\n",
            "Speed: 2.7ms preprocess, 13.9ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[181.7596,  27.3416, 327.7858, 220.6927],\n",
            "        [ 14.7924,  82.7326, 177.5791, 271.1963]], device='cuda:0')\n",
            "001448_person_0.jpg\n",
            "001448_person_1.jpg\n",
            "\n",
            "0: 480x640 2 persons, 20.6ms\n",
            "Speed: 2.9ms preprocess, 20.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[319.5915, 103.6691, 453.0291, 363.8589],\n",
            "        [225.7464, 114.9793, 288.1720, 160.9935]], device='cuda:0')\n",
            "001535_person_0.jpg\n",
            "001535_person_1.jpg\n",
            "\n",
            "0: 448x640 1 person, 14.0ms\n",
            "Speed: 2.7ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[168.5653, 135.6652, 288.8286, 335.1492]], device='cuda:0')\n",
            "005021_person_0.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.7ms\n",
            "Speed: 2.8ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[193.6117,  21.9258, 414.5642, 333.0000],\n",
            "        [  0.0000,  57.0889,  33.2594, 332.8069],\n",
            "        [183.5139,  15.8593, 310.0463, 330.5934]], device='cuda:0')\n",
            "001191_person_0.jpg\n",
            "001191_person_1.jpg\n",
            "001191_person_2.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.3ms\n",
            "Speed: 2.8ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[267.0268,  70.8751, 352.2495, 301.6984]], device='cuda:0')\n",
            "001580_person_0.jpg\n",
            "\n",
            "0: 640x480 1 person, 17.5ms\n",
            "Speed: 4.6ms preprocess, 17.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "tensor([[227.0432, 320.7903, 310.9000, 490.8695]], device='cuda:0')\n",
            "001824_person_0.jpg\n",
            "\n",
            "0: 480x640 6 persons, 16.3ms\n",
            "Speed: 3.6ms preprocess, 16.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[264.0677,  86.6780, 323.2713, 299.8365],\n",
            "        [ 49.8572,  80.3382, 118.4514, 300.0000],\n",
            "        [ 96.0977,  89.5946, 222.7371, 300.0000],\n",
            "        [151.7224,  83.0582, 233.4246, 178.8861],\n",
            "        [ 98.5636,  84.0290, 281.6971, 300.0000],\n",
            "        [104.1964, 106.1665, 158.4402, 300.0000]], device='cuda:0')\n",
            "001187_person_0.jpg\n",
            "001187_person_1.jpg\n",
            "001187_person_2.jpg\n",
            "001187_person_3.jpg\n",
            "001187_person_4.jpg\n",
            "001187_person_5.jpg\n",
            "\n",
            "0: 480x640 2 persons, 13.2ms\n",
            "Speed: 3.1ms preprocess, 13.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[ 16.8704,  53.3845, 157.2436, 351.7867],\n",
            "        [296.1862,  43.2553, 477.5961, 352.0000]], device='cuda:0')\n",
            "001143_person_0.jpg\n",
            "001143_person_1.jpg\n",
            "\n",
            "0: 512x640 2 persons, 14.0ms\n",
            "Speed: 4.3ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "tensor([[242.8994,  14.1907, 456.3051, 196.1695],\n",
            "        [180.2299, 100.9905, 294.9082, 207.8280]], device='cuda:0')\n",
            "005190_person_0.jpg\n",
            "005190_person_1.jpg\n",
            "\n",
            "0: 480x640 2 persons, 14.5ms\n",
            "Speed: 3.1ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[236.2523,  60.0983, 265.7205, 131.4986],\n",
            "        [472.7349, 313.1620, 499.8555, 347.9075]], device='cuda:0')\n",
            "005201_person_0.jpg\n",
            "005201_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.9ms\n",
            "Speed: 2.6ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[268.3490, 115.5313, 348.5278, 227.3471],\n",
            "        [231.5659, 134.3565, 288.3902, 212.7766],\n",
            "        [191.8875, 149.1953, 246.8696, 205.9785]], device='cuda:0')\n",
            "001604_person_0.jpg\n",
            "001604_person_1.jpg\n",
            "001604_person_2.jpg\n",
            "\n",
            "0: 448x640 1 person, 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[179.4690,  74.7681, 312.1204, 262.8817]], device='cuda:0')\n",
            "001373_person_0.jpg\n",
            "\n",
            "0: 416x640 3 persons, 13.7ms\n",
            "Speed: 2.6ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[215.6614,  90.0427, 362.5309, 320.0000],\n",
            "        [  2.6633,  50.5521, 218.5130, 320.0000],\n",
            "        [356.6342,  70.4615, 458.3387, 298.8355]], device='cuda:0')\n",
            "001323_person_0.jpg\n",
            "001323_person_1.jpg\n",
            "001323_person_2.jpg\n",
            "\n",
            "0: 640x448 1 person, 15.0ms\n",
            "Speed: 2.9ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[ 33.8316,  71.8302, 135.8059, 266.7876]], device='cuda:0')\n",
            "001545_person_0.jpg\n",
            "\n",
            "0: 448x640 4 persons, 16.2ms\n",
            "Speed: 2.6ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[193.6221,  38.8976, 317.9427, 331.6933],\n",
            "        [379.7162,  52.0148, 440.8648, 230.7947],\n",
            "        [443.1457,  91.7894, 486.5312, 171.8844],\n",
            "        [160.9153,   4.0330, 243.4903, 288.9839]], device='cuda:0')\n",
            "005028_person_0.jpg\n",
            "005028_person_1.jpg\n",
            "005028_person_2.jpg\n",
            "005028_person_3.jpg\n",
            "\n",
            "0: 416x640 2 persons, 14.4ms\n",
            "Speed: 5.7ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[ 81.8674,  89.5530, 127.9096, 159.9903],\n",
            "        [142.3605, 109.8834, 184.0202, 173.2689]], device='cuda:0')\n",
            "001073_person_0.jpg\n",
            "001073_person_1.jpg\n",
            "\n",
            "0: 480x640 2 persons, 16.3ms\n",
            "Speed: 3.0ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[200.3227,  89.9952, 230.1711, 160.9391],\n",
            "        [121.3530, 185.2829, 145.5750, 274.5273]], device='cuda:0')\n",
            "001265_person_0.jpg\n",
            "001265_person_1.jpg\n",
            "\n",
            "0: 640x448 2 persons, 13.2ms\n",
            "Speed: 3.1ms preprocess, 13.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[338.3006, 503.5538, 460.3955, 700.9776],\n",
            "        [241.8778, 426.9653, 310.5479, 570.1989]], device='cuda:0')\n",
            "005072_person_0.jpg\n",
            "005072_person_1.jpg\n",
            "\n",
            "0: 640x448 1 person, 13.4ms\n",
            "Speed: 3.0ms preprocess, 13.4ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[ 34.6399,  36.3114, 496.9477, 750.0000]], device='cuda:0')\n",
            "005244_person_0.jpg\n",
            "\n",
            "0: 448x640 1 person, 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[122.5921, 120.6066, 483.4292, 332.0424]], device='cuda:0')\n",
            "001931_person_0.jpg\n",
            "\n",
            "0: 480x640 4 persons, 14.4ms\n",
            "Speed: 3.0ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[ 35.5347,  60.4901, 104.6393, 272.7298],\n",
            "        [ 95.7007,  68.7000, 152.2906, 230.4743],\n",
            "        [171.5656,  73.8081, 207.5834, 201.0098],\n",
            "        [ 29.0210,  62.9995,  64.8950, 224.5160]], device='cuda:0')\n",
            "001198_person_0.jpg\n",
            "001198_person_1.jpg\n",
            "001198_person_2.jpg\n",
            "001198_person_3.jpg\n",
            "\n",
            "0: 448x640 2 persons, 18.4ms\n",
            "Speed: 2.7ms preprocess, 18.4ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[168.2379,  66.6616, 500.0000, 331.9792],\n",
            "        [ 11.4828,  27.8238, 299.0796, 330.5701]], device='cuda:0')\n",
            "001855_person_0.jpg\n",
            "001855_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.2ms\n",
            "Speed: 3.0ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 83.9624, 105.1827, 307.3525, 279.3107],\n",
            "        [337.8943,  53.9292, 470.9297, 276.5140]], device='cuda:0')\n",
            "005128_person_0.jpg\n",
            "005128_person_1.jpg\n",
            "\n",
            "0: 480x640 2 persons, 20.4ms\n",
            "Speed: 2.8ms preprocess, 20.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[ 99.0631,  26.5585, 214.9342, 312.9321],\n",
            "        [264.5601,  76.2180, 337.9772, 297.9167]], device='cuda:0')\n",
            "001173_person_0.jpg\n",
            "001173_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 20.1ms\n",
            "Speed: 2.7ms preprocess, 20.1ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[  0.0000, 109.6245, 121.5876, 264.2906],\n",
            "        [ 92.9709, 144.5382, 158.5098, 264.4185]], device='cuda:0')\n",
            "001878_person_0.jpg\n",
            "001878_person_1.jpg\n",
            "\n",
            "0: 448x640 8 persons, 19.7ms\n",
            "Speed: 2.7ms preprocess, 19.7ms inference, 2.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[2.9445e+02, 3.9537e+01, 3.4141e+02, 1.6212e+02],\n",
            "        [3.9136e+02, 2.1936e+02, 4.4300e+02, 3.2645e+02],\n",
            "        [1.0947e+02, 3.7420e+01, 1.5989e+02, 1.5907e+02],\n",
            "        [3.5060e+02, 2.3751e+02, 3.9480e+02, 3.2635e+02],\n",
            "        [1.4568e+02, 2.2204e+02, 1.8130e+02, 3.2697e+02],\n",
            "        [1.1368e-01, 2.3466e+02, 3.1862e+01, 3.2578e+02],\n",
            "        [1.7990e+02, 2.3838e+02, 2.2067e+02, 3.2534e+02],\n",
            "        [4.5276e+02, 2.4841e+02, 4.7791e+02, 3.2660e+02]], device='cuda:0')\n",
            "001180_person_0.jpg\n",
            "001180_person_1.jpg\n",
            "001180_person_2.jpg\n",
            "001180_person_3.jpg\n",
            "001180_person_4.jpg\n",
            "001180_person_5.jpg\n",
            "001180_person_6.jpg\n",
            "001180_person_7.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.1ms\n",
            "Speed: 3.3ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[293.6579, 107.7644, 500.0000, 333.7295],\n",
            "        [175.5877, 122.0938, 368.0243, 334.0000]], device='cuda:0')\n",
            "001707_person_0.jpg\n",
            "001707_person_1.jpg\n",
            "\n",
            "0: 416x640 2 persons, 13.6ms\n",
            "Speed: 2.0ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[ 11.2377,  73.7899, 189.4193, 250.0000],\n",
            "        [ 80.1368,  51.0931, 133.7087, 133.0868]], device='cuda:0')\n",
            "001997_person_0.jpg\n",
            "001997_person_1.jpg\n",
            "\n",
            "0: 640x448 2 persons, 12.7ms\n",
            "Speed: 3.5ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[ 86.4922, 174.0446, 233.4096, 420.0000],\n",
            "        [ 50.8491,  94.6338, 164.6658, 358.7067]], device='cuda:0')\n",
            "001668_person_0.jpg\n",
            "001668_person_1.jpg\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "tensor([[384.3804, 164.5217, 428.2914, 288.2320],\n",
            "        [309.1129, 161.4223, 343.1698, 270.7115],\n",
            "        [359.5918, 122.4115, 411.0390, 211.3693]], device='cuda:0')\n",
            "001347_person_0.jpg\n",
            "001347_person_1.jpg\n",
            "001347_person_2.jpg\n",
            "\n",
            "0: 480x640 1 person, 14.0ms\n",
            "Speed: 2.3ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[ 76.2301,  15.5678, 394.0662, 365.0000]], device='cuda:0')\n",
            "001029_person_0.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.9ms\n",
            "Speed: 2.7ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[138.1387,  33.5626, 233.7074, 228.1426],\n",
            "        [334.1574, 200.9510, 371.8806, 297.4940]], device='cuda:0')\n",
            "001952_person_0.jpg\n",
            "001952_person_1.jpg\n",
            "\n",
            "0: 416x640 1 person, 14.6ms\n",
            "Speed: 3.0ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[190.9414, 143.0115, 315.8423, 314.6509]], device='cuda:0')\n",
            "001811_person_0.jpg\n",
            "\n",
            "0: 640x416 2 persons, 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 416)\n",
            "tensor([[183.6628, 112.2753, 259.3710, 282.6262],\n",
            "        [100.3776, 124.6436, 161.2492, 265.9835]], device='cuda:0')\n",
            "005087_person_0.jpg\n",
            "005087_person_1.jpg\n",
            "\n",
            "0: 416x640 2 persons, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[207.8281,   7.7665, 305.0818, 194.2179],\n",
            "        [ 57.5756,  23.6909, 118.3703, 172.6901]], device='cuda:0')\n",
            "001268_person_0.jpg\n",
            "001268_person_1.jpg\n",
            "\n",
            "0: 320x640 3 persons, 51.9ms\n",
            "Speed: 3.8ms preprocess, 51.9ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n",
            "tensor([[ 39.0503,  51.1102, 174.3527, 300.0000],\n",
            "        [210.6027,  66.4988, 340.5053, 299.9448],\n",
            "        [393.2745,  33.6617, 511.4117, 300.0000]], device='cuda:0')\n",
            "001664_person_0.jpg\n",
            "001664_person_1.jpg\n",
            "001664_person_2.jpg\n",
            "\n",
            "0: 640x544 1 person, 16.8ms\n",
            "Speed: 2.6ms preprocess, 16.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
            "tensor([[102.5158,  46.9936, 231.3419, 350.2184]], device='cuda:0')\n",
            "001155_person_0.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.7ms\n",
            "Speed: 3.6ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[309.0244, 165.4363, 360.0849, 323.7533],\n",
            "        [341.1947,  41.8173, 402.2480, 167.7820]], device='cuda:0')\n",
            "005175_person_0.jpg\n",
            "005175_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.0ms\n",
            "Speed: 3.9ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[188.0646, 250.5515, 230.9421, 331.6446],\n",
            "        [370.4212, 242.2650, 409.7045, 332.5899]], device='cuda:0')\n",
            "001948_person_0.jpg\n",
            "001948_person_1.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 4.0ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[128.7622,  28.7993, 309.6480, 342.0000]], device='cuda:0')\n",
            "001045_person_0.jpg\n",
            "\n",
            "0: 448x640 1 person, 12.9ms\n",
            "Speed: 2.8ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[181.3341, 122.8571, 299.6507, 326.1911]], device='cuda:0')\n",
            "001196_person_0.jpg\n",
            "\n",
            "0: 448x640 4 persons, 12.9ms\n",
            "Speed: 4.1ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[2.1286e+02, 9.4246e+01, 3.3996e+02, 3.2064e+02],\n",
            "        [2.5350e+01, 5.8898e+01, 2.4627e+02, 3.3718e+02],\n",
            "        [1.6174e+02, 1.2476e+02, 2.1639e+02, 2.8540e+02],\n",
            "        [4.1109e-02, 1.1131e+02, 6.5530e+01, 3.2805e+02]], device='cuda:0')\n",
            "001071_person_0.jpg\n",
            "001071_person_1.jpg\n",
            "001071_person_2.jpg\n",
            "001071_person_3.jpg\n",
            "\n",
            "0: 416x640 7 persons, 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[  3.0412,  48.4261, 220.0871, 306.0000],\n",
            "        [284.5053,  70.5701, 403.7741, 305.7969],\n",
            "        [155.0962,  57.4693, 302.3614, 303.6394],\n",
            "        [385.7983,  33.7826, 455.5433, 264.1166],\n",
            "        [385.2650,  28.3291, 499.8599, 306.0000],\n",
            "        [445.0102,  23.7180, 500.0000, 305.8101],\n",
            "        [421.7206,  27.1491, 499.8049, 304.1971]], device='cuda:0')\n",
            "001381_person_0.jpg\n",
            "001381_person_1.jpg\n",
            "001381_person_2.jpg\n",
            "001381_person_3.jpg\n",
            "001381_person_4.jpg\n",
            "001381_person_5.jpg\n",
            "001381_person_6.jpg\n",
            "\n",
            "0: 480x640 2 persons, 14.3ms\n",
            "Speed: 2.8ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[ 22.9506,  50.6111, 333.8380, 374.2832],\n",
            "        [317.9424,   1.6191, 496.7865, 375.0000]], device='cuda:0')\n",
            "001436_person_0.jpg\n",
            "001436_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 14.4ms\n",
            "Speed: 2.7ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[268.9781, 152.3612, 364.1836, 256.4176],\n",
            "        [215.7246, 107.1043, 320.9701, 270.3129]], device='cuda:0')\n",
            "001634_person_0.jpg\n",
            "001634_person_1.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 4.4ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 16.2214,  67.8476, 209.1404, 266.0000]], device='cuda:0')\n",
            "001330_person_0.jpg\n",
            "\n",
            "0: 448x640 3 persons, 12.9ms\n",
            "Speed: 3.2ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[266.4236, 151.0308, 316.4456, 270.0789],\n",
            "        [287.6822, 260.2916, 328.1138, 338.3215],\n",
            "        [203.6182, 133.2130, 298.9828, 210.7485]], device='cuda:0')\n",
            "005069_person_0.jpg\n",
            "005069_person_1.jpg\n",
            "005069_person_2.jpg\n",
            "\n",
            "0: 640x448 1 person, 12.7ms\n",
            "Speed: 3.4ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[ 78.0242,  95.4524, 456.9688, 608.4150]], device='cuda:0')\n",
            "001175_person_0.jpg\n",
            "\n",
            "0: 448x640 7 persons, 13.6ms\n",
            "Speed: 3.2ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[251.2631, 153.7457, 374.8419, 330.8553],\n",
            "        [113.6383, 178.9788, 216.1135, 330.6688],\n",
            "        [ 19.5590, 101.1466, 147.1254, 331.0000],\n",
            "        [357.7082, 157.0536, 428.0027, 329.2840],\n",
            "        [427.4794, 149.8148, 469.2523, 283.2240],\n",
            "        [156.2464,  55.3917, 284.9318, 289.2545],\n",
            "        [461.6654, 176.6477, 498.6486, 288.4124]], device='cuda:0')\n",
            "001675_person_0.jpg\n",
            "001675_person_1.jpg\n",
            "001675_person_2.jpg\n",
            "001675_person_3.jpg\n",
            "001675_person_4.jpg\n",
            "001675_person_5.jpg\n",
            "001675_person_6.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 4.0ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[174.4726,   9.7967, 392.2773, 330.5782]], device='cuda:0')\n",
            "005184_person_0.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 11.0559,  16.7928, 337.8549, 331.5486]], device='cuda:0')\n",
            "001937_person_0.jpg\n",
            "\n",
            "0: 512x640 2 persons, 13.9ms\n",
            "Speed: 3.8ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "tensor([[ 95.3384, 279.0433, 167.4109, 376.6041],\n",
            "        [ 50.7042, 290.4260,  96.9857, 347.9112]], device='cuda:0')\n",
            "001438_person_0.jpg\n",
            "001438_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.6ms\n",
            "Speed: 2.9ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[162.4218,  81.8715, 232.7434, 176.2552],\n",
            "        [235.3363,  50.4933, 279.8698, 170.7526],\n",
            "        [414.1484,  18.6837, 470.5758, 198.3634]], device='cuda:0')\n",
            "001111_person_0.jpg\n",
            "001111_person_1.jpg\n",
            "001111_person_2.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.0ms\n",
            "Speed: 3.6ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[233.2062,  90.9414, 289.3698, 241.2130],\n",
            "        [205.0529, 247.6865, 245.3863, 313.7180],\n",
            "        [128.8466, 253.9221, 175.8685, 314.7117]], device='cuda:0')\n",
            "005198_person_0.jpg\n",
            "005198_person_1.jpg\n",
            "005198_person_2.jpg\n",
            "\n",
            "0: 448x640 2 persons, 14.1ms\n",
            "Speed: 6.7ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[172.3787, 133.4711, 239.3151, 242.8616],\n",
            "        [257.4834, 114.9097, 330.1218, 251.0306]], device='cuda:0')\n",
            "001840_person_0.jpg\n",
            "001840_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 17.4ms\n",
            "Speed: 4.0ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[242.2875,  99.3219, 311.2837, 294.8248],\n",
            "        [ 26.6224, 108.5178, 104.5518, 330.8274],\n",
            "        [359.7822, 119.4949, 397.8754, 246.3293]], device='cuda:0')\n",
            "001223_person_0.jpg\n",
            "001223_person_1.jpg\n",
            "001223_person_2.jpg\n",
            "\n",
            "0: 448x640 4 persons, 13.0ms\n",
            "Speed: 3.1ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[238.8872, 151.5755, 311.0105, 239.6811],\n",
            "        [407.7673, 108.0999, 468.3178, 173.5393],\n",
            "        [170.6281,  98.9618, 221.1695, 186.5477],\n",
            "        [287.6514, 112.8872, 328.9613, 162.0726]], device='cuda:0')\n",
            "001682_person_0.jpg\n",
            "001682_person_1.jpg\n",
            "001682_person_2.jpg\n",
            "001682_person_3.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 3.4ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[281.6742,  79.8202, 396.4331, 306.3220]], device='cuda:0')\n",
            "001875_person_0.jpg\n",
            "\n",
            "0: 448x640 4 persons, 13.0ms\n",
            "Speed: 3.6ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 69.3478,  56.6001, 198.7482, 259.4824],\n",
            "        [249.0314,  75.0752, 386.2177, 309.0577],\n",
            "        [152.7924,  36.6260, 208.3151, 185.9724],\n",
            "        [216.2939,  57.6087, 252.0956, 165.0991]], device='cuda:0')\n",
            "005013_person_0.jpg\n",
            "005013_person_1.jpg\n",
            "005013_person_2.jpg\n",
            "005013_person_3.jpg\n",
            "\n",
            "0: 480x640 2 persons, 15.3ms\n",
            "Speed: 3.1ms preprocess, 15.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[219.1002, 166.0897, 301.7564, 285.2188],\n",
            "        [267.8153,  25.3195, 364.1955, 342.1587]], device='cuda:0')\n",
            "001080_person_0.jpg\n",
            "001080_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 14.3ms\n",
            "Speed: 2.7ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[100.7491,  62.8129, 282.0428, 331.7684],\n",
            "        [205.7833,  66.1347, 357.6587, 332.0494],\n",
            "        [221.5640,  13.4314, 449.7139, 332.8381]], device='cuda:0')\n",
            "001454_person_0.jpg\n",
            "001454_person_1.jpg\n",
            "001454_person_2.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.0ms\n",
            "Speed: 3.6ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[410.3975,  53.5970, 438.0012,  98.6242],\n",
            "        [390.9476,  81.9369, 420.3199, 127.2710],\n",
            "        [143.0774, 218.8020, 171.3776, 282.9081],\n",
            "        [ 93.0633, 204.1076, 111.9814, 267.9733],\n",
            "        [ 78.9381, 200.5313,  98.5824, 260.4411]], device='cuda:0')\n",
            "001324_person_0.jpg\n",
            "001324_person_1.jpg\n",
            "001324_person_2.jpg\n",
            "001324_person_3.jpg\n",
            "001324_person_4.jpg\n",
            "\n",
            "0: 480x640 5 persons, 17.8ms\n",
            "Speed: 3.5ms preprocess, 17.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[224.7757, 119.6331, 274.7722, 300.0366],\n",
            "        [159.3882, 102.0778, 234.2584, 332.9586],\n",
            "        [330.9716,  95.1304, 381.2417, 310.9848],\n",
            "        [ 25.9969,  99.5359,  87.7331, 341.2310],\n",
            "        [393.2498,  99.8505, 462.5575, 262.9288]], device='cuda:0')\n",
            "001757_person_0.jpg\n",
            "001757_person_1.jpg\n",
            "001757_person_2.jpg\n",
            "001757_person_3.jpg\n",
            "001757_person_4.jpg\n",
            "\n",
            "0: 448x640 3 persons, 14.4ms\n",
            "Speed: 4.2ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[160.4688, 115.7192, 216.9636, 189.2309],\n",
            "        [280.2453,  52.3206, 327.5375, 122.8327],\n",
            "        [ 63.7089, 166.1383, 123.5381, 239.4997]], device='cuda:0')\n",
            "005289_person_0.jpg\n",
            "005289_person_1.jpg\n",
            "005289_person_2.jpg\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "tensor([[ 97.6439,   5.6027, 283.9088, 299.7991],\n",
            "        [372.8767,  77.4643, 430.5347, 275.2871],\n",
            "        [493.9801, 122.0536, 521.1091, 184.2180]], device='cuda:0')\n",
            "001532_person_0.jpg\n",
            "001532_person_1.jpg\n",
            "001532_person_2.jpg\n",
            "\n",
            "0: 480x640 1 person, 13.9ms\n",
            "Speed: 3.6ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[239.0951,  71.8853, 290.0747, 245.3822]], device='cuda:0')\n",
            "005132_person_0.jpg\n",
            "\n",
            "0: 448x640 4 persons, 13.9ms\n",
            "Speed: 2.9ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[190.4620,  11.8301, 268.4601, 218.8372],\n",
            "        [ 73.5532,  56.5146,  96.0733, 117.8794],\n",
            "        [ 81.8888,  55.1045, 126.9236, 143.0483],\n",
            "        [ 33.1764,  59.2148,  53.3431, 105.9629]], device='cuda:0')\n",
            "001185_person_0.jpg\n",
            "001185_person_1.jpg\n",
            "001185_person_2.jpg\n",
            "001185_person_3.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[165.1262,  47.4316, 302.9537, 299.0000],\n",
            "        [ 87.8802,  15.8021, 150.0019, 142.8913],\n",
            "        [299.7451,  81.0684, 355.6912, 164.5783],\n",
            "        [ 16.3427,   0.7957, 113.9004, 263.9181],\n",
            "        [246.4101,  82.7909, 293.6448, 155.3858]], device='cuda:0')\n",
            "001486_person_0.jpg\n",
            "001486_person_1.jpg\n",
            "001486_person_2.jpg\n",
            "001486_person_3.jpg\n",
            "001486_person_4.jpg\n",
            "\n",
            "0: 448x640 4 persons, 13.0ms\n",
            "Speed: 3.7ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[211.2607,  19.7400, 441.0326, 309.9505],\n",
            "        [377.6375,  11.1001, 477.8990, 218.0555],\n",
            "        [  1.8962,  86.5421, 154.5508, 331.5263],\n",
            "        [107.9056,  79.1993, 214.7956, 226.6814]], device='cuda:0')\n",
            "001618_person_0.jpg\n",
            "001618_person_1.jpg\n",
            "001618_person_2.jpg\n",
            "001618_person_3.jpg\n",
            "\n",
            "0: 640x448 1 person, 12.7ms\n",
            "Speed: 3.2ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[ 46.1807,  67.3013, 175.2879, 299.5721]], device='cuda:0')\n",
            "001659_person_0.jpg\n",
            "\n",
            "0: 416x640 3 persons, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[189.3870,  19.3718, 448.3681, 289.4187],\n",
            "        [  0.9309,  19.4646, 227.3147, 288.3190],\n",
            "        [136.1356,  79.2556, 228.3522, 286.3770]], device='cuda:0')\n",
            "001627_person_0.jpg\n",
            "001627_person_1.jpg\n",
            "001627_person_2.jpg\n",
            "\n",
            "0: 448x640 5 persons, 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[238.8581, 121.5746, 288.4442, 209.9103],\n",
            "        [172.0243, 150.5854, 225.5197, 260.3866],\n",
            "        [100.0056, 202.7275, 152.5196, 316.5050],\n",
            "        [391.3228, 186.9649, 448.5963, 278.9073],\n",
            "        [ 72.6323, 179.5369, 113.8371, 263.9769]], device='cuda:0')\n",
            "001332_person_0.jpg\n",
            "001332_person_1.jpg\n",
            "001332_person_2.jpg\n",
            "001332_person_3.jpg\n",
            "001332_person_4.jpg\n",
            "\n",
            "0: 448x640 1 person, 14.9ms\n",
            "Speed: 2.7ms preprocess, 14.9ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[342.0726, 145.3869, 396.8349, 298.0098]], device='cuda:0')\n",
            "005114_person_0.jpg\n",
            "\n",
            "0: 448x640 2 persons, 21.4ms\n",
            "Speed: 4.9ms preprocess, 21.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[187.3598,  79.5923, 361.4045, 331.3878],\n",
            "        [318.2400, 127.3599, 386.1982, 227.1160]], device='cuda:0')\n",
            "001341_person_0.jpg\n",
            "001341_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 12.9ms\n",
            "Speed: 2.5ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 44.2508, 165.2429, 131.6255, 288.0286],\n",
            "        [ 25.3600, 166.8394,  68.9937, 265.3178]], device='cuda:0')\n",
            "001710_person_0.jpg\n",
            "001710_person_1.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.2ms\n",
            "Speed: 4.2ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[201.8151,   1.0654, 500.0000, 291.2024]], device='cuda:0')\n",
            "001086_person_0.jpg\n",
            "\n",
            "0: 480x640 2 persons, 14.0ms\n",
            "Speed: 3.1ms preprocess, 14.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[250.9886, 126.9440, 397.0666, 319.8414],\n",
            "        [ 34.8138, 166.2532, 185.0096, 350.6115]], device='cuda:0')\n",
            "001831_person_0.jpg\n",
            "001831_person_1.jpg\n",
            "\n",
            "0: 384x640 7 persons, 41.8ms\n",
            "Speed: 3.4ms preprocess, 41.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "tensor([[ 65.9028,  57.6151, 136.0710, 238.3655],\n",
            "        [177.6594,  78.0147, 241.3929, 197.1064],\n",
            "        [  0.0000,  88.7437,  48.0227, 240.0013],\n",
            "        [226.5686,  81.9493, 273.3456, 144.2620],\n",
            "        [126.8889,  80.0735, 232.3212, 215.4487],\n",
            "        [356.1218,  73.3133, 451.7498, 299.2457],\n",
            "        [270.3468,  87.5425, 309.1273, 162.8309]], device='cuda:0')\n",
            "005159_person_0.jpg\n",
            "005159_person_1.jpg\n",
            "005159_person_2.jpg\n",
            "005159_person_3.jpg\n",
            "005159_person_4.jpg\n",
            "005159_person_5.jpg\n",
            "005159_person_6.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.8ms\n",
            "Speed: 2.5ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[169.9596, 163.7975, 212.9881, 239.1812]], device='cuda:0')\n",
            "005164_person_0.jpg\n",
            "\n",
            "0: 512x640 2 persons, 14.0ms\n",
            "Speed: 3.9ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "tensor([[175.6286,  12.0587, 257.7467, 202.8835],\n",
            "        [148.3165,  45.9856, 224.1556, 203.3972]], device='cuda:0')\n",
            "001003_person_0.jpg\n",
            "001003_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.7ms\n",
            "Speed: 3.8ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[279.3502,  42.9470, 358.5571, 175.0104],\n",
            "        [210.6473,  73.7204, 284.9034, 204.3607]], device='cuda:0')\n",
            "001890_person_0.jpg\n",
            "001890_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.6ms\n",
            "Speed: 3.4ms preprocess, 13.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 80.4824, 139.2135, 228.0345, 263.7785],\n",
            "        [277.2913,   1.0250, 400.0000, 264.0000],\n",
            "        [214.6752, 149.1974, 347.5136, 263.8317]], device='cuda:0')\n",
            "005119_person_0.jpg\n",
            "005119_person_1.jpg\n",
            "005119_person_2.jpg\n",
            "\n",
            "0: 416x640 1 person, 13.5ms\n",
            "Speed: 3.6ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[386.0403, 148.2824, 500.0000, 305.0000]], device='cuda:0')\n",
            "001990_person_0.jpg\n",
            "\n",
            "0: 480x640 7 persons, 13.8ms\n",
            "Speed: 4.6ms preprocess, 13.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[8.9880e+01, 2.1944e+01, 1.7591e+02, 2.3700e+02],\n",
            "        [3.0561e+02, 5.7789e+01, 3.7232e+02, 1.8153e+02],\n",
            "        [2.2492e+02, 4.8433e+01, 2.7891e+02, 1.7076e+02],\n",
            "        [2.6826e-01, 2.0719e+01, 5.4803e+01, 2.3143e+02],\n",
            "        [2.6729e+02, 2.8736e+01, 3.0188e+02, 1.3416e+02],\n",
            "        [2.0516e+02, 5.1986e+01, 2.4487e+02, 1.6166e+02],\n",
            "        [1.8396e+02, 3.3168e+01, 2.2209e+02, 1.3076e+02]], device='cuda:0')\n",
            "001183_person_0.jpg\n",
            "001183_person_1.jpg\n",
            "001183_person_2.jpg\n",
            "001183_person_3.jpg\n",
            "001183_person_4.jpg\n",
            "001183_person_5.jpg\n",
            "001183_person_6.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.9ms\n",
            "Speed: 3.7ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[138.6217, 106.6029, 270.7313, 251.9800],\n",
            "        [  0.6447,  49.1891, 189.6459, 263.0752]], device='cuda:0')\n",
            "001318_person_0.jpg\n",
            "001318_person_1.jpg\n",
            "\n",
            "0: 480x640 2 persons, 13.9ms\n",
            "Speed: 4.1ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[133.5634,  56.3179, 241.5950, 322.3835],\n",
            "        [ 59.8682, 215.3303, 147.5629, 337.6246]], device='cuda:0')\n",
            "001781_person_0.jpg\n",
            "001781_person_1.jpg\n",
            "\n",
            "0: 416x640 2 persons, 14.5ms\n",
            "Speed: 4.3ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[3.6289e+02, 9.6563e+01, 4.5792e+02, 2.0713e+02],\n",
            "        [2.3514e-01, 1.1986e+02, 3.1422e+01, 1.9351e+02]], device='cuda:0')\n",
            "001184_person_0.jpg\n",
            "001184_person_1.jpg\n",
            "\n",
            "0: 640x448 2 persons, 12.8ms\n",
            "Speed: 3.3ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[211.1128,  92.5845, 413.5834, 534.9359],\n",
            "        [192.4798, 171.0589, 284.4454, 348.6506]], device='cuda:0')\n",
            "001406_person_0.jpg\n",
            "001406_person_1.jpg\n",
            "\n",
            "0: 384x640 10 persons, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "tensor([[107.5344,  97.2039, 175.9825, 296.1958],\n",
            "        [180.5276,  88.5299, 243.1858, 284.4278],\n",
            "        [ 32.5016, 104.1705, 109.4532, 272.3163],\n",
            "        [333.9381,  85.8906, 428.2159, 300.0000],\n",
            "        [265.8496, 102.7698, 338.6703, 298.7834],\n",
            "        [159.4352, 101.3280, 194.4551, 256.7527],\n",
            "        [ 13.5809, 115.0308,  46.4922, 204.8188],\n",
            "        [245.4756,  86.4744, 292.2642, 257.2392],\n",
            "        [319.7170,  64.7747, 377.3232, 295.9597],\n",
            "        [229.2096,  93.9787, 262.5044, 244.5158]], device='cuda:0')\n",
            "001806_person_0.jpg\n",
            "001806_person_1.jpg\n",
            "001806_person_2.jpg\n",
            "001806_person_3.jpg\n",
            "001806_person_4.jpg\n",
            "001806_person_5.jpg\n",
            "001806_person_6.jpg\n",
            "001806_person_7.jpg\n",
            "001806_person_8.jpg\n",
            "001806_person_9.jpg\n",
            "\n",
            "0: 480x640 1 person, 14.0ms\n",
            "Speed: 3.5ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[238.0237,  87.3102, 497.3464, 375.0000]], device='cuda:0')\n",
            "001551_person_0.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.7ms\n",
            "Speed: 3.9ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[203.1595,  98.3376, 390.9879, 265.5072]], device='cuda:0')\n",
            "001926_person_0.jpg\n",
            "\n",
            "0: 640x448 4 persons, 12.5ms\n",
            "Speed: 3.8ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[165.2465, 410.5883, 248.8644, 629.4760],\n",
            "        [377.1739, 335.2841, 446.9942, 458.2125],\n",
            "        [199.4040,  33.6846, 268.5712, 165.0857],\n",
            "        [225.0470, 224.3559, 271.7637, 353.0878]], device='cuda:0')\n",
            "001005_person_0.jpg\n",
            "001005_person_1.jpg\n",
            "001005_person_2.jpg\n",
            "001005_person_3.jpg\n",
            "\n",
            "0: 448x640 4 persons, 14.8ms\n",
            "Speed: 2.9ms preprocess, 14.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 16.9091,  93.2972, 109.0543, 227.5713],\n",
            "        [264.4655,  83.4799, 366.2496, 222.4168],\n",
            "        [145.9806, 104.6349, 218.8613, 199.0384],\n",
            "        [232.0634, 105.2798, 288.2195, 173.4021]], device='cuda:0')\n",
            "005057_person_0.jpg\n",
            "005057_person_1.jpg\n",
            "005057_person_2.jpg\n",
            "005057_person_3.jpg\n",
            "\n",
            "0: 480x640 4 persons, 13.9ms\n",
            "Speed: 3.3ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[122.1206,  89.1087, 240.7834, 234.3422],\n",
            "        [239.7947,  16.9785, 341.1231, 241.6866],\n",
            "        [343.2096, 113.4093, 455.5601, 267.1303],\n",
            "        [ 97.3731,  47.8772, 146.8260, 108.5599]], device='cuda:0')\n",
            "001229_person_0.jpg\n",
            "001229_person_1.jpg\n",
            "001229_person_2.jpg\n",
            "001229_person_3.jpg\n",
            "\n",
            "0: 480x640 1 person, 13.2ms\n",
            "Speed: 3.4ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[225.3911,   9.9023, 364.8461, 353.4507]], device='cuda:0')\n",
            "001411_person_0.jpg\n",
            "\n",
            "0: 480x640 4 persons, 13.2ms\n",
            "Speed: 4.7ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[422.5011,  55.7323, 478.9168, 280.9181],\n",
            "        [250.9212,  80.8189, 339.9167, 288.2980],\n",
            "        [337.8499,  50.3867, 438.9133, 324.2943],\n",
            "        [312.4106,  89.3946, 395.4801, 305.1349]], device='cuda:0')\n",
            "001129_person_0.jpg\n",
            "001129_person_1.jpg\n",
            "001129_person_2.jpg\n",
            "001129_person_3.jpg\n",
            "\n",
            "0: 480x640 2 persons, 13.2ms\n",
            "Speed: 4.0ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[350.1196, 215.8882, 425.0459, 288.1530],\n",
            "        [169.2928, 164.5422, 206.0563, 277.4773]], device='cuda:0')\n",
            "001911_person_0.jpg\n",
            "001911_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.9ms\n",
            "Speed: 3.1ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[118.1325,  80.7415, 243.3457, 296.8850],\n",
            "        [ 32.8941,  69.3262, 130.8074, 297.6064]], device='cuda:0')\n",
            "001693_person_0.jpg\n",
            "001693_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.0ms\n",
            "Speed: 3.9ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[280.0517, 113.1839, 337.0667, 253.5670],\n",
            "        [215.0323, 127.4953, 261.7858, 255.4242],\n",
            "        [375.7180, 130.6326, 432.3959, 255.0576]], device='cuda:0')\n",
            "001711_person_0.jpg\n",
            "001711_person_1.jpg\n",
            "001711_person_2.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.1ms\n",
            "Speed: 4.0ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[243.9442, 110.7185, 301.9907, 234.3675],\n",
            "        [172.2137, 114.3964, 241.8308, 231.5879]], device='cuda:0')\n",
            "001455_person_0.jpg\n",
            "001455_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.0ms\n",
            "Speed: 3.4ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[203.1804,  41.5360, 362.1684, 247.4934],\n",
            "        [305.5479,  17.5392, 331.9481,  88.0694],\n",
            "        [328.4497,  26.0223, 377.1152,  88.5073]], device='cuda:0')\n",
            "001619_person_0.jpg\n",
            "001619_person_1.jpg\n",
            "001619_person_2.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[320.0195,  28.0806, 431.8463, 272.1855]], device='cuda:0')\n",
            "001376_person_0.jpg\n",
            "\n",
            "0: 416x640 2 persons, 13.4ms\n",
            "Speed: 3.4ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[ 88.4306, 135.0015, 175.9670, 284.5218],\n",
            "        [286.0529,  93.2340, 341.8682, 284.2222]], device='cuda:0')\n",
            "005207_person_0.jpg\n",
            "005207_person_1.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.7ms\n",
            "Speed: 3.0ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[121.9222, 100.6398, 366.4395, 344.0000]], device='cuda:0')\n",
            "001541_person_0.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.0ms\n",
            "Speed: 3.5ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 78.8294,  86.7169, 133.8187, 169.2963],\n",
            "        [308.2751,   3.7321, 360.9815, 113.9404],\n",
            "        [230.5044,  49.8511, 269.8559, 125.4807]], device='cuda:0')\n",
            "001062_person_0.jpg\n",
            "001062_person_1.jpg\n",
            "001062_person_2.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.0ms\n",
            "Speed: 4.0ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[163.5513, 115.6315, 286.3640, 320.6606],\n",
            "        [ 23.8415,  37.0330, 163.5119, 259.9832]], device='cuda:0')\n",
            "005106_person_0.jpg\n",
            "005106_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.0ms\n",
            "Speed: 2.3ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 61.8941,  83.2528, 102.9661, 157.9527],\n",
            "        [156.2391,  74.5010, 176.9298, 143.8726]], device='cuda:0')\n",
            "001308_person_0.jpg\n",
            "001308_person_1.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.0ms\n",
            "Speed: 4.6ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[1.5565e+02, 1.0725e+02, 2.3236e+02, 2.5356e+02],\n",
            "        [2.1205e+01, 1.0243e+02, 9.3622e+01, 2.3708e+02],\n",
            "        [6.8620e+01, 9.8184e+01, 1.6576e+02, 2.6500e+02],\n",
            "        [1.2378e+02, 9.9961e+01, 1.6658e+02, 2.0552e+02],\n",
            "        [5.5227e-02, 4.8494e+01, 2.1821e+01, 2.5699e+02]], device='cuda:0')\n",
            "001221_person_0.jpg\n",
            "001221_person_1.jpg\n",
            "001221_person_2.jpg\n",
            "001221_person_3.jpg\n",
            "001221_person_4.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.7ms\n",
            "Speed: 3.0ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[103.2049,  36.2814, 233.7432, 331.0000]], device='cuda:0')\n",
            "005273_person_0.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 3.2ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[127.7714,   1.0389, 365.4050, 276.2194]], device='cuda:0')\n",
            "005027_person_0.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[180.8382,  45.9235, 328.2136, 298.5505],\n",
            "        [ 24.5501, 110.3296,  90.1154, 299.7894],\n",
            "        [358.3423,   1.2867, 449.8229, 298.4532]], device='cuda:0')\n",
            "001669_person_0.jpg\n",
            "001669_person_1.jpg\n",
            "001669_person_2.jpg\n",
            "\n",
            "0: 448x640 4 persons, 13.0ms\n",
            "Speed: 3.1ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[4.8757e-02, 1.6596e+02, 1.5087e+02, 3.3245e+02],\n",
            "        [1.3544e+02, 6.4352e+01, 5.0000e+02, 3.3300e+02],\n",
            "        [4.9987e+01, 1.2413e+00, 3.1479e+02, 3.3273e+02],\n",
            "        [4.6274e+02, 1.7901e+00, 5.0000e+02, 3.2920e+02]], device='cuda:0')\n",
            "001188_person_0.jpg\n",
            "001188_person_1.jpg\n",
            "001188_person_2.jpg\n",
            "001188_person_3.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 3.5ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[194.1723,  12.1372, 441.0627, 334.8041]], device='cuda:0')\n",
            "001544_person_0.jpg\n",
            "\n",
            "0: 448x640 4 persons, 13.1ms\n",
            "Speed: 2.6ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[337.6370,  90.1546, 406.2486, 300.9576],\n",
            "        [233.2133, 186.4933, 313.1634, 332.0618],\n",
            "        [ 19.9505, 170.9401,  81.3637, 327.4583],\n",
            "        [ 78.4242, 233.9767, 138.6618, 330.1962]], device='cuda:0')\n",
            "001561_person_0.jpg\n",
            "001561_person_1.jpg\n",
            "001561_person_2.jpg\n",
            "001561_person_3.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[387.3087,  80.0163, 499.8752, 259.2104]], device='cuda:0')\n",
            "001553_person_0.jpg\n",
            "\n",
            "0: 448x640 4 persons, 13.0ms\n",
            "Speed: 4.7ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 87.5465, 141.1750, 171.6912, 301.4876],\n",
            "        [215.0813,  35.2489, 491.4690, 328.8939],\n",
            "        [170.0728, 136.5285, 224.7731, 290.7875],\n",
            "        [403.6260,   4.5014, 499.6339, 325.6680]], device='cuda:0')\n",
            "005055_person_0.jpg\n",
            "005055_person_1.jpg\n",
            "005055_person_2.jpg\n",
            "005055_person_3.jpg\n",
            "\n",
            "0: 448x640 4 persons, 13.0ms\n",
            "Speed: 3.8ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[144.2438,  13.2331, 181.0043, 122.8564],\n",
            "        [241.4990, 104.6700, 277.2212, 193.9931],\n",
            "        [288.1188, 236.8442, 321.7826, 334.0801],\n",
            "        [210.0308, 185.2475, 244.4487, 221.4978]], device='cuda:0')\n",
            "001589_person_0.jpg\n",
            "001589_person_1.jpg\n",
            "001589_person_2.jpg\n",
            "001589_person_3.jpg\n",
            "\n",
            "0: 448x640 8 persons, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[310.3192,  36.0787, 380.2605, 277.2877],\n",
            "        [128.3524,  73.0217, 162.8568, 197.1497],\n",
            "        [162.9972,  33.2569, 222.6588, 243.2910],\n",
            "        [253.8981,  41.2086, 316.7029, 262.0892],\n",
            "        [ 69.3353,  30.3929, 132.6043, 268.1718],\n",
            "        [201.5210,  56.6909, 236.6586, 198.0099],\n",
            "        [388.6615,  52.0794, 419.9665, 213.8952],\n",
            "        [306.1060,  41.4549, 334.5729, 209.5099]], device='cuda:0')\n",
            "005216_person_0.jpg\n",
            "005216_person_1.jpg\n",
            "005216_person_2.jpg\n",
            "005216_person_3.jpg\n",
            "005216_person_4.jpg\n",
            "005216_person_5.jpg\n",
            "005216_person_6.jpg\n",
            "005216_person_7.jpg\n",
            "\n",
            "0: 448x640 5 persons, 16.2ms\n",
            "Speed: 2.7ms preprocess, 16.2ms inference, 6.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 50.7206, 151.7430, 134.4200, 332.5799],\n",
            "        [318.0991, 154.5277, 380.2812, 330.9912],\n",
            "        [158.8247,  75.3586, 350.7946, 330.3401],\n",
            "        [120.7245,  14.9230, 219.8892, 332.9196],\n",
            "        [210.7814, 139.3622, 277.5608, 333.0000]], device='cuda:0')\n",
            "001358_person_0.jpg\n",
            "001358_person_1.jpg\n",
            "001358_person_2.jpg\n",
            "001358_person_3.jpg\n",
            "001358_person_4.jpg\n",
            "\n",
            "0: 512x640 2 persons, 14.1ms\n",
            "Speed: 3.6ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "tensor([[ 80.9064,  74.0174, 287.5848, 399.4242],\n",
            "        [378.4523,   0.0000, 499.9846, 400.0000]], device='cuda:0')\n",
            "001271_person_0.jpg\n",
            "001271_person_1.jpg\n",
            "\n",
            "0: 448x640 1 person, 16.4ms\n",
            "Speed: 2.5ms preprocess, 16.4ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[270.3397, 106.3902, 373.7076, 214.2638]], device='cuda:0')\n",
            "001476_person_0.jpg\n",
            "\n",
            "0: 480x640 3 persons, 14.1ms\n",
            "Speed: 3.8ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[1.1424e-01, 8.8987e+01, 1.7855e+02, 3.7500e+02],\n",
            "        [1.7549e+02, 1.0137e+02, 3.0790e+02, 3.3559e+02],\n",
            "        [3.2669e+02, 8.8792e+01, 4.2733e+02, 3.3869e+02]], device='cuda:0')\n",
            "001546_person_0.jpg\n",
            "001546_person_1.jpg\n",
            "001546_person_2.jpg\n",
            "\n",
            "0: 448x640 2 persons, 23.3ms\n",
            "Speed: 2.8ms preprocess, 23.3ms inference, 2.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 39.8414,  81.9238, 132.1873, 258.0364],\n",
            "        [164.2486, 108.2944, 277.7291, 278.2524]], device='cuda:0')\n",
            "001516_person_0.jpg\n",
            "001516_person_1.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.1ms\n",
            "Speed: 3.0ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[359.0380,  49.4875, 455.8681, 288.0665]], device='cuda:0')\n",
            "001852_person_0.jpg\n",
            "\n",
            "0: 448x640 4 persons, 20.9ms\n",
            "Speed: 3.4ms preprocess, 20.9ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[245.5871,  92.6170, 379.6497, 333.0000],\n",
            "        [135.2377, 107.0665, 250.9238, 332.8623],\n",
            "        [ 23.7754, 108.1611, 146.5764, 333.0000],\n",
            "        [261.5296, 103.2201, 485.6906, 332.4563]], device='cuda:0')\n",
            "005099_person_0.jpg\n",
            "005099_person_1.jpg\n",
            "005099_person_2.jpg\n",
            "005099_person_3.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[224.5545,  85.3589, 390.8615, 333.6467],\n",
            "        [103.1917,  51.7563, 340.6727, 334.0000]], device='cuda:0')\n",
            "005268_person_0.jpg\n",
            "005268_person_1.jpg\n",
            "\n",
            "0: 544x640 6 persons, 18.6ms\n",
            "Speed: 3.2ms preprocess, 18.6ms inference, 1.9ms postprocess per image at shape (1, 3, 544, 640)\n",
            "tensor([[274.3958, 166.9317, 348.1803, 358.9995],\n",
            "        [114.2399,  96.2114, 234.2652, 279.2627],\n",
            "        [227.4760, 120.7579, 282.9465, 306.1467],\n",
            "        [353.2994, 184.2355, 445.7816, 373.7794],\n",
            "        [196.3797,  87.4230, 252.4603, 204.2321],\n",
            "        [330.5051, 170.0118, 395.0929, 370.9744]], device='cuda:0')\n",
            "001426_person_0.jpg\n",
            "001426_person_1.jpg\n",
            "001426_person_2.jpg\n",
            "001426_person_3.jpg\n",
            "001426_person_4.jpg\n",
            "001426_person_5.jpg\n",
            "\n",
            "0: 640x480 9 persons, 14.3ms\n",
            "Speed: 2.0ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "tensor([[313.9391,  33.7172, 451.7201, 361.9319],\n",
            "        [  0.0000,   0.0000, 189.0321, 439.1523],\n",
            "        [205.6727, 116.3601, 275.0525, 368.2226],\n",
            "        [421.5238,  47.0306, 479.9226, 355.4624],\n",
            "        [  0.0000,  46.1342,  32.6351, 291.9777],\n",
            "        [116.9590,  47.6887, 161.2252, 220.9710],\n",
            "        [108.0333,  50.9218, 154.0314, 223.0571],\n",
            "        [  0.0000,  98.2726,  28.1468, 296.4195],\n",
            "        [100.4309,  35.4316, 148.3895, 220.7855]], device='cuda:0')\n",
            "001865_person_0.jpg\n",
            "001865_person_1.jpg\n",
            "001865_person_2.jpg\n",
            "001865_person_3.jpg\n",
            "001865_person_4.jpg\n",
            "001865_person_5.jpg\n",
            "001865_person_6.jpg\n",
            "001865_person_7.jpg\n",
            "001865_person_8.jpg\n",
            "\n",
            "0: 448x640 5 persons, 17.5ms\n",
            "Speed: 2.7ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[369.4443, 209.1533, 439.5501, 334.7842],\n",
            "        [221.9208, 157.4034, 249.0755, 212.9750],\n",
            "        [279.3375, 166.2652, 314.8890, 237.3226],\n",
            "        [120.1987, 213.3176, 137.2983, 266.2852],\n",
            "        [306.7960, 205.4535, 325.1777, 280.5552]], device='cuda:0')\n",
            "001814_person_0.jpg\n",
            "001814_person_1.jpg\n",
            "001814_person_2.jpg\n",
            "001814_person_3.jpg\n",
            "001814_person_4.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[157.2304,  65.4067, 268.1527, 244.0137],\n",
            "        [ 92.3506,  30.5866, 184.5593, 236.8435],\n",
            "        [371.8734,  42.2469, 432.9183, 230.3745],\n",
            "        [ 26.1754,  40.0514, 139.8964, 261.4794],\n",
            "        [316.5938,  71.7539, 376.1468, 213.0609]], device='cuda:0')\n",
            "001729_person_0.jpg\n",
            "001729_person_1.jpg\n",
            "001729_person_2.jpg\n",
            "001729_person_3.jpg\n",
            "001729_person_4.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.6ms\n",
            "Speed: 2.8ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 92.2423,  48.4394, 248.0171, 299.8578],\n",
            "        [263.4173,   9.1159, 338.8860, 250.5939],\n",
            "        [199.3679,  75.2752, 256.7436, 213.1674]], device='cuda:0')\n",
            "001186_person_0.jpg\n",
            "001186_person_1.jpg\n",
            "001186_person_2.jpg\n",
            "\n",
            "0: 480x640 2 persons, 14.3ms\n",
            "Speed: 3.4ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[363.7797, 119.9374, 420.4402, 288.9017],\n",
            "        [ 38.0135, 115.3783,  73.0979, 184.0029]], device='cuda:0')\n",
            "005260_person_0.jpg\n",
            "005260_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 14.4ms\n",
            "Speed: 3.9ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[121.9153, 164.3520, 233.8118, 343.9468],\n",
            "        [117.3560, 122.2545, 214.0640, 252.8327]], device='cuda:0')\n",
            "001236_person_0.jpg\n",
            "001236_person_1.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.0ms\n",
            "Speed: 3.0ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 63.7046, 190.6400, 170.9443, 336.1111],\n",
            "        [155.0242, 185.8897, 243.3540, 334.3331],\n",
            "        [276.3707, 219.5524, 330.3674, 336.4605],\n",
            "        [459.7116, 259.2183, 500.0000, 336.1963],\n",
            "        [  7.4985, 207.5761, 103.9728, 336.3286]], device='cuda:0')\n",
            "001177_person_0.jpg\n",
            "001177_person_1.jpg\n",
            "001177_person_2.jpg\n",
            "001177_person_3.jpg\n",
            "001177_person_4.jpg\n",
            "\n",
            "0: 480x640 3 persons, 14.2ms\n",
            "Speed: 3.5ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[398.3627, 169.7053, 457.5790, 310.7113],\n",
            "        [155.4241, 196.5924, 191.7549, 315.6591],\n",
            "        [130.3106, 194.4772, 174.5368, 316.2346]], device='cuda:0')\n",
            "001038_person_0.jpg\n",
            "001038_person_1.jpg\n",
            "001038_person_2.jpg\n",
            "\n",
            "0: 448x640 4 persons, 14.1ms\n",
            "Speed: 3.1ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[319.2891,   0.0000, 478.9304, 332.0689],\n",
            "        [243.0225, 105.1243, 401.0117, 333.0000],\n",
            "        [408.8014,   1.3699, 500.0000, 333.0000],\n",
            "        [237.3021, 105.1608, 335.7271, 333.0000]], device='cuda:0')\n",
            "001697_person_0.jpg\n",
            "001697_person_1.jpg\n",
            "001697_person_2.jpg\n",
            "001697_person_3.jpg\n",
            "\n",
            "0: 480x640 1 person, 15.2ms\n",
            "Speed: 2.8ms preprocess, 15.2ms inference, 7.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[ 18.3221,  30.1819, 461.1698, 375.0000]], device='cuda:0')\n",
            "001689_person_0.jpg\n",
            "\n",
            "0: 384x640 4 persons, 12.2ms\n",
            "Speed: 2.7ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "tensor([[ 24.7195,  19.0115, 143.4436, 203.2702],\n",
            "        [381.5787, 101.8683, 439.2507, 286.8983],\n",
            "        [278.4718, 100.4640, 329.1006, 155.1006],\n",
            "        [345.9463, 240.0284, 483.9706, 300.0000]], device='cuda:0')\n",
            "001109_person_0.jpg\n",
            "001109_person_1.jpg\n",
            "001109_person_2.jpg\n",
            "001109_person_3.jpg\n",
            "\n",
            "0: 448x640 2 persons, 15.2ms\n",
            "Speed: 3.3ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[235.8359,  34.8015, 383.9460, 134.9948],\n",
            "        [ 31.2140,  15.9877, 171.3460, 257.0000]], device='cuda:0')\n",
            "001202_person_0.jpg\n",
            "001202_person_1.jpg\n",
            "\n",
            "0: 480x640 4 persons, 14.4ms\n",
            "Speed: 2.9ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[215.5393, 126.7163, 260.4908, 272.8861],\n",
            "        [154.4854, 125.4756, 240.2912, 352.3871],\n",
            "        [327.7628, 140.3564, 364.2634, 241.3603],\n",
            "        [271.3624, 124.3176, 328.8870, 273.1635]], device='cuda:0')\n",
            "001773_person_0.jpg\n",
            "001773_person_1.jpg\n",
            "001773_person_2.jpg\n",
            "001773_person_3.jpg\n",
            "\n",
            "0: 448x640 2 persons, 18.1ms\n",
            "Speed: 4.9ms preprocess, 18.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[256.7423,  88.8024, 389.0959, 332.0000],\n",
            "        [185.1095, 119.3851, 272.6198, 319.7766]], device='cuda:0')\n",
            "005026_person_0.jpg\n",
            "005026_person_1.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[364.5927, 260.7135, 379.1824, 287.3514],\n",
            "        [395.2699, 252.5500, 407.8560, 313.0165],\n",
            "        [384.6859, 259.7209, 398.7885, 316.2935],\n",
            "        [386.7785, 256.7657, 402.8726, 316.1106],\n",
            "        [389.6212, 255.0394, 405.9847, 313.4116]], device='cuda:0')\n",
            "001147_person_0.jpg\n",
            "001147_person_1.jpg\n",
            "001147_person_2.jpg\n",
            "001147_person_3.jpg\n",
            "001147_person_4.jpg\n",
            "\n",
            "0: 448x640 2 persons, 14.5ms\n",
            "Speed: 3.2ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[110.6940,  99.9540, 206.5010, 342.7915],\n",
            "        [223.7419, 130.2847, 288.3467, 343.7615]], device='cuda:0')\n",
            "001479_person_0.jpg\n",
            "001479_person_1.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.6ms\n",
            "Speed: 4.7ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 16.3947,  71.7184, 174.5439, 336.1739],\n",
            "        [227.9641,  55.7716, 340.2312, 336.1201],\n",
            "        [347.9673,  34.9981, 460.8542, 335.7886],\n",
            "        [167.2173,  84.7585, 247.1425, 336.7646],\n",
            "        [303.3220,  73.1828, 369.4138, 332.9754]], device='cuda:0')\n",
            "005200_person_0.jpg\n",
            "005200_person_1.jpg\n",
            "005200_person_2.jpg\n",
            "005200_person_3.jpg\n",
            "005200_person_4.jpg\n",
            "\n",
            "0: 448x640 9 persons, 13.1ms\n",
            "Speed: 5.6ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[1.3978e+02, 9.7226e+01, 2.7593e+02, 3.3375e+02],\n",
            "        [2.9784e+02, 1.2224e+02, 3.7661e+02, 3.3400e+02],\n",
            "        [3.5098e+02, 9.1124e+01, 4.5319e+02, 3.3400e+02],\n",
            "        [5.8625e+00, 8.5306e+01, 1.1472e+02, 3.3394e+02],\n",
            "        [4.4494e+02, 1.0306e+02, 5.0000e+02, 3.3308e+02],\n",
            "        [7.3871e+01, 9.0728e+01, 1.6722e+02, 3.3338e+02],\n",
            "        [4.4723e-01, 8.4791e+01, 5.1113e+01, 3.3162e+02],\n",
            "        [2.3920e-01, 7.7306e+01, 2.1821e+01, 3.3400e+02],\n",
            "        [2.1466e-01, 6.3660e+01, 3.6006e+01, 3.3400e+02]], device='cuda:0')\n",
            "005155_person_0.jpg\n",
            "005155_person_1.jpg\n",
            "005155_person_2.jpg\n",
            "005155_person_3.jpg\n",
            "005155_person_4.jpg\n",
            "005155_person_5.jpg\n",
            "005155_person_6.jpg\n",
            "005155_person_7.jpg\n",
            "005155_person_8.jpg\n",
            "\n",
            "0: 480x640 5 persons, 16.7ms\n",
            "Speed: 3.0ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[164.6954,  71.9210, 300.2015, 374.3990],\n",
            "        [391.1421,  44.4923, 499.8137, 375.0000],\n",
            "        [  0.0000,  56.2441, 127.6039, 375.0000],\n",
            "        [281.4557,  81.2641, 353.7489, 355.8998],\n",
            "        [334.1492,  68.3170, 412.7736, 373.2522]], device='cuda:0')\n",
            "001841_person_0.jpg\n",
            "001841_person_1.jpg\n",
            "001841_person_2.jpg\n",
            "001841_person_3.jpg\n",
            "001841_person_4.jpg\n",
            "\n",
            "0: 448x640 11 persons, 14.2ms\n",
            "Speed: 3.5ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[224.2115, 142.3792, 283.2027, 325.7829],\n",
            "        [322.5240, 142.8883, 391.4201, 332.4651],\n",
            "        [ 65.6571, 166.6258, 112.4084, 294.3644],\n",
            "        [147.9195, 161.7611, 195.1474, 275.9698],\n",
            "        [260.9687, 151.8230, 294.4223, 277.5152],\n",
            "        [366.1796, 151.5679, 390.5530, 207.7570],\n",
            "        [308.8421, 152.9217, 342.4967, 274.5841],\n",
            "        [438.1075, 153.1150, 443.3296, 173.9799],\n",
            "        [295.2519, 157.7744, 313.7477, 210.6139],\n",
            "        [143.3207, 165.3637, 162.9781, 255.2968],\n",
            "        [437.2372, 154.5636, 444.4511, 174.1491]], device='cuda:0')\n",
            "001305_person_0.jpg\n",
            "001305_person_1.jpg\n",
            "001305_person_2.jpg\n",
            "001305_person_3.jpg\n",
            "001305_person_4.jpg\n",
            "001305_person_5.jpg\n",
            "001305_person_6.jpg\n",
            "001305_person_7.jpg\n",
            "001305_person_8.jpg\n",
            "001305_person_9.jpg\n",
            "001305_person_10.jpg\n",
            "\n",
            "0: 480x640 10 persons, 68.1ms\n",
            "Speed: 3.9ms preprocess, 68.1ms inference, 12.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[161.1488, 148.0846, 230.3260, 333.2131],\n",
            "        [136.8032, 142.2270, 186.5770, 312.1867],\n",
            "        [372.7520, 146.1988, 441.8055, 361.4369],\n",
            "        [202.8922, 129.9791, 248.3021, 313.7385],\n",
            "        [352.6620, 147.5887, 397.7813, 332.9348],\n",
            "        [279.4500, 143.9802, 334.0032, 342.4992],\n",
            "        [222.7125, 143.8344, 282.4774, 339.4682],\n",
            "        [315.8782, 137.9888, 370.6080, 341.0138],\n",
            "        [268.5057, 142.5550, 301.6667, 315.0907],\n",
            "        [192.9867, 136.7550, 212.4070, 168.9796]], device='cuda:0')\n",
            "001391_person_0.jpg\n",
            "001391_person_1.jpg\n",
            "001391_person_2.jpg\n",
            "001391_person_3.jpg\n",
            "001391_person_4.jpg\n",
            "001391_person_5.jpg\n",
            "001391_person_6.jpg\n",
            "001391_person_7.jpg\n",
            "001391_person_8.jpg\n",
            "001391_person_9.jpg\n",
            "\n",
            "0: 448x640 11 persons, 13.8ms\n",
            "Speed: 4.2ms preprocess, 13.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[317.9888, 123.8171, 395.9772, 330.0000],\n",
            "        [397.9315, 119.8138, 470.9156, 330.0000],\n",
            "        [240.4870, 114.6157, 302.4901, 216.5673],\n",
            "        [134.8670, 125.5202, 177.3620, 211.3029],\n",
            "        [374.1559, 112.3515, 416.6606, 182.1770],\n",
            "        [439.2171, 134.0242, 498.8588, 329.2350],\n",
            "        [458.0464, 112.7841, 500.0000, 203.4308],\n",
            "        [345.3893,  99.6391, 403.5092, 235.5808],\n",
            "        [240.8106, 115.4110, 301.2647, 329.6523],\n",
            "        [170.0930, 110.8965, 204.1927, 193.9608],\n",
            "        [457.1264, 111.6380, 499.9321, 244.1447]], device='cuda:0')\n",
            "001042_person_0.jpg\n",
            "001042_person_1.jpg\n",
            "001042_person_2.jpg\n",
            "001042_person_3.jpg\n",
            "001042_person_4.jpg\n",
            "001042_person_5.jpg\n",
            "001042_person_6.jpg\n",
            "001042_person_7.jpg\n",
            "001042_person_8.jpg\n",
            "001042_person_9.jpg\n",
            "001042_person_10.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.0ms\n",
            "Speed: 2.5ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 79.1841,  58.3581, 190.7424, 318.2440],\n",
            "        [307.0195,  35.6679, 426.7133, 332.2010],\n",
            "        [237.5570,  30.7259, 323.7664, 332.4303],\n",
            "        [391.4696,  19.9351, 493.2679, 333.0000],\n",
            "        [197.6509,  60.3842, 251.4031, 268.8886]], device='cuda:0')\n",
            "005188_person_0.jpg\n",
            "005188_person_1.jpg\n",
            "005188_person_2.jpg\n",
            "005188_person_3.jpg\n",
            "005188_person_4.jpg\n",
            "\n",
            "0: 448x640 6 persons, 13.0ms\n",
            "Speed: 3.7ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[143.9087,  61.3548, 242.6442, 331.6565],\n",
            "        [293.7044,  63.7056, 444.6510, 331.5752],\n",
            "        [206.8413,  81.8272, 270.0406, 273.2819],\n",
            "        [ 16.1829,  76.6742,  91.2370, 330.3811],\n",
            "        [ 97.2887, 104.6358, 118.9152, 175.6006],\n",
            "        [  0.0000,  66.1121,  19.7290, 308.5456]], device='cuda:0')\n",
            "005071_person_0.jpg\n",
            "005071_person_1.jpg\n",
            "005071_person_2.jpg\n",
            "005071_person_3.jpg\n",
            "005071_person_4.jpg\n",
            "005071_person_5.jpg\n",
            "\n",
            "0: 320x640 15 persons, 11.4ms\n",
            "Speed: 5.3ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "tensor([[ 64.0337,  63.3703, 114.0084, 202.1451],\n",
            "        [  6.1931,  66.9966,  58.4396, 202.8992],\n",
            "        [398.5427,  83.3486, 435.9803, 194.1521],\n",
            "        [244.7802,  83.6739, 276.4490, 196.9540],\n",
            "        [344.9042,  85.5354, 377.6685, 189.1557],\n",
            "        [303.4041,  75.2682, 338.7501, 195.1975],\n",
            "        [128.7779,  69.0201, 179.7234, 204.5892],\n",
            "        [192.6933,  74.2279, 234.3240, 202.3787],\n",
            "        [170.4358,  86.4289, 197.7130, 190.0803],\n",
            "        [275.0664,  79.5598, 311.1285, 199.3403],\n",
            "        [118.6241,  87.9177, 142.1102, 187.2345],\n",
            "        [234.3124,  92.2014, 251.4652, 185.7431],\n",
            "        [272.0035,  78.8481, 291.5207, 193.1490],\n",
            "        [214.8109,  79.0936, 242.0503, 189.1456],\n",
            "        [229.4147,  90.7633, 247.8622, 188.3594]], device='cuda:0')\n",
            "001257_person_0.jpg\n",
            "001257_person_1.jpg\n",
            "001257_person_2.jpg\n",
            "001257_person_3.jpg\n",
            "001257_person_4.jpg\n",
            "001257_person_5.jpg\n",
            "001257_person_6.jpg\n",
            "001257_person_7.jpg\n",
            "001257_person_8.jpg\n",
            "001257_person_9.jpg\n",
            "001257_person_10.jpg\n",
            "001257_person_11.jpg\n",
            "001257_person_12.jpg\n",
            "001257_person_13.jpg\n",
            "001257_person_14.jpg\n",
            "\n",
            "0: 512x640 5 persons, 13.8ms\n",
            "Speed: 3.8ms preprocess, 13.8ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "tensor([[139.2104,  35.4239, 292.6291, 377.0988],\n",
            "        [  0.0000,  48.3498, 184.8055, 377.9458],\n",
            "        [353.8807,  38.3547, 500.0000, 377.6320],\n",
            "        [296.9509,  68.9115, 422.9275, 377.7608],\n",
            "        [280.9375,  87.5537, 359.2445, 375.6425]], device='cuda:0')\n",
            "001647_person_0.jpg\n",
            "001647_person_1.jpg\n",
            "001647_person_2.jpg\n",
            "001647_person_3.jpg\n",
            "001647_person_4.jpg\n",
            "\n",
            "0: 480x640 4 persons, 15.1ms\n",
            "Speed: 3.4ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[130.3037,  44.9421, 189.5993, 214.3425],\n",
            "        [230.5166,  54.3148, 278.5705, 205.2534],\n",
            "        [276.4017,  64.5085, 329.2182, 276.3340],\n",
            "        [305.3941,  41.5029, 359.8140, 203.9801]], device='cuda:0')\n",
            "001696_person_0.jpg\n",
            "001696_person_1.jpg\n",
            "001696_person_2.jpg\n",
            "001696_person_3.jpg\n",
            "\n",
            "0: 480x640 8 persons, 14.2ms\n",
            "Speed: 3.0ms preprocess, 14.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[6.9919e+01, 1.7357e+02, 1.3032e+02, 3.4584e+02],\n",
            "        [1.2306e+02, 1.7910e+02, 1.6437e+02, 3.3098e+02],\n",
            "        [1.5193e+02, 1.6937e+02, 2.0928e+02, 3.7453e+02],\n",
            "        [3.8747e+02, 1.5482e+02, 4.9969e+02, 3.7436e+02],\n",
            "        [2.1558e+02, 1.8239e+02, 2.7343e+02, 3.4303e+02],\n",
            "        [1.4321e-01, 1.8240e+02, 5.9384e+01, 3.7500e+02],\n",
            "        [3.0374e+02, 1.7713e+02, 3.5525e+02, 3.4325e+02],\n",
            "        [3.8127e+02, 1.7572e+02, 4.4161e+02, 3.6027e+02]], device='cuda:0')\n",
            "005237_person_0.jpg\n",
            "005237_person_1.jpg\n",
            "005237_person_2.jpg\n",
            "005237_person_3.jpg\n",
            "005237_person_4.jpg\n",
            "005237_person_5.jpg\n",
            "005237_person_6.jpg\n",
            "005237_person_7.jpg\n",
            "\n",
            "0: 384x640 5 persons, 11.7ms\n",
            "Speed: 3.0ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "tensor([[ 84.6062,  40.3369, 171.6111, 299.8330],\n",
            "        [202.7477, 105.6768, 242.0914, 229.2633],\n",
            "        [287.2859, 100.6943, 327.4908, 240.7466],\n",
            "        [ 60.2816,  83.7732, 104.8983, 251.6344],\n",
            "        [ 84.3848,  62.6881, 132.2535, 271.8997]], device='cuda:0')\n",
            "001303_person_0.jpg\n",
            "001303_person_1.jpg\n",
            "001303_person_2.jpg\n",
            "001303_person_3.jpg\n",
            "001303_person_4.jpg\n",
            "\n",
            "0: 480x640 3 persons, 16.0ms\n",
            "Speed: 3.6ms preprocess, 16.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[198.8816,  56.9078, 304.2300, 331.4978],\n",
            "        [ 87.4567,  63.9406, 183.5835, 290.4087],\n",
            "        [286.7271,  35.0481, 369.9701, 375.0000]], device='cuda:0')\n",
            "001725_person_0.jpg\n",
            "001725_person_1.jpg\n",
            "001725_person_2.jpg\n",
            "\n",
            "0: 416x640 10 persons, 13.5ms\n",
            "Speed: 3.9ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[385.6876,  89.9373, 487.2391, 324.0000],\n",
            "        [314.9228, 116.7303, 388.3878, 324.0000],\n",
            "        [ 75.4150, 120.0515, 132.3580, 323.7610],\n",
            "        [  1.1458, 149.7109,  34.9803, 246.7224],\n",
            "        [163.7738, 141.2303, 222.5129, 323.0006],\n",
            "        [119.4923,  57.7749, 319.9111, 322.3781],\n",
            "        [ 52.7051, 149.9348,  79.6498, 245.6267],\n",
            "        [127.8769, 142.7075, 154.2377, 236.6165],\n",
            "        [476.9613,  76.0254, 500.0000, 324.0000],\n",
            "        [153.3905, 148.8697, 173.7451, 206.6478]], device='cuda:0')\n",
            "005097_person_0.jpg\n",
            "005097_person_1.jpg\n",
            "005097_person_2.jpg\n",
            "005097_person_3.jpg\n",
            "005097_person_4.jpg\n",
            "005097_person_5.jpg\n",
            "005097_person_6.jpg\n",
            "005097_person_7.jpg\n",
            "005097_person_8.jpg\n",
            "005097_person_9.jpg\n",
            "\n",
            "0: 448x640 6 persons, 13.9ms\n",
            "Speed: 3.3ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 46.6679,  43.1932, 128.7269, 262.4724],\n",
            "        [371.6742,  47.0063, 464.3651, 287.0795],\n",
            "        [296.9356,  61.8073, 352.4943, 228.0491],\n",
            "        [140.0901,  44.2293, 214.4266, 263.0126],\n",
            "        [213.4520,  41.6815, 293.0283, 313.6648],\n",
            "        [349.1498,  60.8072, 410.5036, 245.9235]], device='cuda:0')\n",
            "001093_person_0.jpg\n",
            "001093_person_1.jpg\n",
            "001093_person_2.jpg\n",
            "001093_person_3.jpg\n",
            "001093_person_4.jpg\n",
            "001093_person_5.jpg\n",
            "\n",
            "0: 480x640 3 persons, 16.2ms\n",
            "Speed: 3.9ms preprocess, 16.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[133.3648,  77.5343, 252.7796, 353.2067],\n",
            "        [257.6723,  78.6919, 343.5155, 352.9557],\n",
            "        [222.0525,  71.1435, 284.8331, 264.4956]], device='cuda:0')\n",
            "001961_person_0.jpg\n",
            "001961_person_1.jpg\n",
            "001961_person_2.jpg\n",
            "\n",
            "0: 480x640 6 persons, 13.1ms\n",
            "Speed: 3.8ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[315.7363, 116.3857, 381.4705, 341.8839],\n",
            "        [228.1640, 143.0094, 269.7680, 294.3917],\n",
            "        [149.2862, 144.1752, 193.3186, 337.8550],\n",
            "        [176.4816, 147.4544, 229.5468, 317.3849],\n",
            "        [270.7879, 136.7394, 317.5511, 308.9505],\n",
            "        [ 78.4008, 146.5980, 160.2018, 374.9918]], device='cuda:0')\n",
            "001514_person_0.jpg\n",
            "001514_person_1.jpg\n",
            "001514_person_2.jpg\n",
            "001514_person_3.jpg\n",
            "001514_person_4.jpg\n",
            "001514_person_5.jpg\n",
            "\n",
            "0: 448x640 9 persons, 14.1ms\n",
            "Speed: 5.1ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[357.1943,  87.2565, 499.3307, 318.2991],\n",
            "        [186.9392,  81.3487, 288.1009, 334.0000],\n",
            "        [  0.0000,  76.6921,  92.5977, 333.9910],\n",
            "        [ 66.4166,  52.2187, 166.4398, 333.6083],\n",
            "        [290.1540,  86.1085, 341.7735, 281.8565],\n",
            "        [317.5505,  74.7687, 394.1785, 327.2411],\n",
            "        [141.4758,  84.3362, 206.2192, 331.3696],\n",
            "        [256.0988,  79.1164, 315.6667, 322.9745],\n",
            "        [427.7166,  79.9249, 492.7609, 313.1759]], device='cuda:0')\n",
            "001908_person_0.jpg\n",
            "001908_person_1.jpg\n",
            "001908_person_2.jpg\n",
            "001908_person_3.jpg\n",
            "001908_person_4.jpg\n",
            "001908_person_5.jpg\n",
            "001908_person_6.jpg\n",
            "001908_person_7.jpg\n",
            "001908_person_8.jpg\n",
            "\n",
            "0: 480x640 7 persons, 13.9ms\n",
            "Speed: 3.3ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[257.9881, 134.9158, 332.1680, 332.4738],\n",
            "        [197.3225, 140.4688, 254.1817, 332.8031],\n",
            "        [380.8879, 149.6914, 424.6965, 263.4296],\n",
            "        [239.6156, 146.4405, 268.9507, 273.0613],\n",
            "        [ 70.7266, 127.4521,  98.0941, 201.3483],\n",
            "        [145.3623, 153.4150, 176.1637, 226.9704],\n",
            "        [179.0047, 156.3724, 199.2219, 221.2802]], device='cuda:0')\n",
            "001930_person_0.jpg\n",
            "001930_person_1.jpg\n",
            "001930_person_2.jpg\n",
            "001930_person_3.jpg\n",
            "001930_person_4.jpg\n",
            "001930_person_5.jpg\n",
            "001930_person_6.jpg\n",
            "\n",
            "0: 480x640 9 persons, 13.2ms\n",
            "Speed: 3.1ms preprocess, 13.2ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[446.4323, 193.8466, 484.1249, 299.4302],\n",
            "        [ 30.5859, 183.1488,  83.5755, 329.1682],\n",
            "        [323.3929, 188.0905, 364.4674, 306.3524],\n",
            "        [158.5540, 193.9567, 193.9044, 325.0858],\n",
            "        [103.1670, 197.1490, 153.5906, 329.6221],\n",
            "        [278.9071, 198.4196, 321.4244, 314.4467],\n",
            "        [361.3012, 201.7189, 402.9586, 307.9046],\n",
            "        [209.9278, 198.0651, 247.1491, 323.2075],\n",
            "        [390.2395, 193.1153, 423.5394, 302.3567]], device='cuda:0')\n",
            "001164_person_0.jpg\n",
            "001164_person_1.jpg\n",
            "001164_person_2.jpg\n",
            "001164_person_3.jpg\n",
            "001164_person_4.jpg\n",
            "001164_person_5.jpg\n",
            "001164_person_6.jpg\n",
            "001164_person_7.jpg\n",
            "001164_person_8.jpg\n",
            "\n",
            "0: 480x640 11 persons, 13.3ms\n",
            "Speed: 3.1ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[3.0131e+02, 1.5348e+02, 3.5748e+02, 2.9922e+02],\n",
            "        [2.3121e+02, 1.5865e+02, 2.7343e+02, 2.6968e+02],\n",
            "        [1.1331e+02, 1.3584e+02, 1.6215e+02, 2.7123e+02],\n",
            "        [3.5881e+02, 1.4516e+02, 3.9955e+02, 2.5648e+02],\n",
            "        [7.0750e+01, 1.2312e+02, 1.1386e+02, 2.7750e+02],\n",
            "        [4.1110e+01, 1.2702e+02, 8.1981e+01, 2.6415e+02],\n",
            "        [1.6527e+02, 1.3191e+02, 1.9545e+02, 2.4115e+02],\n",
            "        [3.1385e-02, 1.0523e+02, 7.2903e+01, 3.0000e+02],\n",
            "        [2.7155e+02, 1.5385e+02, 3.0992e+02, 2.8956e+02],\n",
            "        [1.7094e+02, 1.4229e+02, 2.1625e+02, 2.6956e+02],\n",
            "        [1.0513e+02, 1.3470e+02, 1.3286e+02, 2.5456e+02]], device='cuda:0')\n",
            "001205_person_0.jpg\n",
            "001205_person_1.jpg\n",
            "001205_person_2.jpg\n",
            "001205_person_3.jpg\n",
            "001205_person_4.jpg\n",
            "001205_person_5.jpg\n",
            "001205_person_6.jpg\n",
            "001205_person_7.jpg\n",
            "001205_person_8.jpg\n",
            "001205_person_9.jpg\n",
            "001205_person_10.jpg\n",
            "\n",
            "0: 448x640 9 persons, 14.3ms\n",
            "Speed: 2.7ms preprocess, 14.3ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 85.7452,  87.8065, 136.1660, 239.1981],\n",
            "        [357.0656,  86.2410, 419.2920, 283.3956],\n",
            "        [240.8023,  93.9153, 293.1682, 250.7280],\n",
            "        [141.1285,  95.9961, 184.5030, 238.0382],\n",
            "        [186.9964,  94.6552, 230.0465, 243.4409],\n",
            "        [289.5775,  97.6357, 344.1945, 266.6653],\n",
            "        [224.4025,  96.4505, 257.0656, 219.7424],\n",
            "        [346.9248,  97.3634, 378.5194, 227.5487],\n",
            "        [283.3671,  90.5169, 308.9210, 239.8723]], device='cuda:0')\n",
            "001758_person_0.jpg\n",
            "001758_person_1.jpg\n",
            "001758_person_2.jpg\n",
            "001758_person_3.jpg\n",
            "001758_person_4.jpg\n",
            "001758_person_5.jpg\n",
            "001758_person_6.jpg\n",
            "001758_person_7.jpg\n",
            "001758_person_8.jpg\n",
            "\n",
            "0: 480x640 6 persons, 14.3ms\n",
            "Speed: 8.2ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[198.8218, 112.5334, 299.2811, 354.3250],\n",
            "        [101.5710, 126.4137, 218.4091, 375.0000],\n",
            "        [267.2750, 118.7665, 321.5117, 303.7702],\n",
            "        [319.5053, 109.0391, 387.1438, 335.8763],\n",
            "        [184.8004, 120.6481, 233.4508, 303.2066],\n",
            "        [  0.0000,  91.1701,  36.0903, 375.0000]], device='cuda:0')\n",
            "001932_person_0.jpg\n",
            "001932_person_1.jpg\n",
            "001932_person_2.jpg\n",
            "001932_person_3.jpg\n",
            "001932_person_4.jpg\n",
            "001932_person_5.jpg\n",
            "\n",
            "0: 448x640 5 persons, 14.5ms\n",
            "Speed: 2.7ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[130.2845,  86.2343, 284.2392, 334.0000],\n",
            "        [311.3582,  85.5225, 442.6501, 333.3266],\n",
            "        [  0.0000,  33.6841, 108.4438, 334.0000],\n",
            "        [417.7935,  43.9211, 499.9786, 333.9589],\n",
            "        [262.3398,  70.9930, 380.1853, 329.0988]], device='cuda:0')\n",
            "005240_person_0.jpg\n",
            "005240_person_1.jpg\n",
            "005240_person_2.jpg\n",
            "005240_person_3.jpg\n",
            "005240_person_4.jpg\n",
            "\n",
            "0: 448x640 9 persons, 13.1ms\n",
            "Speed: 3.0ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[442.7817, 137.7360, 494.9387, 275.5132],\n",
            "        [250.0176, 135.3665, 293.2444, 262.0092],\n",
            "        [369.9373, 137.9013, 419.3182, 282.6138],\n",
            "        [172.2833, 131.4616, 222.8925, 280.2476],\n",
            "        [340.7220, 147.0362, 376.2231, 269.0683],\n",
            "        [296.4651, 135.1025, 345.6270, 271.5442],\n",
            "        [286.8890, 141.0555, 310.4284, 240.0494],\n",
            "        [398.7043, 138.7514, 432.7681, 254.4528],\n",
            "        [166.0331, 141.4387, 192.7565, 250.9382]], device='cuda:0')\n",
            "001282_person_0.jpg\n",
            "001282_person_1.jpg\n",
            "001282_person_2.jpg\n",
            "001282_person_3.jpg\n",
            "001282_person_4.jpg\n",
            "001282_person_5.jpg\n",
            "001282_person_6.jpg\n",
            "001282_person_7.jpg\n",
            "001282_person_8.jpg\n",
            "\n",
            "0: 448x640 9 persons, 20.4ms\n",
            "Speed: 2.8ms preprocess, 20.4ms inference, 10.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[166.5845, 114.3155, 290.0776, 333.2258],\n",
            "        [ 14.3560, 133.8985,  77.6175, 294.8792],\n",
            "        [292.8675, 102.8577, 351.0513, 277.2393],\n",
            "        [135.9489, 127.0760, 176.4055, 277.1064],\n",
            "        [360.0377,  65.8253, 499.3644, 335.0000],\n",
            "        [ 68.3218, 135.6376, 121.0909, 269.8531],\n",
            "        [217.9770, 115.5885, 273.9600, 268.0916],\n",
            "        [424.6314,  29.9972, 500.0000, 331.6675],\n",
            "        [479.3085,  32.5529, 499.8768, 125.5717]], device='cuda:0')\n",
            "001360_person_0.jpg\n",
            "001360_person_1.jpg\n",
            "001360_person_2.jpg\n",
            "001360_person_3.jpg\n",
            "001360_person_4.jpg\n",
            "001360_person_5.jpg\n",
            "001360_person_6.jpg\n",
            "001360_person_7.jpg\n",
            "001360_person_8.jpg\n",
            "\n",
            "0: 352x640 7 persons, 42.6ms\n",
            "Speed: 2.3ms preprocess, 42.6ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "tensor([[ 76.5279,  33.6491, 151.8979, 244.1168],\n",
            "        [331.4370,  53.7106, 396.1637, 180.8209],\n",
            "        [ 12.5215,  54.0683, 103.6152, 265.7618],\n",
            "        [391.1570,  42.6156, 453.7663, 173.7555],\n",
            "        [277.2321,  53.9235, 325.6046, 193.7740],\n",
            "        [181.0846,  51.3002, 247.4034, 215.5969],\n",
            "        [220.6843,  58.2946, 297.4443, 209.9995]], device='cuda:0')\n",
            "005275_person_0.jpg\n",
            "005275_person_1.jpg\n",
            "005275_person_2.jpg\n",
            "005275_person_3.jpg\n",
            "005275_person_4.jpg\n",
            "005275_person_5.jpg\n",
            "005275_person_6.jpg\n",
            "\n",
            "0: 480x640 11 persons, 14.0ms\n",
            "Speed: 3.2ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[417.2103, 138.0889, 476.3268, 328.9582],\n",
            "        [136.8580, 120.5364, 208.2248, 353.0000],\n",
            "        [205.2994, 112.7722, 287.1445, 352.5013],\n",
            "        [352.5432, 138.4066, 409.4151, 293.0265],\n",
            "        [ 25.7664, 106.5825, 101.1895, 353.0000],\n",
            "        [282.0555, 108.0745, 356.7335, 352.1168],\n",
            "        [ 92.3655, 131.4606, 135.5490, 321.1551],\n",
            "        [327.7482, 137.1838, 368.1962, 300.8078],\n",
            "        [189.5264, 138.8913, 221.0725, 294.6339],\n",
            "        [126.0179, 143.5545, 149.8194, 245.3638],\n",
            "        [261.5081, 136.0891, 291.4864, 299.5208]], device='cuda:0')\n",
            "001146_person_0.jpg\n",
            "001146_person_1.jpg\n",
            "001146_person_2.jpg\n",
            "001146_person_3.jpg\n",
            "001146_person_4.jpg\n",
            "001146_person_5.jpg\n",
            "001146_person_6.jpg\n",
            "001146_person_7.jpg\n",
            "001146_person_8.jpg\n",
            "001146_person_9.jpg\n",
            "001146_person_10.jpg\n",
            "\n",
            "0: 448x640 5 persons, 14.1ms\n",
            "Speed: 2.6ms preprocess, 14.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[151.7360,  47.0023, 288.1355, 266.7394],\n",
            "        [ 24.1755,  31.9003, 151.6513, 266.4974],\n",
            "        [266.3045,  24.7006, 398.7369, 267.0000],\n",
            "        [133.9651,  63.3959, 195.8378, 266.9088],\n",
            "        [ 13.5313,  51.4276,  74.7220, 265.3757]], device='cuda:0')\n",
            "001987_person_0.jpg\n",
            "001987_person_1.jpg\n",
            "001987_person_2.jpg\n",
            "001987_person_3.jpg\n",
            "001987_person_4.jpg\n",
            "\n",
            "0: 448x640 10 persons, 13.0ms\n",
            "Speed: 5.0ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[398.5735,  76.7868, 499.7796, 333.1027],\n",
            "        [190.7902,  73.4910, 288.8304, 336.2330],\n",
            "        [  0.0000,  41.0561, 122.0409, 336.2654],\n",
            "        [ 94.5788, 102.8687, 153.2417, 226.3004],\n",
            "        [342.2238,  74.1024, 429.4439, 336.0792],\n",
            "        [267.8904,  86.3040, 314.5533, 240.2020],\n",
            "        [174.0110,  88.5808, 211.8370, 253.8531],\n",
            "        [305.4247,  77.3108, 361.2476, 281.2791],\n",
            "        [ 64.7101, 107.4302,  93.9547, 221.1469],\n",
            "        [466.1969,  77.7110, 500.0000, 275.8124]], device='cuda:0')\n",
            "001883_person_0.jpg\n",
            "001883_person_1.jpg\n",
            "001883_person_2.jpg\n",
            "001883_person_3.jpg\n",
            "001883_person_4.jpg\n",
            "001883_person_5.jpg\n",
            "001883_person_6.jpg\n",
            "001883_person_7.jpg\n",
            "001883_person_8.jpg\n",
            "001883_person_9.jpg\n",
            "\n",
            "0: 448x640 10 persons, 13.1ms\n",
            "Speed: 3.5ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[124.7124, 112.8472, 175.7266, 247.6586],\n",
            "        [370.9468, 111.3449, 402.1639, 251.3776],\n",
            "        [259.4499, 105.4523, 300.0156, 247.6203],\n",
            "        [288.9762, 111.8261, 330.9306, 260.0436],\n",
            "        [330.9123, 110.4745, 393.9028, 277.9624],\n",
            "        [212.7068, 109.8445, 250.1604, 243.8259],\n",
            "        [161.4317, 116.8500, 194.7936, 229.2348],\n",
            "        [195.2288, 111.9881, 225.1180, 230.8255],\n",
            "        [175.9490, 115.5616, 198.9081, 215.5547],\n",
            "        [322.1819, 114.3243, 345.8284, 232.0074]], device='cuda:0')\n",
            "001388_person_0.jpg\n",
            "001388_person_1.jpg\n",
            "001388_person_2.jpg\n",
            "001388_person_3.jpg\n",
            "001388_person_4.jpg\n",
            "001388_person_5.jpg\n",
            "001388_person_6.jpg\n",
            "001388_person_7.jpg\n",
            "001388_person_8.jpg\n",
            "001388_person_9.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[3.0501e+02, 7.7813e+01, 4.0290e+02, 3.3300e+02],\n",
            "        [1.5726e+02, 7.5485e+01, 2.5980e+02, 3.3300e+02],\n",
            "        [4.0064e+02, 7.8249e+01, 4.7759e+02, 3.3300e+02],\n",
            "        [9.6547e+01, 1.1731e+02, 1.6161e+02, 3.3284e+02],\n",
            "        [5.8955e-02, 1.0827e+02, 6.0075e+01, 3.0639e+02]], device='cuda:0')\n",
            "001971_person_0.jpg\n",
            "001971_person_1.jpg\n",
            "001971_person_2.jpg\n",
            "001971_person_3.jpg\n",
            "001971_person_4.jpg\n",
            "\n",
            "0: 448x640 13 persons, 13.2ms\n",
            "Speed: 4.7ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[211.4377,  76.1796, 317.4883, 235.8194],\n",
            "        [ 95.4309,  82.1045, 217.4406, 235.0595],\n",
            "        [  0.0000,  14.4171,  99.0935, 331.9591],\n",
            "        [400.1993,  76.4068, 429.7769, 105.3021],\n",
            "        [303.5458,  55.3848, 499.3159, 243.4351],\n",
            "        [ 86.8887,  91.2434, 155.0902, 235.5556],\n",
            "        [301.2076,  53.7331, 498.8091, 327.7195],\n",
            "        [ 34.6865,  72.1929, 135.7223, 262.3244],\n",
            "        [430.1096,   0.0000, 500.0000, 325.6531],\n",
            "        [304.3823,  91.6515, 381.8811, 239.5571],\n",
            "        [475.6355,   0.0000, 500.0000, 306.3962],\n",
            "        [  0.0000, 287.1607,  22.0545, 326.3032],\n",
            "        [427.9778, 114.9325, 500.0000, 332.0000]], device='cuda:0')\n",
            "001124_person_0.jpg\n",
            "001124_person_1.jpg\n",
            "001124_person_2.jpg\n",
            "001124_person_3.jpg\n",
            "001124_person_4.jpg\n",
            "001124_person_5.jpg\n",
            "001124_person_6.jpg\n",
            "001124_person_7.jpg\n",
            "001124_person_8.jpg\n",
            "001124_person_9.jpg\n",
            "001124_person_10.jpg\n",
            "001124_person_11.jpg\n",
            "001124_person_12.jpg\n",
            "\n",
            "0: 448x640 9 persons, 13.3ms\n",
            "Speed: 3.7ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[283.2443, 182.6392, 348.7492, 313.5786],\n",
            "        [198.4248, 203.0673, 318.1982, 334.0000],\n",
            "        [ 21.2500, 177.7659,  98.1671, 249.8702],\n",
            "        [ 88.0150, 178.9840, 141.2813, 235.7162],\n",
            "        [145.8373, 170.5472, 187.0282, 229.6513],\n",
            "        [342.5997, 182.0562, 390.3535, 248.7556],\n",
            "        [191.3716, 170.2703, 234.9987, 220.6062],\n",
            "        [263.0561, 170.3939, 295.5745, 209.0617],\n",
            "        [343.1138, 189.9137, 412.5519, 262.1445]], device='cuda:0')\n",
            "001547_person_0.jpg\n",
            "001547_person_1.jpg\n",
            "001547_person_2.jpg\n",
            "001547_person_3.jpg\n",
            "001547_person_4.jpg\n",
            "001547_person_5.jpg\n",
            "001547_person_6.jpg\n",
            "001547_person_7.jpg\n",
            "001547_person_8.jpg\n",
            "\n",
            "0: 480x640 5 persons, 14.1ms\n",
            "Speed: 3.4ms preprocess, 14.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[6.0871e+01, 1.1243e+02, 1.7281e+02, 3.4582e+02],\n",
            "        [2.4136e+02, 1.3355e+02, 3.4994e+02, 3.7129e+02],\n",
            "        [3.4896e+02, 1.2041e+02, 4.4357e+02, 3.7188e+02],\n",
            "        [4.2626e-01, 1.2063e+02, 1.1907e+02, 3.7300e+02],\n",
            "        [3.9594e+02, 1.1046e+02, 4.9984e+02, 3.7300e+02]], device='cuda:0')\n",
            "001453_person_0.jpg\n",
            "001453_person_1.jpg\n",
            "001453_person_2.jpg\n",
            "001453_person_3.jpg\n",
            "001453_person_4.jpg\n",
            "\n",
            "0: 480x640 5 persons, 13.2ms\n",
            "Speed: 3.6ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[172.2398, 108.1660, 288.2430, 374.7979],\n",
            "        [289.7117, 103.8606, 408.0818, 374.6281],\n",
            "        [ 51.5688,  97.2904, 168.5996, 375.0000],\n",
            "        [408.5249,  82.2466, 499.8382, 375.0000],\n",
            "        [  0.0000,  84.2553, 104.9745, 375.0000]], device='cuda:0')\n",
            "001637_person_0.jpg\n",
            "001637_person_1.jpg\n",
            "001637_person_2.jpg\n",
            "001637_person_3.jpg\n",
            "001637_person_4.jpg\n",
            "\n",
            "0: 384x640 14 persons, 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "tensor([[8.9018e+01, 1.0927e+02, 2.1962e+02, 2.9957e+02],\n",
            "        [2.5553e+01, 9.0213e+01, 1.1758e+02, 2.9929e+02],\n",
            "        [2.5643e+02, 1.0831e+02, 3.9379e+02, 2.9969e+02],\n",
            "        [3.6833e+02, 1.0670e+02, 5.0436e+02, 3.0000e+02],\n",
            "        [3.5305e-01, 9.2196e+01, 5.6605e+01, 2.5537e+02],\n",
            "        [4.8885e+02, 9.5053e+01, 5.3500e+02, 1.7905e+02],\n",
            "        [1.7082e+00, 7.4430e+01, 3.9892e+01, 1.4068e+02],\n",
            "        [3.1428e+02, 9.0413e+01, 3.5946e+02, 1.5122e+02],\n",
            "        [2.6576e+02, 7.0969e+01, 3.1414e+02, 1.4436e+02],\n",
            "        [5.0092e+01, 7.0539e+01, 1.0075e+02, 1.1984e+02],\n",
            "        [3.5965e+02, 1.0125e+02, 4.1814e+02, 1.6127e+02],\n",
            "        [1.8974e+02, 8.5428e+01, 2.5394e+02, 1.3714e+02],\n",
            "        [1.6320e+02, 8.6892e+01, 2.0282e+02, 1.2778e+02],\n",
            "        [1.0854e+02, 9.0490e+01, 1.2646e+02, 1.1652e+02]], device='cuda:0')\n",
            "001792_person_0.jpg\n",
            "001792_person_1.jpg\n",
            "001792_person_2.jpg\n",
            "001792_person_3.jpg\n",
            "001792_person_4.jpg\n",
            "001792_person_5.jpg\n",
            "001792_person_6.jpg\n",
            "001792_person_7.jpg\n",
            "001792_person_8.jpg\n",
            "001792_person_9.jpg\n",
            "001792_person_10.jpg\n",
            "001792_person_11.jpg\n",
            "001792_person_12.jpg\n",
            "001792_person_13.jpg\n",
            "\n",
            "0: 448x640 9 persons, 14.5ms\n",
            "Speed: 3.8ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 94.7959, 128.1682, 164.8269, 325.7685],\n",
            "        [ 27.0484, 136.5537,  86.5657, 329.0745],\n",
            "        [172.7436, 121.3809, 240.7555, 329.5396],\n",
            "        [230.5915, 114.6745, 303.9096, 329.8759],\n",
            "        [294.5561, 139.6616, 360.5895, 331.3458],\n",
            "        [468.3893, 123.0582, 500.0000, 286.7448],\n",
            "        [149.5556, 135.3282, 180.2836, 252.6062],\n",
            "        [429.7252, 112.4615, 480.0533, 267.8565],\n",
            "        [213.2037, 130.0848, 243.6136, 255.9620]], device='cuda:0')\n",
            "005129_person_0.jpg\n",
            "005129_person_1.jpg\n",
            "005129_person_2.jpg\n",
            "005129_person_3.jpg\n",
            "005129_person_4.jpg\n",
            "005129_person_5.jpg\n",
            "005129_person_6.jpg\n",
            "005129_person_7.jpg\n",
            "005129_person_8.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.2ms\n",
            "Speed: 3.7ms preprocess, 13.2ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[292.3189,  73.7381, 410.1893, 334.0000],\n",
            "        [154.9566,  67.5134, 267.2982, 334.0000]], device='cuda:0')\n",
            "001417_person_0.jpg\n",
            "001417_person_1.jpg\n",
            "\n",
            "0: 448x640 6 persons, 14.4ms\n",
            "Speed: 3.3ms preprocess, 14.4ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[331.2581, 100.4255, 429.8656, 332.2754],\n",
            "        [255.2000,  91.9543, 350.2702, 332.2980],\n",
            "        [143.1035,  99.2576, 245.7194, 332.1637],\n",
            "        [ 32.2610,  95.5219, 119.5391, 332.2493],\n",
            "        [219.4973,  95.7825, 284.3931, 333.0000],\n",
            "        [ 98.2546, 118.4329, 152.7578, 333.0000]], device='cuda:0')\n",
            "001157_person_0.jpg\n",
            "001157_person_1.jpg\n",
            "001157_person_2.jpg\n",
            "001157_person_3.jpg\n",
            "001157_person_4.jpg\n",
            "001157_person_5.jpg\n",
            "\n",
            "0: 576x640 16 persons, 43.8ms\n",
            "Speed: 5.9ms preprocess, 43.8ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "tensor([[2.2182e+02, 2.3250e+02, 2.8261e+02, 4.3495e+02],\n",
            "        [1.0187e+02, 2.2241e+02, 1.7103e+02, 4.3500e+02],\n",
            "        [3.1197e+02, 2.2447e+02, 3.7438e+02, 3.9620e+02],\n",
            "        [3.6133e+02, 2.3398e+02, 3.9546e+02, 3.5259e+02],\n",
            "        [2.6536e+02, 2.2754e+02, 3.1078e+02, 3.8600e+02],\n",
            "        [5.2945e+01, 2.2606e+02, 9.8755e+01, 3.9403e+02],\n",
            "        [4.0898e+02, 2.2730e+02, 4.3373e+02, 2.7849e+02],\n",
            "        [4.2952e+02, 2.3753e+02, 4.7914e+02, 3.6918e+02],\n",
            "        [2.6652e-01, 2.1486e+02, 6.4574e+01, 4.3303e+02],\n",
            "        [1.9204e+02, 2.3192e+02, 2.4351e+02, 3.8959e+02],\n",
            "        [4.4702e+02, 2.1797e+02, 4.9997e+02, 3.9695e+02],\n",
            "        [1.7989e+02, 2.2509e+02, 2.1793e+02, 3.4974e+02],\n",
            "        [9.4525e+01, 2.3160e+02, 1.3109e+02, 4.0121e+02],\n",
            "        [3.0381e+01, 2.2380e+02, 6.9788e+01, 4.0029e+02],\n",
            "        [0.0000e+00, 2.2778e+02, 1.8806e+01, 4.2624e+02],\n",
            "        [4.5334e-02, 2.3362e+02, 1.6542e+01, 3.9007e+02]], device='cuda:0')\n",
            "001661_person_0.jpg\n",
            "001661_person_1.jpg\n",
            "001661_person_2.jpg\n",
            "001661_person_3.jpg\n",
            "001661_person_4.jpg\n",
            "001661_person_5.jpg\n",
            "001661_person_6.jpg\n",
            "001661_person_7.jpg\n",
            "001661_person_8.jpg\n",
            "001661_person_9.jpg\n",
            "001661_person_10.jpg\n",
            "001661_person_11.jpg\n",
            "001661_person_12.jpg\n",
            "001661_person_13.jpg\n",
            "001661_person_14.jpg\n",
            "001661_person_15.jpg\n",
            "\n",
            "0: 640x640 3 persons, 17.8ms\n",
            "Speed: 3.2ms preprocess, 17.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[144.9262, 106.3586, 315.1823, 462.1082],\n",
            "        [279.1805, 102.4766, 607.7920, 518.9134],\n",
            "        [  0.0000,   5.9343, 206.6247, 574.6660]], device='cuda:0')\n",
            "001214_jpg.rf.1341753c952df6e0889b1f781af22c77_person_0.jpg\n",
            "001214_jpg.rf.1341753c952df6e0889b1f781af22c77_person_1.jpg\n",
            "001214_jpg.rf.1341753c952df6e0889b1f781af22c77_person_2.jpg\n",
            "\n",
            "0: 640x640 3 persons, 16.3ms\n",
            "Speed: 3.0ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[2.5890e+02, 6.7122e+00, 6.4000e+02, 6.4000e+02],\n",
            "        [3.7968e+01, 2.4119e+00, 4.2662e+02, 6.1877e+02],\n",
            "        [0.0000e+00, 3.8129e-01, 1.2523e+02, 5.3751e+02]], device='cuda:0')\n",
            "001344_jpg.rf.1c7c5ed37e407155e2d7cf0216f893ed_person_0.jpg\n",
            "001344_jpg.rf.1c7c5ed37e407155e2d7cf0216f893ed_person_1.jpg\n",
            "001344_jpg.rf.1c7c5ed37e407155e2d7cf0216f893ed_person_2.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 52.2326,  89.0326, 393.6061, 605.5892]], device='cuda:0')\n",
            "image_217_jpg.rf.1e4d9fbf97a087648742078ff5941b67_person_0.jpg\n",
            "\n",
            "0: 640x640 2 persons, 16.5ms\n",
            "Speed: 2.6ms preprocess, 16.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[264.3296,  54.1396, 497.4968, 637.3986],\n",
            "        [115.2719, 289.6323, 381.9106, 639.2958]], device='cuda:0')\n",
            "YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-34_jpg.rf.01d6349eabce5613415c586a543c9f0b_person_0.jpg\n",
            "YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-34_jpg.rf.01d6349eabce5613415c586a543c9f0b_person_1.jpg\n",
            "\n",
            "0: 640x640 2 persons, 18.3ms\n",
            "Speed: 3.8ms preprocess, 18.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[407.8804,  33.8562, 502.2836, 119.4297],\n",
            "        [239.1423,  30.8769, 341.1740, 249.7884]], device='cuda:0')\n",
            "-1532-_png_jpg.rf.08a5b6985f24bfe7efefdb45c04469c2_person_0.jpg\n",
            "-1532-_png_jpg.rf.08a5b6985f24bfe7efefdb45c04469c2_person_1.jpg\n",
            "\n",
            "0: 640x640 3 persons, 18.3ms\n",
            "Speed: 3.7ms preprocess, 18.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[1.4247e+02, 2.4036e+02, 2.3358e+02, 4.4810e+02],\n",
            "        [7.4647e+01, 2.1876e+02, 1.7874e+02, 4.8406e+02],\n",
            "        [2.5525e-01, 1.2916e+02, 1.0714e+02, 5.8459e+02]], device='cuda:0')\n",
            "001246_jpg.rf.05724a1c67f05c4fbd6fb3d872bc98b4_person_0.jpg\n",
            "001246_jpg.rf.05724a1c67f05c4fbd6fb3d872bc98b4_person_1.jpg\n",
            "001246_jpg.rf.05724a1c67f05c4fbd6fb3d872bc98b4_person_2.jpg\n",
            "\n",
            "0: 640x640 4 persons, 16.3ms\n",
            "Speed: 3.7ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 53.2357, 179.3552, 162.2587, 498.0956],\n",
            "        [351.0620, 207.3547, 441.8268, 492.8798],\n",
            "        [227.3995, 185.2703, 372.1655, 507.5139],\n",
            "        [140.8329, 151.2977, 292.5754, 640.0000]], device='cuda:0')\n",
            "-1832-_png_jpg.rf.d56cb4edba4c059bdfa7f2c581d26a19_person_0.jpg\n",
            "-1832-_png_jpg.rf.d56cb4edba4c059bdfa7f2c581d26a19_person_1.jpg\n",
            "-1832-_png_jpg.rf.d56cb4edba4c059bdfa7f2c581d26a19_person_2.jpg\n",
            "-1832-_png_jpg.rf.d56cb4edba4c059bdfa7f2c581d26a19_person_3.jpg\n",
            "\n",
            "0: 640x640 1 person, 18.1ms\n",
            "Speed: 5.4ms preprocess, 18.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[  0.0000,   0.0000, 630.6891, 636.7914]], device='cuda:0')\n",
            "RPReplay_Final1667001201_MP4-459_jpg.rf.352ca04a4c2cc5df8bf2dd3d8c01c120_person_0.jpg\n",
            "\n",
            "0: 640x640 2 persons, 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[307.3823, 151.5476, 343.7278, 243.3775],\n",
            "        [281.3588, 239.5960, 306.4942, 372.1361]], device='cuda:0')\n",
            "ppe_1189_jpg.rf.f6977c81a4c10b70e7d36a5b90956b94_person_0.jpg\n",
            "ppe_1189_jpg.rf.f6977c81a4c10b70e7d36a5b90956b94_person_1.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 3.5ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[147.2259,  84.8167, 252.8587, 538.0889]], device='cuda:0')\n",
            "helmet999958_jpg.rf.c20b516a6a36203afcd0cd426a11b71c_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 3.6ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[329.1804, 241.1077, 466.7200, 444.7588]], device='cuda:0')\n",
            "-2391-_png_jpg.rf.8781d03c5c7efeeb7fdaeb65e1dd0fc7_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.5ms\n",
            "Speed: 3.6ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[321.1211, 128.8806, 446.3032, 637.9897]], device='cuda:0')\n",
            "ppe_1202_jpg.rf.c2963de6cf48426e058b866f008b72f0_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[148.0234,  85.1477, 250.9179, 538.2551]], device='cuda:0')\n",
            "helmet999965_jpg.rf.756eaab75a0b323e1784e0115c0a35e8_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 3.6ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[209.1119, 341.5750, 367.6282, 640.0000]], device='cuda:0')\n",
            "00570_jpg.rf.8ef9857b5322e813de5cbd952d01b137_person_0.jpg\n",
            "\n",
            "0: 640x640 5 persons, 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[191.4478, 215.2228, 245.8095, 482.7943],\n",
            "        [301.8542, 182.3663, 370.0886, 497.9463],\n",
            "        [343.2192, 182.3875, 389.2670, 423.0801],\n",
            "        [271.1048, 237.5604, 305.7053, 407.3152],\n",
            "        [233.8139, 219.9740, 280.7376, 439.6094]], device='cuda:0')\n",
            "00550_jpg.rf.956081908ad03e1ac7531cf1445c948a_person_0.jpg\n",
            "00550_jpg.rf.956081908ad03e1ac7531cf1445c948a_person_1.jpg\n",
            "00550_jpg.rf.956081908ad03e1ac7531cf1445c948a_person_2.jpg\n",
            "00550_jpg.rf.956081908ad03e1ac7531cf1445c948a_person_3.jpg\n",
            "00550_jpg.rf.956081908ad03e1ac7531cf1445c948a_person_4.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.5ms\n",
            "Speed: 2.4ms preprocess, 16.5ms inference, 14.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[126.1152,  93.2177, 244.5348, 532.8401]], device='cuda:0')\n",
            "helmet999934_jpg.rf.7ac9be3c69da7e2d4edf14bf94abc29c_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 20.0ms\n",
            "Speed: 2.2ms preprocess, 20.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 48.7183, 269.6553, 536.1767, 640.0000]], device='cuda:0')\n",
            "02567_jpg.rf.d1327d7fe3826f7ae0976fc5e90f94aa_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[154.5266,  86.7432, 357.0387, 623.8321]], device='cuda:0')\n",
            "image_108_jpg.rf.a2a7f9dd16e7a136d02fb42a810d1644_person_0.jpg\n",
            "\n",
            "0: 640x640 7 persons, 20.2ms\n",
            "Speed: 2.2ms preprocess, 20.2ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[138.8851, 372.5749, 172.1179, 453.1321],\n",
            "        [198.4681, 356.5275, 242.7036, 494.7542],\n",
            "        [396.6897, 210.0037, 432.9081, 314.8451],\n",
            "        [ 36.1067, 365.4958,  71.6975, 461.2271],\n",
            "        [199.6290, 560.9813, 238.2515, 640.0000],\n",
            "        [ 33.2132, 591.5035,  79.1736, 640.0000],\n",
            "        [140.0350, 599.7123, 166.0925, 640.0000]], device='cuda:0')\n",
            "-2082-_png_jpg.rf.7b89e77b67643cd28c0ce52ed7e588e3_person_0.jpg\n",
            "-2082-_png_jpg.rf.7b89e77b67643cd28c0ce52ed7e588e3_person_1.jpg\n",
            "-2082-_png_jpg.rf.7b89e77b67643cd28c0ce52ed7e588e3_person_2.jpg\n",
            "-2082-_png_jpg.rf.7b89e77b67643cd28c0ce52ed7e588e3_person_3.jpg\n",
            "-2082-_png_jpg.rf.7b89e77b67643cd28c0ce52ed7e588e3_person_4.jpg\n",
            "-2082-_png_jpg.rf.7b89e77b67643cd28c0ce52ed7e588e3_person_5.jpg\n",
            "-2082-_png_jpg.rf.7b89e77b67643cd28c0ce52ed7e588e3_person_6.jpg\n",
            "\n",
            "0: 640x640 4 persons, 36.8ms\n",
            "Speed: 9.4ms preprocess, 36.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[378.8213, 175.5907, 514.7274, 314.0005],\n",
            "        [307.6454, 188.1646, 445.1174, 409.3339],\n",
            "        [148.6392,  31.3680, 218.3809, 223.7818],\n",
            "        [605.3612, 195.4447, 639.6945, 314.7422]], device='cuda:0')\n",
            "-2435-_png_jpg.rf.d88968da6353df51746244bb3619cc5a_person_0.jpg\n",
            "-2435-_png_jpg.rf.d88968da6353df51746244bb3619cc5a_person_1.jpg\n",
            "-2435-_png_jpg.rf.d88968da6353df51746244bb3619cc5a_person_2.jpg\n",
            "-2435-_png_jpg.rf.d88968da6353df51746244bb3619cc5a_person_3.jpg\n",
            "\n",
            "0: 640x640 2 persons, 22.3ms\n",
            "Speed: 2.3ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[114.5621, 114.3000, 285.0275, 417.9258],\n",
            "        [298.8204, 177.2634, 419.3847, 327.6603]], device='cuda:0')\n",
            "-2168-_png_jpg.rf.cd5ce7cad7216bda1d5a2e90d9ccdd4e_person_0.jpg\n",
            "-2168-_png_jpg.rf.cd5ce7cad7216bda1d5a2e90d9ccdd4e_person_1.jpg\n",
            "\n",
            "0: 640x640 (no detections), 16.3ms\n",
            "Speed: 2.5ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections found in image YouTube-FREE-AerialStockFootage_CityUrban-YKY3Mm5P1tE-720p_mp4-7_jpg.rf.3ad1e4933e697179f9d54d06d31830e4.jpg\n",
            "\n",
            "0: 640x640 1 person, 19.2ms\n",
            "Speed: 2.9ms preprocess, 19.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 71.3256, 218.0142, 207.8893, 520.3516]], device='cuda:0')\n",
            "-2091-_png_jpg.rf.24a38225fa17a89f450e6fcf90584bb5_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 19.7ms\n",
            "Speed: 4.1ms preprocess, 19.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[266.5345,  77.3654, 516.3193, 625.2013]], device='cuda:0')\n",
            "006369_jpg.rf.5a962f5cea4ec0c8758fdca0b035728d_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 4.1ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[  0.0000, 115.4391, 285.9116, 640.0000]], device='cuda:0')\n",
            "-2398-_png_jpg.rf.bcec23ae95199cde62866097de49e92c_person_0.jpg\n",
            "\n",
            "0: 640x640 3 persons, 16.3ms\n",
            "Speed: 2.2ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[378.5712, 217.4881, 445.2587, 382.3848],\n",
            "        [318.1840, 101.1455, 378.0929, 271.7193],\n",
            "        [209.8288, 294.0928, 312.2381, 493.3851]], device='cuda:0')\n",
            "001107_jpg.rf.ddc4b21edf46aaa9518dfe33a381ff29_person_0.jpg\n",
            "001107_jpg.rf.ddc4b21edf46aaa9518dfe33a381ff29_person_1.jpg\n",
            "001107_jpg.rf.ddc4b21edf46aaa9518dfe33a381ff29_person_2.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[163.9440,  86.6592, 275.5457, 536.0298]], device='cuda:0')\n",
            "helmet999908_jpg.rf.eb7ec7dc0f18f138ae8ef798ce105624_person_0.jpg\n",
            "\n",
            "0: 640x640 5 persons, 21.0ms\n",
            "Speed: 2.1ms preprocess, 21.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 74.2197,  14.3812, 341.4174, 629.4677],\n",
            "        [382.0869,  75.3373, 585.5304, 622.9093],\n",
            "        [ 99.7768, 310.0476, 141.6975, 434.2504],\n",
            "        [140.0034, 312.8300, 171.0976, 448.8582],\n",
            "        [300.7081,  80.6736, 454.0928, 620.9249]], device='cuda:0')\n",
            "006336_jpg.rf.4882fa277106be1378a906016ab8a711_person_0.jpg\n",
            "006336_jpg.rf.4882fa277106be1378a906016ab8a711_person_1.jpg\n",
            "006336_jpg.rf.4882fa277106be1378a906016ab8a711_person_2.jpg\n",
            "006336_jpg.rf.4882fa277106be1378a906016ab8a711_person_3.jpg\n",
            "006336_jpg.rf.4882fa277106be1378a906016ab8a711_person_4.jpg\n",
            "\n",
            "0: 640x640 3 persons, 16.7ms\n",
            "Speed: 4.5ms preprocess, 16.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[410.3740, 157.0395, 510.0234, 482.3604],\n",
            "        [315.5956, 168.6894, 400.9451, 479.4377],\n",
            "        [275.5736, 166.4578, 337.2573, 478.1821]], device='cuda:0')\n",
            "-4100-_png_jpg.rf.aebfe87c2b4f556f03d14fc3cc6facf7_person_0.jpg\n",
            "-4100-_png_jpg.rf.aebfe87c2b4f556f03d14fc3cc6facf7_person_1.jpg\n",
            "-4100-_png_jpg.rf.aebfe87c2b4f556f03d14fc3cc6facf7_person_2.jpg\n",
            "\n",
            "0: 640x640 6 persons, 19.0ms\n",
            "Speed: 2.3ms preprocess, 19.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[200.7147, 272.5546, 298.3193, 573.6682],\n",
            "        [296.5461, 298.1384, 384.8005, 549.5317],\n",
            "        [103.7847, 264.5652, 191.5245, 524.5028],\n",
            "        [419.6691, 275.5335, 545.0197, 556.6567],\n",
            "        [162.8942, 261.0193, 222.7740, 529.1910],\n",
            "        [400.4336, 289.5346, 465.1151, 555.4804]], device='cuda:0')\n",
            "-2180-_png_jpg.rf.9d63bb305e7747d22fe9a196dcc5ce13_person_0.jpg\n",
            "-2180-_png_jpg.rf.9d63bb305e7747d22fe9a196dcc5ce13_person_1.jpg\n",
            "-2180-_png_jpg.rf.9d63bb305e7747d22fe9a196dcc5ce13_person_2.jpg\n",
            "-2180-_png_jpg.rf.9d63bb305e7747d22fe9a196dcc5ce13_person_3.jpg\n",
            "-2180-_png_jpg.rf.9d63bb305e7747d22fe9a196dcc5ce13_person_4.jpg\n",
            "-2180-_png_jpg.rf.9d63bb305e7747d22fe9a196dcc5ce13_person_5.jpg\n",
            "\n",
            "0: 640x640 2 persons, 16.9ms\n",
            "Speed: 2.4ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[277.0328, 187.3382, 330.0978, 367.1071],\n",
            "        [310.9327, 250.0329, 358.4501, 423.9133]], device='cuda:0')\n",
            "006276_jpg.rf.4da030f18de405fcd561b953c26f9383_person_0.jpg\n",
            "006276_jpg.rf.4da030f18de405fcd561b953c26f9383_person_1.jpg\n",
            "\n",
            "0: 640x640 (no detections), 16.3ms\n",
            "Speed: 2.4ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections found in image youtube-6_jpg.rf.a9f31f242ee7d731c625ed07f6002b9b.jpg\n",
            "\n",
            "0: 640x640 7 persons, 16.2ms\n",
            "Speed: 2.2ms preprocess, 16.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[260.3524, 136.6976, 351.2526, 359.1132],\n",
            "        [218.2848, 308.7067, 384.6057, 640.0000],\n",
            "        [  0.0000, 101.3339, 243.4882, 640.0000],\n",
            "        [133.4933, 130.6419, 252.8410, 377.6449],\n",
            "        [575.9023, 164.0101, 638.9517, 277.5507],\n",
            "        [413.0076, 110.5175, 640.0000, 640.0000],\n",
            "        [378.5397,  96.0907, 490.4006, 540.3035]], device='cuda:0')\n",
            "001353_jpg.rf.c0abf8e966961dd3c902dce35a401240_person_0.jpg\n",
            "001353_jpg.rf.c0abf8e966961dd3c902dce35a401240_person_1.jpg\n",
            "001353_jpg.rf.c0abf8e966961dd3c902dce35a401240_person_2.jpg\n",
            "001353_jpg.rf.c0abf8e966961dd3c902dce35a401240_person_3.jpg\n",
            "001353_jpg.rf.c0abf8e966961dd3c902dce35a401240_person_4.jpg\n",
            "001353_jpg.rf.c0abf8e966961dd3c902dce35a401240_person_5.jpg\n",
            "001353_jpg.rf.c0abf8e966961dd3c902dce35a401240_person_6.jpg\n",
            "\n",
            "0: 640x640 3 persons, 17.4ms\n",
            "Speed: 2.5ms preprocess, 17.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[266.9555, 153.2148, 394.6780, 554.5503],\n",
            "        [387.9567, 150.0670, 506.3700, 546.8448],\n",
            "        [150.1695, 153.8919, 274.2305, 574.2944]], device='cuda:0')\n",
            "-184-_png_jpg.rf.b02963998a79b9ad5079f57b65130bc2_person_0.jpg\n",
            "-184-_png_jpg.rf.b02963998a79b9ad5079f57b65130bc2_person_1.jpg\n",
            "-184-_png_jpg.rf.b02963998a79b9ad5079f57b65130bc2_person_2.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.6ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 77.3848, 136.5000, 346.2643, 638.8493]], device='cuda:0')\n",
            "YouTube-FreeStockFootage-PersonThinkingDeeply-h-HC-hj-Zo-720p_mp4-7_jpg.rf.4d6b125dc1fa9f9970e29a35bab61c9a_person_0.jpg\n",
            "\n",
            "0: 640x640 2 persons, 21.0ms\n",
            "Speed: 2.2ms preprocess, 21.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[1.9966e+02, 2.6340e+02, 3.0457e+02, 4.5236e+02],\n",
            "        [4.5522e+02, 4.3121e-02, 5.6486e+02, 3.5075e+02]], device='cuda:0')\n",
            "-1943-_png_jpg.rf.fe8693f39c8d2c4be6615a63edd3550d_person_0.jpg\n",
            "-1943-_png_jpg.rf.fe8693f39c8d2c4be6615a63edd3550d_person_1.jpg\n",
            "\n",
            "0: 640x640 4 persons, 16.3ms\n",
            "Speed: 2.9ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[277.9814, 140.0209, 420.3767, 638.7397],\n",
            "        [ 21.1117, 121.8499, 175.0790, 637.9102],\n",
            "        [490.6450, 138.3148, 616.5269, 639.0240],\n",
            "        [144.6127, 202.4311, 218.6248, 637.4526]], device='cuda:0')\n",
            "01338_jpg.rf.e142346c853fbd92e2340e43eb30eecf_person_0.jpg\n",
            "01338_jpg.rf.e142346c853fbd92e2340e43eb30eecf_person_1.jpg\n",
            "01338_jpg.rf.e142346c853fbd92e2340e43eb30eecf_person_2.jpg\n",
            "01338_jpg.rf.e142346c853fbd92e2340e43eb30eecf_person_3.jpg\n",
            "\n",
            "0: 640x640 6 persons, 17.1ms\n",
            "Speed: 2.5ms preprocess, 17.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[302.2816, 202.9047, 383.1100, 555.7001],\n",
            "        [113.1139, 213.8170, 187.5047, 525.8351],\n",
            "        [376.8257, 206.1201, 465.6459, 559.1042],\n",
            "        [  8.0430, 210.6211, 100.2482, 567.7230],\n",
            "        [184.9528, 189.8430, 267.4539, 563.5311],\n",
            "        [521.3377, 169.2073, 614.3972, 635.0427]], device='cuda:0')\n",
            "001056_jpg.rf.fb5d9fbc2ccfa43ca89d84be6d2a98ea_person_0.jpg\n",
            "001056_jpg.rf.fb5d9fbc2ccfa43ca89d84be6d2a98ea_person_1.jpg\n",
            "001056_jpg.rf.fb5d9fbc2ccfa43ca89d84be6d2a98ea_person_2.jpg\n",
            "001056_jpg.rf.fb5d9fbc2ccfa43ca89d84be6d2a98ea_person_3.jpg\n",
            "001056_jpg.rf.fb5d9fbc2ccfa43ca89d84be6d2a98ea_person_4.jpg\n",
            "001056_jpg.rf.fb5d9fbc2ccfa43ca89d84be6d2a98ea_person_5.jpg\n",
            "\n",
            "0: 640x640 2 persons, 17.6ms\n",
            "Speed: 2.6ms preprocess, 17.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[420.3869, 266.5370, 608.3979, 614.8238],\n",
            "        [ 44.4536,  92.5728, 401.1256, 591.3097]], device='cuda:0')\n",
            "ppe_1166_jpg.rf.ccad8bba387168ec13aa4f3ce7848f27_person_0.jpg\n",
            "ppe_1166_jpg.rf.ccad8bba387168ec13aa4f3ce7848f27_person_1.jpg\n",
            "\n",
            "0: 640x640 4 persons, 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 88.6658, 303.4725, 200.6728, 573.9961],\n",
            "        [383.3601, 280.6993, 480.7954, 612.8552],\n",
            "        [299.6816, 324.6181, 344.1789, 429.5958],\n",
            "        [260.8740, 422.8366, 381.8358, 637.4940]], device='cuda:0')\n",
            "ppe_1022_jpg.rf.589fdbf689e5614020d4706c7a5f5083_person_0.jpg\n",
            "ppe_1022_jpg.rf.589fdbf689e5614020d4706c7a5f5083_person_1.jpg\n",
            "ppe_1022_jpg.rf.589fdbf689e5614020d4706c7a5f5083_person_2.jpg\n",
            "ppe_1022_jpg.rf.589fdbf689e5614020d4706c7a5f5083_person_3.jpg\n",
            "\n",
            "0: 640x640 3 persons, 16.4ms\n",
            "Speed: 2.6ms preprocess, 16.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[310.5774, 220.2088, 469.3991, 402.3113],\n",
            "        [182.4003, 269.1003, 449.8641, 525.0211],\n",
            "        [ 74.3577, 237.1395, 139.0978, 368.5665]], device='cuda:0')\n",
            "-4216-_png_jpg.rf.881e17f72716e3cbdaa9d20cf9558142_person_0.jpg\n",
            "-4216-_png_jpg.rf.881e17f72716e3cbdaa9d20cf9558142_person_1.jpg\n",
            "-4216-_png_jpg.rf.881e17f72716e3cbdaa9d20cf9558142_person_2.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.6ms\n",
            "Speed: 2.2ms preprocess, 16.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[157.2152,  87.8483, 259.9046, 572.9250]], device='cuda:0')\n",
            "helmet9991123_jpg.rf.b2f88448522c155ac91f0ab719addf38_person_0.jpg\n",
            "\n",
            "0: 640x640 (no detections), 19.4ms\n",
            "Speed: 5.5ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections found in image YouTube-FREE-AerialStockFootage_CityUrban-YKY3Mm5P1tE-720p_mp4-31_jpg.rf.c88b23a01eb99ef16b5208d11dd5764f.jpg\n",
            "\n",
            "0: 640x640 3 persons, 19.9ms\n",
            "Speed: 5.7ms preprocess, 19.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[150.2085, 114.6426, 344.5147, 580.1544],\n",
            "        [345.6076,  90.1805, 475.6472, 580.1488],\n",
            "        [589.5111,  80.0681, 639.9594, 284.8713]], device='cuda:0')\n",
            "ppe_0886_jpg.rf.ad5ddd17cb1d27b716f5681b4aae8fd3_person_0.jpg\n",
            "ppe_0886_jpg.rf.ad5ddd17cb1d27b716f5681b4aae8fd3_person_1.jpg\n",
            "ppe_0886_jpg.rf.ad5ddd17cb1d27b716f5681b4aae8fd3_person_2.jpg\n",
            "\n",
            "0: 640x640 4 persons, 16.3ms\n",
            "Speed: 2.7ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[136.3401,  56.8750, 438.8218, 640.0000],\n",
            "        [328.1550, 112.2290, 483.2837, 398.8870],\n",
            "        [324.4377, 111.8819, 484.5685, 548.2388],\n",
            "        [  0.0000, 260.2144,  44.1490, 640.0000]], device='cuda:0')\n",
            "YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-35_jpg.rf.d03a2efbca9287a52d02a3d428d2aaf5_person_0.jpg\n",
            "YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-35_jpg.rf.d03a2efbca9287a52d02a3d428d2aaf5_person_1.jpg\n",
            "YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-35_jpg.rf.d03a2efbca9287a52d02a3d428d2aaf5_person_2.jpg\n",
            "YouTube-FreeStockFootage_Child-playing-with-parents-JoyLaughterHD-RQ_qqCZOkZk-720p_mp4-35_jpg.rf.d03a2efbca9287a52d02a3d428d2aaf5_person_3.jpg\n",
            "\n",
            "0: 640x640 2 persons, 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[273.1047,  79.8229, 614.9999, 640.0000],\n",
            "        [ 96.1922, 196.5285, 391.6884, 640.0000]], device='cuda:0')\n",
            "001216_jpg.rf.c7de195db643cb4d72f58f262b39b050_person_0.jpg\n",
            "001216_jpg.rf.c7de195db643cb4d72f58f262b39b050_person_1.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.6ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[204.9267,  72.5485, 281.5703, 212.0103]], device='cuda:0')\n",
            "ppe_1130_jpg.rf.88358e5b86cdc4d55d4689abe5cb87e4_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.6ms\n",
            "Speed: 2.6ms preprocess, 16.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[152.5706,  75.0911, 358.0833, 640.0000]], device='cuda:0')\n",
            "image_123_jpg.rf.97f3e3dfff77ad0bdf3ed26cebb847c2_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.8ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[248.2058,  93.4215, 375.1396, 637.6554]], device='cuda:0')\n",
            "image_217_jpg.rf.460f83c2cb3f8a18689f92b2f8835f9a_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.2ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[175.1112,  99.1677, 351.7301, 575.0432]], device='cuda:0')\n",
            "image_154_jpg.rf.8b5af37534dcf73cb9cd2833f7630273_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[169.4949,  97.6233, 315.2703, 576.3252]], device='cuda:0')\n",
            "image_237_jpg.rf.353ad34ef2718e9f9e14f8a21bc5afa6_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.4ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[134.6212,  85.0782, 323.4579, 612.9161]], device='cuda:0')\n",
            "image_190_jpg.rf.2e92814af735dd1c2f54325bac2750f3_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.7ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 85.9727,  93.0628, 292.4894, 566.7684]], device='cuda:0')\n",
            "image_108_jpg.rf.6b8ca4832a9576fc6d610029fbaed93a_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.0ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[195.5086, 161.2183, 425.2445, 528.2768]], device='cuda:0')\n",
            "Video3_19_jpg.rf.ae0c1d1923ab81af7575d5d532490729_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 21.5ms\n",
            "Speed: 2.5ms preprocess, 21.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[392.0701, 123.1180, 553.9333, 639.5581]], device='cuda:0')\n",
            "image_150_jpg.rf.6b42024e9ab03c2c17d1025c76bff9a0_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.9ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[271.3702,  80.5380, 410.1518, 321.7040]], device='cuda:0')\n",
            "Video2_143_jpg.rf.7035ecddb4b2c8cfdbd5a004d946a496_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[128.7707,  97.5273, 322.8486, 576.8622]], device='cuda:0')\n",
            "image_159_jpg.rf.0483e0dd4df48c05815b5b0d751cbbc3_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.5ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[202.4718,  91.7228, 418.8228, 452.5133]], device='cuda:0')\n",
            "Video1_2_jpg.rf.0754a5fb79396bd903a4ded0145f7bc9_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 17.0ms\n",
            "Speed: 3.7ms preprocess, 17.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[370.5433,  28.3323, 584.0174, 640.0000]], device='cuda:0')\n",
            "images-2022-07-04T013042_jpg.rf.b978dadc52cedd1622e4ef2c8cd1489d_person_0.jpg\n",
            "\n",
            "0: 640x640 (no detections), 16.7ms\n",
            "Speed: 3.1ms preprocess, 16.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No detections found in image TsirinTu0018_jpg.rf.3fe2fc0fdb3a31434f1bac91d61e53be.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.2ms\n",
            "Speed: 2.3ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[269.2333,  79.5200, 374.4660, 634.2711]], device='cuda:0')\n",
            "image_158_jpg.rf.21b1c9f094c45914d813470b6a644c58_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.8ms\n",
            "Speed: 2.3ms preprocess, 16.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[139.6077,  84.9512, 404.4432, 636.8116]], device='cuda:0')\n",
            "gettyimages-650169013-612x612_jpg.rf.90fc5c76e7c05968c9b793beb168af66_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.2ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[287.6094,  86.1512, 432.1148, 346.1020]], device='cuda:0')\n",
            "Video2_178_jpg.rf.589896c6e0322de89e52bcd29313c422_person_0.jpg\n",
            "\n",
            "0: 640x640 3 persons, 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[277.9478, 201.7075, 446.5472, 589.7187],\n",
            "        [ 63.6434, 127.6747, 294.7419, 592.6890],\n",
            "        [420.1473, 168.1871, 566.5088, 615.8354]], device='cuda:0')\n",
            "ppe_0941_jpg.rf.c7fcf7d8f89d423c80586709b693b697_person_0.jpg\n",
            "ppe_0941_jpg.rf.c7fcf7d8f89d423c80586709b693b697_person_1.jpg\n",
            "ppe_0941_jpg.rf.c7fcf7d8f89d423c80586709b693b697_person_2.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 3.5ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[269.4893, 124.6066, 494.8590, 476.8325]], device='cuda:0')\n",
            "Video2_38_jpg.rf.a593c2439bc2acd57f3d9e911c710e75_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.2ms\n",
            "Speed: 2.1ms preprocess, 16.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[180.9741,  64.8918, 468.7687, 638.3835]], device='cuda:0')\n",
            "Video3_42_jpg.rf.38bac29f7f62c6a04896444e6e26a925_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[  6.7023, 123.5616, 631.7605, 635.0659]], device='cuda:0')\n",
            "images85_jpg.rf.63100ad7637913c912a58d3538cae4bd_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.2ms\n",
            "Speed: 2.8ms preprocess, 16.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 15.7542, 169.0155, 395.4507, 633.8770]], device='cuda:0')\n",
            "images-2022-07-04T013101_jpg.rf.61a513fd8447097dc3c37ad8e6ab7e78_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[257.6872,  91.8184, 408.4263, 342.8842]], device='cuda:0')\n",
            "Video2_174_jpg.rf.d04a29e17bdf3c1135e2a0d6744250c0_person_0.jpg\n",
            "\n",
            "0: 640x640 2 persons, 16.6ms\n",
            "Speed: 2.7ms preprocess, 16.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[103.8867,   8.4493, 281.4812, 640.0000],\n",
            "        [320.3822,  17.8017, 583.8370, 640.0000]], device='cuda:0')\n",
            "ppe_0153_jpg.rf.cfc5bb75e388eecc7b459d59d4c41b95_person_0.jpg\n",
            "ppe_0153_jpg.rf.cfc5bb75e388eecc7b459d59d4c41b95_person_1.jpg\n",
            "\n",
            "0: 640x640 7 persons, 16.9ms\n",
            "Speed: 2.7ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[160.0883, 135.0646, 244.5500, 520.2469],\n",
            "        [453.9114, 230.5128, 533.6033, 590.6359],\n",
            "        [366.4845, 185.0708, 454.7313, 519.8040],\n",
            "        [213.5942, 154.0818, 282.7407, 436.4468],\n",
            "        [260.9582, 112.8572, 346.5009, 518.4445],\n",
            "        [ 49.8976,  60.5649, 155.5497, 579.7809],\n",
            "        [343.6527, 162.0277, 411.5533, 484.3546]], device='cuda:0')\n",
            "Aitin1170_jpg.rf.1b9fa28a4e61ee842a39db039d69d464_person_0.jpg\n",
            "Aitin1170_jpg.rf.1b9fa28a4e61ee842a39db039d69d464_person_1.jpg\n",
            "Aitin1170_jpg.rf.1b9fa28a4e61ee842a39db039d69d464_person_2.jpg\n",
            "Aitin1170_jpg.rf.1b9fa28a4e61ee842a39db039d69d464_person_3.jpg\n",
            "Aitin1170_jpg.rf.1b9fa28a4e61ee842a39db039d69d464_person_4.jpg\n",
            "Aitin1170_jpg.rf.1b9fa28a4e61ee842a39db039d69d464_person_5.jpg\n",
            "Aitin1170_jpg.rf.1b9fa28a4e61ee842a39db039d69d464_person_6.jpg\n",
            "\n",
            "0: 640x640 5 persons, 16.3ms\n",
            "Speed: 3.3ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[  0.7649,  89.8762, 105.0279, 532.1251],\n",
            "        [327.2582, 146.0519, 483.4711, 638.9305],\n",
            "        [168.9603, 149.7115, 264.4879, 574.3170],\n",
            "        [103.3667, 134.5235, 185.4583, 525.0522],\n",
            "        [255.1033,  50.2293, 356.0351, 637.5403]], device='cuda:0')\n",
            "Aitin3205_jpg.rf.0e0bc650138d83144f9e7196dd2bec38_person_0.jpg\n",
            "Aitin3205_jpg.rf.0e0bc650138d83144f9e7196dd2bec38_person_1.jpg\n",
            "Aitin3205_jpg.rf.0e0bc650138d83144f9e7196dd2bec38_person_2.jpg\n",
            "Aitin3205_jpg.rf.0e0bc650138d83144f9e7196dd2bec38_person_3.jpg\n",
            "Aitin3205_jpg.rf.0e0bc650138d83144f9e7196dd2bec38_person_4.jpg\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "from ultralytics import YOLO\n",
        "\n",
        "def load_class_map(classes_file):\n",
        "    class_map = {}\n",
        "    with open(classes_file, 'r') as f:\n",
        "        for idx, class_name in enumerate(f.readlines()):\n",
        "            class_map[class_name.strip()] = idx\n",
        "    return class_map\n",
        "\n",
        "\n",
        "def crop_images_and_update_annotations(input_dir, output_dir, person_model_path):\n",
        "    # Load the person detection model\n",
        "    person_model = YOLO(person_model_path)\n",
        "\n",
        "    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'labels'), exist_ok=True)\n",
        "\n",
        "    for img_name in os.listdir(os.path.join(input_dir, 'images')):\n",
        "        img_path = os.path.join(input_dir, 'images', img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Detect persons in the image\n",
        "        results = person_model(img)\n",
        "        # print(type(person_model(img)))\n",
        "        # print(\"gaseuidfgiuasedgfhuisagedfuigh\",results[0].boxes.xyxy.shape, img_name)\n",
        "\n",
        "        if len(results) == 0 or results[0].boxes.xyxy.shape[0] == 0:  # Check if results are empty or no bounding boxes\n",
        "            print(f\"No detections found in image {img_name}\")\n",
        "            continue\n",
        "        for i, result in enumerate(results[0].boxes.xyxy):\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, result)\n",
        "\n",
        "            # Crop the image\n",
        "            cropped_img = img[y1:y2, x1:x2]\n",
        "\n",
        "            # Save the cropped image\n",
        "            cropped_img_name = f\"{os.path.splitext(img_name)[0]}_person_{i}.jpg\"\n",
        "            cv2.imwrite(os.path.join(output_dir, 'images', cropped_img_name), cropped_img)\n",
        "\n",
        "            # Update annotations for the cropped image\n",
        "            print(cropped_img_name)\n",
        "        # import sys\n",
        "        # sys.exit()\n",
        "            update_annotations(input_dir, output_dir, img_name, cropped_img_name, x1, y1, x2, y2)\n",
        "\n",
        "def update_annotations(input_dir, output_dir, original_img_name, cropped_img_name, x1, y1, x2, y2):\n",
        "    # Load the original annotation file\n",
        "    xml_file = os.path.join(input_dir, 'xmls',  f\"{os.path.splitext(original_img_name)[0]}.xml\")\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    img_width = int(root.find('size/width').text)\n",
        "    img_height = int(root.find('size/height').text)\n",
        "    cropped_width = x2 - x1\n",
        "    cropped_height = y2 - y1\n",
        "    class_map = load_class_map(\"/content/drive/MyDrive/Syook/datasets/classes.txt\")\n",
        "    yolo_annotations = []\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "\n",
        "        # Only include PPE classes in the new annotations\n",
        "        if class_name in [\"hard-hat\", \"gloves\", \"mask\", \"glasses\", \"boots\", \"vest\", \"ppe-suit\", \"ear-protector\", \"safety-harness\"]:\n",
        "            bbox = obj.find('bndbox')\n",
        "            xmin = int(bbox.find('xmin').text)\n",
        "            ymin = int(bbox.find('ymin').text)\n",
        "            xmax = int(bbox.find('xmax').text)\n",
        "            ymax = int(bbox.find('ymax').text)\n",
        "\n",
        "            # Check if the PPE is within the person bounding box\n",
        "            if xmin >= x1 and xmax <= x2 and ymin >= y1 and ymax <= y2:\n",
        "                # Adjust coordinates relative to the cropped image\n",
        "                new_xmin = xmin - x1\n",
        "                new_ymin = ymin - y1\n",
        "                new_xmax = xmax - x1\n",
        "                new_ymax = ymax - y1\n",
        "\n",
        "                # Convert to YOLO format\n",
        "                x_center = (new_xmin + new_xmax) / 2 / cropped_width\n",
        "                y_center = (new_ymin + new_ymax) / 2 / cropped_height\n",
        "                width = (new_xmax - new_xmin) / cropped_width\n",
        "                height = (new_ymax - new_ymin) / cropped_height\n",
        "\n",
        "                class_id = class_map[class_name]\n",
        "                yolo_annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
        "\n",
        "    # Save the new annotations\n",
        "    annotation_file_path = os.path.join(output_dir, 'new', f\"{os.path.splitext(cropped_img_name)[0]}.txt\")\n",
        "    with open(annotation_file_path, 'w') as f:\n",
        "        f.write('\\n'.join(yolo_annotations))\n",
        "\n",
        "\n",
        "\n",
        "# class_map = load_class_map(\"/content/drive/MyDrive/Syook/datasets/classes.txt\")\n",
        "if __name__ == \"__main__\":\n",
        "    input_dir = '/content/drive/MyDrive/Syook/datasets/partitioned/train' # images ka path\n",
        "    output_dir = '/content/drive/MyDrive/Syook/datasets/partitioned/train/ppe' # ppe wala path\n",
        "    person_model_path = '/content/drive/MyDrive/Syook/runs/detect/yolov8_person_detection/weights/best.pt' # weights\n",
        "    crop_images_and_update_annotations(input_dir, output_dir, person_model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN-dm5wqlLOp",
        "outputId": "05d23d49-8898-494e-d628-d64f5d1c43c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 2 persons, 14.9ms\n",
            "Speed: 2.4ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[264.6149, 250.3693, 300.7280, 351.1180],\n",
            "        [419.1040, 245.6912, 449.9090, 320.0105]], device='cuda:0')\n",
            "001790_person_0.jpg\n",
            "001790_person_1.jpg\n",
            "\n",
            "0: 448x640 6 persons, 13.7ms\n",
            "Speed: 4.3ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 19.9134,  52.1453, 141.3338, 328.0000],\n",
            "        [279.8102,  84.9043, 418.7665, 328.0000],\n",
            "        [130.0103,  94.9068, 203.3782, 325.7939],\n",
            "        [217.8213,  83.6731, 285.3411, 324.8172],\n",
            "        [ 94.9314, 101.7081, 149.3835, 254.0850],\n",
            "        [173.4844,  91.9042, 214.8692, 305.1819]], device='cuda:0')\n",
            "001953_person_0.jpg\n",
            "001953_person_1.jpg\n",
            "001953_person_2.jpg\n",
            "001953_person_3.jpg\n",
            "001953_person_4.jpg\n",
            "001953_person_5.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[  0.0000, 123.6899, 133.7391, 426.0000],\n",
            "        [116.4809, 131.2309, 274.1683, 425.7083],\n",
            "        [264.6274,   7.6719, 640.0000, 426.0000]], device='cuda:0')\n",
            "001082_person_0.jpg\n",
            "001082_person_1.jpg\n",
            "001082_person_2.jpg\n",
            "\n",
            "0: 480x640 1 person, 13.9ms\n",
            "Speed: 3.7ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[156.8253,  48.9690, 263.6865, 210.3430]], device='cuda:0')\n",
            "001412_person_0.jpg\n",
            "\n",
            "0: 448x640 4 persons, 13.7ms\n",
            "Speed: 2.8ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[149.5674, 115.5156, 233.1349, 332.9353],\n",
            "        [310.4913, 137.5333, 386.5626, 331.7978],\n",
            "        [243.4164, 130.4931, 321.4221, 333.0000],\n",
            "        [ 45.7102, 113.0993, 145.1598, 333.0000]], device='cuda:0')\n",
            "001474_person_0.jpg\n",
            "001474_person_1.jpg\n",
            "001474_person_2.jpg\n",
            "001474_person_3.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[175.6236,  15.2966, 450.0000, 297.3093]], device='cuda:0')\n",
            "001834_person_0.jpg\n",
            "\n",
            "0: 480x640 8 persons, 14.4ms\n",
            "Speed: 3.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[3.0137e+02, 1.1238e+02, 3.7955e+02, 3.7351e+02],\n",
            "        [1.1612e-01, 8.1461e+01, 1.0412e+02, 3.7500e+02],\n",
            "        [3.8942e+02, 1.1707e+02, 4.7386e+02, 3.5283e+02],\n",
            "        [1.0218e+02, 9.9493e+01, 1.7072e+02, 3.7369e+02],\n",
            "        [2.7216e+02, 1.1683e+02, 3.2386e+02, 3.2792e+02],\n",
            "        [4.4351e+02, 1.1802e+02, 5.0000e+02, 3.7459e+02],\n",
            "        [0.0000e+00, 1.2169e+02, 2.8832e+01, 1.8323e+02],\n",
            "        [8.4519e-03, 1.2053e+02, 2.9802e+01, 3.3831e+02]], device='cuda:0')\n",
            "005250_person_0.jpg\n",
            "005250_person_1.jpg\n",
            "005250_person_2.jpg\n",
            "005250_person_3.jpg\n",
            "005250_person_4.jpg\n",
            "005250_person_5.jpg\n",
            "005250_person_6.jpg\n",
            "005250_person_7.jpg\n",
            "\n",
            "0: 544x640 3 persons, 21.1ms\n",
            "Speed: 3.2ms preprocess, 21.1ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
            "tensor([[172.8580, 112.1651, 258.4149, 278.3251],\n",
            "        [111.6384, 111.3807, 142.6411, 156.6200],\n",
            "        [258.6230, 206.1335, 377.9770, 333.2600]], device='cuda:0')\n",
            "005138_person_0.jpg\n",
            "005138_person_1.jpg\n",
            "005138_person_2.jpg\n",
            "\n",
            "0: 448x640 3 persons, 15.0ms\n",
            "Speed: 4.7ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[293.1447,  53.4946, 438.0000, 299.9092],\n",
            "        [ 64.6848,  62.4714, 208.4303, 298.9637],\n",
            "        [162.4678,  70.7632, 307.0165, 300.0000]], device='cuda:0')\n",
            "001939_person_0.jpg\n",
            "001939_person_1.jpg\n",
            "001939_person_2.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.1ms\n",
            "Speed: 4.0ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[191.5360,  77.2926, 285.9607, 221.1062],\n",
            "        [ 92.8587,  97.1507, 207.1371, 228.8477],\n",
            "        [316.6649,  58.0855, 355.4471, 165.4701]], device='cuda:0')\n",
            "001325_person_0.jpg\n",
            "001325_person_1.jpg\n",
            "001325_person_2.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.0ms\n",
            "Speed: 3.7ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[  4.4031,  40.2388, 214.1861, 332.2678],\n",
            "        [ 78.6192,  36.6818, 214.9388, 332.3671]], device='cuda:0')\n",
            "001501_person_0.jpg\n",
            "001501_person_1.jpg\n",
            "\n",
            "0: 352x640 6 persons, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n",
            "tensor([[451.6480,  51.1298, 526.7958, 260.4817],\n",
            "        [206.3734, 106.5221, 310.4441, 264.5446],\n",
            "        [342.6937,  92.7637, 405.1501, 181.3651],\n",
            "        [510.9624,  49.3868, 549.4297, 201.9011],\n",
            "        [132.8332,  83.0299, 181.3486, 258.3892],\n",
            "        [153.1061,  84.7868, 240.7333, 260.0020]], device='cuda:0')\n",
            "001858_person_0.jpg\n",
            "001858_person_1.jpg\n",
            "001858_person_2.jpg\n",
            "001858_person_3.jpg\n",
            "001858_person_4.jpg\n",
            "001858_person_5.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.8ms\n",
            "Speed: 3.6ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[276.0174, 138.8532, 317.7344, 264.8176],\n",
            "        [251.0424, 156.9831, 290.2777, 259.8074]], device='cuda:0')\n",
            "001199_person_0.jpg\n",
            "001199_person_1.jpg\n",
            "\n",
            "0: 480x640 1 person, 13.9ms\n",
            "Speed: 3.8ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[ 12.3781,  64.7697, 189.1222, 261.7036]], device='cuda:0')\n",
            "001873_person_0.jpg\n",
            "\n",
            "0: 480x640 2 persons, 13.2ms\n",
            "Speed: 3.6ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[197.9729,   0.9864, 449.0189, 315.2733],\n",
            "        [180.2111,  36.2570, 310.3737, 317.0000]], device='cuda:0')\n",
            "001943_person_0.jpg\n",
            "001943_person_1.jpg\n",
            "\n",
            "0: 480x640 2 persons, 13.2ms\n",
            "Speed: 4.0ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[192.4377,  74.6618, 366.7341, 356.0000],\n",
            "        [ 22.0479,  82.6793, 188.6066, 355.6381]], device='cuda:0')\n",
            "001810_person_0.jpg\n",
            "001810_person_1.jpg\n",
            "\n",
            "0: 416x640 4 persons, 13.5ms\n",
            "Speed: 3.6ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[277.1389,  67.1653, 367.5915, 213.4435],\n",
            "        [287.8202,  58.8704, 418.3012, 218.1466],\n",
            "        [316.5705,  57.2157, 417.2374, 257.1185],\n",
            "        [295.7113,   0.0000, 350.2372,  58.8345]], device='cuda:0')\n",
            "001751_person_0.jpg\n",
            "001751_person_1.jpg\n",
            "001751_person_2.jpg\n",
            "001751_person_3.jpg\n",
            "\n",
            "0: 416x640 2 persons, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[144.6527,  38.9034, 265.1816, 225.2431],\n",
            "        [  0.0000,  28.8199,  29.9338, 236.2793]], device='cuda:0')\n",
            "001645_person_0.jpg\n",
            "001645_person_1.jpg\n",
            "\n",
            "0: 448x640 2 persons, 14.4ms\n",
            "Speed: 2.8ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 32.5182,  66.0425, 134.9342, 197.7826],\n",
            "        [180.1061,  64.6432, 244.7696, 180.9363]], device='cuda:0')\n",
            "001158_person_0.jpg\n",
            "001158_person_1.jpg\n",
            "\n",
            "0: 448x640 4 persons, 13.0ms\n",
            "Speed: 4.0ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[395.9701, 209.7881, 447.7905, 334.0000],\n",
            "        [325.2403, 143.4756, 381.3025, 332.6096],\n",
            "        [225.0911, 209.1636, 296.6882, 333.7523],\n",
            "        [322.4695,  11.8803, 390.9937, 131.2422]], device='cuda:0')\n",
            "001898_person_0.jpg\n",
            "001898_person_1.jpg\n",
            "001898_person_2.jpg\n",
            "001898_person_3.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.0ms\n",
            "Speed: 3.8ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 11.0105,  70.1572, 378.7152, 333.0000],\n",
            "        [  3.6827,  70.4430, 263.3120, 333.0000]], device='cuda:0')\n",
            "005038_person_0.jpg\n",
            "005038_person_1.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.0ms\n",
            "Speed: 3.5ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[155.7441,  61.0012, 280.5189, 299.1207],\n",
            "        [241.6756,  28.6529, 399.5341, 298.9784],\n",
            "        [301.2299,  40.0217, 420.3609, 299.0121],\n",
            "        [  1.4210,  22.3034, 190.7478, 300.0000],\n",
            "        [  0.4581,  22.9269, 293.9751, 300.0000]], device='cuda:0')\n",
            "005126_person_0.jpg\n",
            "005126_person_1.jpg\n",
            "005126_person_2.jpg\n",
            "005126_person_3.jpg\n",
            "005126_person_4.jpg\n",
            "\n",
            "0: 448x640 7 persons, 13.0ms\n",
            "Speed: 3.8ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 60.1171, 130.9676, 134.9834, 331.0105],\n",
            "        [152.7897, 130.3138, 221.0106, 333.0000],\n",
            "        [279.9656, 131.1120, 352.1455, 332.4886],\n",
            "        [213.5529, 120.1195, 284.4556, 331.9747],\n",
            "        [112.4176, 137.2391, 169.0090, 333.0000],\n",
            "        [360.7386, 111.9531, 446.9554, 331.3083],\n",
            "        [446.9541, 134.8755, 499.9759, 331.8771]], device='cuda:0')\n",
            "001339_person_0.jpg\n",
            "001339_person_1.jpg\n",
            "001339_person_2.jpg\n",
            "001339_person_3.jpg\n",
            "001339_person_4.jpg\n",
            "001339_person_5.jpg\n",
            "001339_person_6.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 54.8192,  94.5936, 297.7077, 265.7909]], device='cuda:0')\n",
            "001889_person_0.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.0ms\n",
            "Speed: 4.0ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[236.3948, 108.5019, 330.2902, 248.2104],\n",
            "        [161.0579, 146.8428, 250.3124, 259.4674]], device='cuda:0')\n",
            "001502_person_0.jpg\n",
            "001502_person_1.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.0ms\n",
            "Speed: 3.7ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[398.6081, 207.6094, 428.6998, 254.1644]], device='cuda:0')\n",
            "001649_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 17.0ms\n",
            "Speed: 4.5ms preprocess, 17.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 19.7318,  52.0733, 151.0266, 386.0000]], device='cuda:0')\n",
            "001179_person_0.jpg\n",
            "\n",
            "0: 480x640 2 persons, 13.9ms\n",
            "Speed: 3.8ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[118.4968, 159.6154, 223.7988, 340.4782],\n",
            "        [308.6534, 114.8521, 393.3522, 347.4942]], device='cuda:0')\n",
            "001503_person_0.jpg\n",
            "001503_person_1.jpg\n",
            "\n",
            "0: 640x448 3 persons, 15.2ms\n",
            "Speed: 3.7ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[  0.0000, 189.8982, 200.9093, 550.0000],\n",
            "        [125.3370, 248.2744, 300.4737, 550.0000],\n",
            "        [151.9289,  82.7955, 176.2339, 152.8513]], device='cuda:0')\n",
            "001624_person_0.jpg\n",
            "001624_person_1.jpg\n",
            "001624_person_2.jpg\n",
            "\n",
            "0: 448x640 5 persons, 14.2ms\n",
            "Speed: 3.1ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[378.9949, 171.3209, 427.6030, 297.5589],\n",
            "        [287.0674,  63.8869, 356.1060, 295.3575],\n",
            "        [185.6068, 161.6778, 224.1008, 242.2049],\n",
            "        [ 10.3221, 128.1767, 135.4709, 331.0000],\n",
            "        [361.4083, 170.5240, 389.4819, 269.6306]], device='cuda:0')\n",
            "001302_person_0.jpg\n",
            "001302_person_1.jpg\n",
            "001302_person_2.jpg\n",
            "001302_person_3.jpg\n",
            "001302_person_4.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[7.9691e-02, 1.1351e+02, 1.1015e+02, 3.3271e+02],\n",
            "        [2.4688e+02, 1.7989e+02, 2.9873e+02, 2.3158e+02],\n",
            "        [3.3972e+02, 2.2888e+02, 3.7133e+02, 2.9660e+02]], device='cuda:0')\n",
            "001854_person_0.jpg\n",
            "001854_person_1.jpg\n",
            "001854_person_2.jpg\n",
            "\n",
            "0: 448x640 2 persons, 15.7ms\n",
            "Speed: 2.7ms preprocess, 15.7ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[261.5893,  97.7059, 394.7914, 332.0045],\n",
            "        [111.0284,  80.0110, 276.6252, 324.9931]], device='cuda:0')\n",
            "005086_person_0.jpg\n",
            "005086_person_1.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.1ms\n",
            "Speed: 4.9ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[205.7838,  98.3750, 240.3190, 204.0511]], device='cuda:0')\n",
            "001642_person_0.jpg\n",
            "\n",
            "0: 480x640 2 persons, 14.4ms\n",
            "Speed: 4.8ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[223.0124,  93.6012, 433.6978, 375.0000],\n",
            "        [ 95.8075, 109.7878, 235.1812, 362.1408]], device='cuda:0')\n",
            "001746_person_0.jpg\n",
            "001746_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 13.9ms\n",
            "Speed: 4.1ms preprocess, 13.9ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[292.7985,  37.9042, 470.4153, 329.2782],\n",
            "        [ 19.1202,  45.2836, 307.0379, 271.3510],\n",
            "        [ 27.1091,   0.4790, 304.1366, 327.6478]], device='cuda:0')\n",
            "001657_person_0.jpg\n",
            "001657_person_1.jpg\n",
            "001657_person_2.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.0ms\n",
            "Speed: 4.5ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[115.6011, 237.1965, 160.6907, 328.3205],\n",
            "        [153.0061, 258.0016, 198.0968, 320.6845]], device='cuda:0')\n",
            "001843_person_0.jpg\n",
            "001843_person_1.jpg\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "tensor([[257.8881,  23.7832, 420.6506, 209.3678],\n",
            "        [ 64.7201,  48.4023, 253.9836, 249.4133],\n",
            "        [ 13.7770,   0.0000,  64.7588,  91.3270]], device='cuda:0')\n",
            "001807_person_0.jpg\n",
            "001807_person_1.jpg\n",
            "001807_person_2.jpg\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "tensor([[180.6323,  27.5283, 257.7454, 252.8826],\n",
            "        [ 53.5160,  43.4206,  92.7329, 105.6845],\n",
            "        [ 85.9593,  57.2009, 114.3005,  93.2972]], device='cuda:0')\n",
            "001646_person_0.jpg\n",
            "001646_person_1.jpg\n",
            "001646_person_2.jpg\n",
            "\n",
            "0: 512x640 2 persons, 13.9ms\n",
            "Speed: 3.5ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "tensor([[143.6276,  59.1271, 235.0079, 303.4646],\n",
            "        [264.4768,  51.6387, 327.5181, 307.3602]], device='cuda:0')\n",
            "005092_person_0.jpg\n",
            "005092_person_1.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.8ms\n",
            "Speed: 3.3ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[177.9075, 137.4691, 305.2251, 294.5706],\n",
            "        [232.6077,  34.7861, 255.7993,  69.2871],\n",
            "        [363.7323,  68.9628, 446.3948, 266.0173],\n",
            "        [464.4627, 154.7798, 499.9200, 227.1028],\n",
            "        [365.0085,  68.8717, 478.2333, 274.4090]], device='cuda:0')\n",
            "001713_person_0.jpg\n",
            "001713_person_1.jpg\n",
            "001713_person_2.jpg\n",
            "001713_person_3.jpg\n",
            "001713_person_4.jpg\n",
            "\n",
            "0: 448x640 1 person, 13.1ms\n",
            "Speed: 3.8ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[206.7040, 137.0245, 301.9538, 331.4969]], device='cuda:0')\n",
            "001760_person_0.jpg\n",
            "\n",
            "0: 640x448 2 persons, 13.3ms\n",
            "Speed: 4.4ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
            "tensor([[308.4209, 216.6505, 370.6243, 381.5367],\n",
            "        [ 42.3854, 564.9653,  67.8788, 634.4743]], device='cuda:0')\n",
            "001250_person_0.jpg\n",
            "001250_person_1.jpg\n",
            "\n",
            "0: 448x640 3 persons, 14.9ms\n",
            "Speed: 3.8ms preprocess, 14.9ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[140.0594, 266.0666, 257.3355, 332.0000],\n",
            "        [  7.7517, 114.0033,  73.1098, 261.8533],\n",
            "        [ 80.6671,  81.8140, 123.9187, 148.3709]], device='cuda:0')\n",
            "005280_person_0.jpg\n",
            "005280_person_1.jpg\n",
            "005280_person_2.jpg\n",
            "\n",
            "0: 640x480 1 person, 13.9ms\n",
            "Speed: 3.9ms preprocess, 13.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "tensor([[126.2756,  79.8785, 500.0000, 667.0000]], device='cuda:0')\n",
            "001916_person_0.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.7ms\n",
            "Speed: 4.0ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 35.1299,  80.4382, 175.6753, 340.8002],\n",
            "        [129.7308,  72.5388, 382.1242, 342.3593]], device='cuda:0')\n",
            "005262_person_0.jpg\n",
            "005262_person_1.jpg\n",
            "\n",
            "0: 448x640 5 persons, 13.0ms\n",
            "Speed: 3.4ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[112.7566,  93.5340, 187.7693, 234.9210],\n",
            "        [299.7850,  75.4008, 384.0963, 268.1772],\n",
            "        [222.5801, 104.9032, 268.0959, 210.4645],\n",
            "        [177.2471,  89.5024, 220.9851, 210.5871],\n",
            "        [261.8115,  91.1369, 302.0234, 241.2240]], device='cuda:0')\n",
            "005228_person_0.jpg\n",
            "005228_person_1.jpg\n",
            "005228_person_2.jpg\n",
            "005228_person_3.jpg\n",
            "005228_person_4.jpg\n",
            "\n",
            "0: 480x640 6 persons, 13.9ms\n",
            "Speed: 3.7ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[395.5901, 139.1249, 479.3532, 374.8985],\n",
            "        [254.8323, 145.5149, 330.5905, 375.0000],\n",
            "        [107.1832, 127.5169, 183.4701, 375.0000],\n",
            "        [334.3808, 143.0922, 416.4671, 374.9934],\n",
            "        [ 28.6236, 111.8695, 115.4682, 366.5246],\n",
            "        [175.8397, 124.8457, 271.3268, 375.0000]], device='cuda:0')\n",
            "001326_person_0.jpg\n",
            "001326_person_1.jpg\n",
            "001326_person_2.jpg\n",
            "001326_person_3.jpg\n",
            "001326_person_4.jpg\n",
            "001326_person_5.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.8ms\n",
            "Speed: 3.8ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[188.5538,  49.5818, 474.2190, 333.0000],\n",
            "        [309.0852,  49.2298, 472.9364, 333.0000]], device='cuda:0')\n",
            "001752_person_0.jpg\n",
            "001752_person_1.jpg\n",
            "\n",
            "0: 480x640 4 persons, 14.0ms\n",
            "Speed: 3.3ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[ 66.1256, 114.0956, 125.7533, 318.9972],\n",
            "        [428.3649, 119.8119, 470.1770, 221.0135],\n",
            "        [117.8716, 255.9079, 214.0582, 375.0000],\n",
            "        [253.3293, 113.5351, 300.1470, 271.0997]], device='cuda:0')\n",
            "001201_person_0.jpg\n",
            "001201_person_1.jpg\n",
            "001201_person_2.jpg\n",
            "001201_person_3.jpg\n",
            "\n",
            "0: 480x640 2 persons, 13.2ms\n",
            "Speed: 3.3ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[ 70.8752, 105.3378, 195.4143, 358.6801],\n",
            "        [290.3145,  84.8027, 403.4112, 359.0000]], device='cuda:0')\n",
            "001921_person_0.jpg\n",
            "001921_person_1.jpg\n",
            "\n",
            "0: 480x640 9 persons, 13.2ms\n",
            "Speed: 3.1ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[ 98.7254, 149.4640, 146.3094, 287.4942],\n",
            "        [224.6719, 162.5044, 265.6605, 296.2422],\n",
            "        [269.3918, 165.9331, 307.1622, 292.1951],\n",
            "        [136.0489, 165.7423, 168.6207, 269.6178],\n",
            "        [294.8194, 152.3072, 338.4651, 321.0841],\n",
            "        [420.3555, 173.5136, 457.3632, 281.0980],\n",
            "        [331.2314, 163.0523, 365.1201, 298.2037],\n",
            "        [392.5202, 174.7535, 427.2970, 253.3184],\n",
            "        [335.9435, 152.2854, 371.7703, 289.9460]], device='cuda:0')\n",
            "005031_person_0.jpg\n",
            "005031_person_1.jpg\n",
            "005031_person_2.jpg\n",
            "005031_person_3.jpg\n",
            "005031_person_4.jpg\n",
            "005031_person_5.jpg\n",
            "005031_person_6.jpg\n",
            "005031_person_7.jpg\n",
            "005031_person_8.jpg\n",
            "\n",
            "0: 448x640 12 persons, 14.1ms\n",
            "Speed: 3.1ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[3.3111e+01, 1.5011e+02, 9.7366e+01, 3.3102e+02],\n",
            "        [1.0671e-01, 1.6574e+02, 4.0661e+01, 3.3300e+02],\n",
            "        [2.9404e+02, 1.6234e+02, 3.4087e+02, 3.2011e+02],\n",
            "        [9.2635e+01, 1.6525e+02, 1.3980e+02, 3.2666e+02],\n",
            "        [2.5143e+02, 1.7219e+02, 2.9744e+02, 3.2854e+02],\n",
            "        [3.4828e+02, 1.7294e+02, 4.0284e+02, 3.0614e+02],\n",
            "        [1.1257e+02, 1.5874e+02, 1.6981e+02, 3.3118e+02],\n",
            "        [1.7711e+02, 1.6075e+02, 2.3050e+02, 3.3204e+02],\n",
            "        [2.4162e+02, 1.7288e+02, 2.7109e+02, 2.9411e+02],\n",
            "        [2.1445e+02, 1.6765e+02, 2.4863e+02, 3.0255e+02],\n",
            "        [1.6932e+02, 1.7146e+02, 2.0007e+02, 3.2156e+02],\n",
            "        [4.2743e+02, 1.7955e+02, 4.8745e+02, 3.3001e+02]], device='cuda:0')\n",
            "001739_person_0.jpg\n",
            "001739_person_1.jpg\n",
            "001739_person_2.jpg\n",
            "001739_person_3.jpg\n",
            "001739_person_4.jpg\n",
            "001739_person_5.jpg\n",
            "001739_person_6.jpg\n",
            "001739_person_7.jpg\n",
            "001739_person_8.jpg\n",
            "001739_person_9.jpg\n",
            "001739_person_10.jpg\n",
            "001739_person_11.jpg\n",
            "\n",
            "0: 448x640 4 persons, 14.8ms\n",
            "Speed: 2.7ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[303.8001, 133.3279, 391.1890, 210.0435],\n",
            "        [ 59.3219, 118.4790, 132.8039, 330.9115],\n",
            "        [ 64.7248, 110.7019, 273.2975, 333.0000],\n",
            "        [207.3503, 109.1545, 271.9335, 333.0000]], device='cuda:0')\n",
            "005081_person_0.jpg\n",
            "005081_person_1.jpg\n",
            "005081_person_2.jpg\n",
            "005081_person_3.jpg\n",
            "\n",
            "0: 416x640 3 persons, 14.8ms\n",
            "Speed: 2.6ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 416, 640)\n",
            "tensor([[265.0416, 124.2451, 312.6357, 232.7355],\n",
            "        [314.4845, 116.2238, 371.2730, 258.7556],\n",
            "        [259.7766, 127.6197, 280.9440, 191.8790]], device='cuda:0')\n",
            "001284_person_0.jpg\n",
            "001284_person_1.jpg\n",
            "001284_person_2.jpg\n",
            "\n",
            "0: 480x640 6 persons, 15.6ms\n",
            "Speed: 3.8ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[115.1119,  76.8991, 197.5384, 314.6810],\n",
            "        [ 33.1046,  80.1462, 115.3751, 341.5332],\n",
            "        [210.4070,  87.0112, 296.9586, 324.6949],\n",
            "        [360.0702,  82.7594, 456.6156, 324.6156],\n",
            "        [296.9455,  83.7189, 379.6179, 347.6103],\n",
            "        [322.0750,  83.2589, 457.1750, 340.6052]], device='cuda:0')\n",
            "001345_person_0.jpg\n",
            "001345_person_1.jpg\n",
            "001345_person_2.jpg\n",
            "001345_person_3.jpg\n",
            "001345_person_4.jpg\n",
            "001345_person_5.jpg\n",
            "\n",
            "0: 480x640 15 persons, 13.2ms\n",
            "Speed: 4.2ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[5.4649e+01, 7.9118e+01, 1.2568e+02, 3.0051e+02],\n",
            "        [2.7827e+02, 6.2641e+01, 3.4331e+02, 2.8731e+02],\n",
            "        [3.9876e-03, 9.9344e+01, 5.8258e+01, 3.1800e+02],\n",
            "        [1.9197e+02, 5.5468e+01, 2.4141e+02, 2.2350e+02],\n",
            "        [1.2685e+02, 8.2479e+01, 1.8238e+02, 3.0064e+02],\n",
            "        [4.3702e+02, 9.5617e+01, 5.0000e+02, 3.4084e+02],\n",
            "        [2.1754e+02, 6.2884e+01, 2.8320e+02, 2.9840e+02],\n",
            "        [3.6312e+02, 1.2002e+02, 4.4633e+02, 3.4815e+02],\n",
            "        [1.6223e+02, 7.3798e+01, 2.1178e+02, 2.8615e+02],\n",
            "        [9.8385e+01, 5.5838e+01, 1.3770e+02, 2.5108e+02],\n",
            "        [3.9709e+02, 5.1563e+01, 4.6229e+02, 1.5787e+02],\n",
            "        [3.1730e+02, 6.3813e+01, 3.6153e+02, 2.6987e+02],\n",
            "        [4.0479e+02, 7.8633e+01, 4.6249e+02, 3.0519e+02],\n",
            "        [3.4481e+02, 6.3462e+01, 4.1793e+02, 3.3259e+02],\n",
            "        [2.3620e+02, 6.2982e+01, 2.8274e+02, 2.8373e+02]], device='cuda:0')\n",
            "001837_person_0.jpg\n",
            "001837_person_1.jpg\n",
            "001837_person_2.jpg\n",
            "001837_person_3.jpg\n",
            "001837_person_4.jpg\n",
            "001837_person_5.jpg\n",
            "001837_person_6.jpg\n",
            "001837_person_7.jpg\n",
            "001837_person_8.jpg\n",
            "001837_person_9.jpg\n",
            "001837_person_10.jpg\n",
            "001837_person_11.jpg\n",
            "001837_person_12.jpg\n",
            "001837_person_13.jpg\n",
            "001837_person_14.jpg\n",
            "\n",
            "0: 448x640 9 persons, 13.7ms\n",
            "Speed: 3.6ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[356.2385,  93.4592, 412.3316, 259.7383],\n",
            "        [185.0799,  82.4913, 233.7607, 258.4304],\n",
            "        [260.5833,  86.7776, 316.6596, 258.9454],\n",
            "        [134.0789,  85.2622, 196.8392, 259.5956],\n",
            "        [388.1476,  90.7873, 452.6631, 258.8946],\n",
            "        [103.8147,  99.1384, 154.3606, 258.9871],\n",
            "        [213.2247,  84.8396, 271.5970, 258.4719],\n",
            "        [289.2187,  86.1476, 374.5807, 260.4120],\n",
            "        [ 25.9361,  87.8036,  97.2724, 263.4110]], device='cuda:0')\n",
            "001788_person_0.jpg\n",
            "001788_person_1.jpg\n",
            "001788_person_2.jpg\n",
            "001788_person_3.jpg\n",
            "001788_person_4.jpg\n",
            "001788_person_5.jpg\n",
            "001788_person_6.jpg\n",
            "001788_person_7.jpg\n",
            "001788_person_8.jpg\n",
            "\n",
            "0: 480x640 7 persons, 14.0ms\n",
            "Speed: 3.8ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "tensor([[397.1802, 118.7666, 493.6918, 317.3749],\n",
            "        [ 19.9920, 186.1206, 146.0035, 315.8464],\n",
            "        [293.1973, 122.8626, 381.7849, 333.6243],\n",
            "        [100.4436, 109.9048, 198.3119, 300.6750],\n",
            "        [239.7761, 132.4060, 330.3490, 325.7136],\n",
            "        [127.2463, 167.9730, 292.6073, 334.2729],\n",
            "        [395.0619, 101.7199, 436.0978, 298.8748]], device='cuda:0')\n",
            "005113_person_0.jpg\n",
            "005113_person_1.jpg\n",
            "005113_person_2.jpg\n",
            "005113_person_3.jpg\n",
            "005113_person_4.jpg\n",
            "005113_person_5.jpg\n",
            "005113_person_6.jpg\n",
            "\n",
            "0: 448x640 7 persons, 13.8ms\n",
            "Speed: 3.8ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[236.4466, 101.8385, 337.2725, 337.9117],\n",
            "        [202.7417, 126.8092, 253.6365, 323.2934],\n",
            "        [ 86.6260, 139.2933, 141.2681, 277.6433],\n",
            "        [143.8304, 130.6590, 203.5040, 297.9753],\n",
            "        [139.0115, 133.5536, 162.4982, 241.3419],\n",
            "        [453.9385, 126.5174, 473.7533, 186.3652],\n",
            "        [ 85.6557, 142.4793, 111.7867, 251.3925]], device='cuda:0')\n",
            "001687_person_0.jpg\n",
            "001687_person_1.jpg\n",
            "001687_person_2.jpg\n",
            "001687_person_3.jpg\n",
            "001687_person_4.jpg\n",
            "001687_person_5.jpg\n",
            "001687_person_6.jpg\n",
            "\n",
            "0: 448x640 11 persons, 13.0ms\n",
            "Speed: 3.9ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[164.0560,  99.8284, 231.6008, 302.2061],\n",
            "        [462.5065, 129.1070, 500.0000, 259.4996],\n",
            "        [ 46.8226,  95.6748, 119.4260, 331.4413],\n",
            "        [375.3819, 104.9239, 458.5973, 318.6730],\n",
            "        [329.8131, 113.6704, 389.2039, 303.0595],\n",
            "        [257.3711,  94.3007, 338.1269, 334.0000],\n",
            "        [  0.0000,  92.8215,  47.4948, 333.9659],\n",
            "        [221.6871, 115.5877, 270.1703, 281.9486],\n",
            "        [318.6524, 125.7806, 352.7605, 257.6427],\n",
            "        [218.3972, 111.8861, 248.6428, 265.5843],\n",
            "        [375.6910, 124.3399, 404.5734, 267.6888]], device='cuda:0')\n",
            "005000_person_0.jpg\n",
            "005000_person_1.jpg\n",
            "005000_person_2.jpg\n",
            "005000_person_3.jpg\n",
            "005000_person_4.jpg\n",
            "005000_person_5.jpg\n",
            "005000_person_6.jpg\n",
            "005000_person_7.jpg\n",
            "005000_person_8.jpg\n",
            "005000_person_9.jpg\n",
            "005000_person_10.jpg\n",
            "\n",
            "0: 448x640 2 persons, 13.0ms\n",
            "Speed: 3.4ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[188.4341,  67.6667, 356.0948, 332.7841],\n",
            "        [320.3337,  70.4800, 463.8687, 329.7257]], device='cuda:0')\n",
            "001395_person_0.jpg\n",
            "001395_person_1.jpg\n",
            "\n",
            "0: 448x640 6 persons, 13.0ms\n",
            "Speed: 3.9ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "tensor([[ 14.4476,  40.9564, 124.1444, 333.0000],\n",
            "        [228.2681,  54.8389, 293.7094, 298.0972],\n",
            "        [144.6799,  47.4207, 239.1831, 332.3090],\n",
            "        [367.9401,  47.8124, 494.7618, 333.0000],\n",
            "        [478.6694,  55.2524, 500.0000, 262.3002],\n",
            "        [204.1166,  52.2751, 254.2219, 302.3030]], device='cuda:0')\n",
            "001363_person_0.jpg\n",
            "001363_person_1.jpg\n",
            "001363_person_2.jpg\n",
            "001363_person_3.jpg\n",
            "001363_person_4.jpg\n",
            "001363_person_5.jpg\n",
            "\n",
            "0: 640x640 8 persons, 17.3ms\n",
            "Speed: 2.8ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 45.9193, 245.4300, 151.3632, 558.3027],\n",
            "        [515.3065, 301.1246, 566.6537, 509.9128],\n",
            "        [250.7796, 309.8288, 333.0549, 405.7358],\n",
            "        [357.3235, 271.5362, 404.3787, 422.0858],\n",
            "        [395.7537, 269.0346, 429.7365, 372.3471],\n",
            "        [209.4976, 273.2366, 247.8868, 429.9883],\n",
            "        [243.4901, 287.0280, 273.1327, 403.7372],\n",
            "        [190.0818, 304.0502, 226.4525, 428.5966]], device='cuda:0')\n",
            "-4379-_png_jpg.rf.03c410bbf91f791a4bade1f8673fa79c_person_0.jpg\n",
            "-4379-_png_jpg.rf.03c410bbf91f791a4bade1f8673fa79c_person_1.jpg\n",
            "-4379-_png_jpg.rf.03c410bbf91f791a4bade1f8673fa79c_person_2.jpg\n",
            "-4379-_png_jpg.rf.03c410bbf91f791a4bade1f8673fa79c_person_3.jpg\n",
            "-4379-_png_jpg.rf.03c410bbf91f791a4bade1f8673fa79c_person_4.jpg\n",
            "-4379-_png_jpg.rf.03c410bbf91f791a4bade1f8673fa79c_person_5.jpg\n",
            "-4379-_png_jpg.rf.03c410bbf91f791a4bade1f8673fa79c_person_6.jpg\n",
            "-4379-_png_jpg.rf.03c410bbf91f791a4bade1f8673fa79c_person_7.jpg\n",
            "\n",
            "0: 640x640 7 persons, 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[151.5945, 145.6194, 262.5760, 484.3837],\n",
            "        [ 53.1960, 161.5986, 155.4781, 471.4880],\n",
            "        [453.3697, 152.1815, 613.5049, 634.6138],\n",
            "        [ 27.2130, 170.1367,  80.8753, 337.7172],\n",
            "        [451.5561, 175.7522, 529.9668, 401.0729],\n",
            "        [116.8753, 160.7706, 165.8312, 416.4389],\n",
            "        [295.5609, 249.8960, 387.6633, 364.2310]], device='cuda:0')\n",
            "-1817-_png_jpg.rf.0c0c9d7ee4b875c6ad49937fc72182f6_person_0.jpg\n",
            "-1817-_png_jpg.rf.0c0c9d7ee4b875c6ad49937fc72182f6_person_1.jpg\n",
            "-1817-_png_jpg.rf.0c0c9d7ee4b875c6ad49937fc72182f6_person_2.jpg\n",
            "-1817-_png_jpg.rf.0c0c9d7ee4b875c6ad49937fc72182f6_person_3.jpg\n",
            "-1817-_png_jpg.rf.0c0c9d7ee4b875c6ad49937fc72182f6_person_4.jpg\n",
            "-1817-_png_jpg.rf.0c0c9d7ee4b875c6ad49937fc72182f6_person_5.jpg\n",
            "-1817-_png_jpg.rf.0c0c9d7ee4b875c6ad49937fc72182f6_person_6.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[166.3382,  86.0396, 416.7595, 633.4576]], device='cuda:0')\n",
            "image_166_jpg.rf.0c224aad30b67729bbd50121255b0e0c_person_0.jpg\n",
            "\n",
            "0: 640x640 3 persons, 16.3ms\n",
            "Speed: 1.9ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[2.2404e-01, 1.6582e+02, 2.5311e+02, 6.4000e+02],\n",
            "        [3.1899e+02, 1.8167e+02, 5.3982e+02, 6.4000e+02],\n",
            "        [1.8403e+02, 2.1304e+02, 3.2254e+02, 6.4000e+02]], device='cuda:0')\n",
            "-2338-_png_jpg.rf.e79ac380146af51e53738fd6184e1808_person_0.jpg\n",
            "-2338-_png_jpg.rf.e79ac380146af51e53738fd6184e1808_person_1.jpg\n",
            "-2338-_png_jpg.rf.e79ac380146af51e53738fd6184e1808_person_2.jpg\n",
            "\n",
            "0: 640x640 2 persons, 16.3ms\n",
            "Speed: 3.4ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[385.2900, 247.3455, 576.7355, 468.1754],\n",
            "        [153.6443, 298.3559, 262.3848, 434.6813]], device='cuda:0')\n",
            "-1579-_png_jpg.rf.c8f91ec3791bf03ccf9eca6c29f62aec_person_0.jpg\n",
            "-1579-_png_jpg.rf.c8f91ec3791bf03ccf9eca6c29f62aec_person_1.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 4.8ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 30.7612, 183.2455, 382.5336, 639.7341]], device='cuda:0')\n",
            "-1597-_png_jpg.rf.3bd5df66feaa51e0d65197b4acaf356f_person_0.jpg\n",
            "\n",
            "0: 640x640 3 persons, 20.9ms\n",
            "Speed: 2.5ms preprocess, 20.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[2.3683e+02, 3.2132e+02, 2.8561e+02, 4.6639e+02],\n",
            "        [6.1996e-01, 2.4408e+02, 1.8576e+02, 6.4000e+02],\n",
            "        [4.7405e+02, 3.2998e+02, 5.4776e+02, 5.7532e+02]], device='cuda:0')\n",
            "001302_jpg.rf.6e51fb4e9255ceda9bca16f35d4ae32b_person_0.jpg\n",
            "001302_jpg.rf.6e51fb4e9255ceda9bca16f35d4ae32b_person_1.jpg\n",
            "001302_jpg.rf.6e51fb4e9255ceda9bca16f35d4ae32b_person_2.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.4ms\n",
            "Speed: 3.9ms preprocess, 16.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[227.3096, 126.8553, 366.8865, 610.1667]], device='cuda:0')\n",
            "image_146_jpg.rf.ffe871c6889f76ba6b6e19534dce0fb6_person_0.jpg\n",
            "\n",
            "0: 640x640 3 persons, 16.9ms\n",
            "Speed: 2.8ms preprocess, 16.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[1.7905e+02, 1.6489e+02, 4.6607e+02, 6.4000e+02],\n",
            "        [5.1231e-01, 2.0262e+01, 1.6345e+02, 6.4000e+02],\n",
            "        [0.0000e+00, 1.4517e+01, 2.4100e+02, 6.3995e+02]], device='cuda:0')\n",
            "00617_jpg.rf.6c879ad11ecb4c30ed430299227b33d0_person_0.jpg\n",
            "00617_jpg.rf.6c879ad11ecb4c30ed430299227b33d0_person_1.jpg\n",
            "00617_jpg.rf.6c879ad11ecb4c30ed430299227b33d0_person_2.jpg\n",
            "\n",
            "0: 640x640 4 persons, 16.3ms\n",
            "Speed: 2.6ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[576.4642, 342.4949, 640.0000, 639.0284],\n",
            "        [ 94.3254,   0.0000, 640.0000, 640.0000],\n",
            "        [169.4601, 292.8841, 253.2970, 377.4096],\n",
            "        [168.9130, 292.3535, 252.9281, 413.8174]], device='cuda:0')\n",
            "-2293-_png_jpg.rf.b1d581d625ae74bb60b5d56e7b562654_person_0.jpg\n",
            "-2293-_png_jpg.rf.b1d581d625ae74bb60b5d56e7b562654_person_1.jpg\n",
            "-2293-_png_jpg.rf.b1d581d625ae74bb60b5d56e7b562654_person_2.jpg\n",
            "-2293-_png_jpg.rf.b1d581d625ae74bb60b5d56e7b562654_person_3.jpg\n",
            "\n",
            "0: 640x640 4 persons, 19.6ms\n",
            "Speed: 2.3ms preprocess, 19.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[ 85.9957, 316.6454, 123.1412, 433.2858],\n",
            "        [324.7565, 329.7316, 372.2006, 444.7590],\n",
            "        [172.3640, 325.0767, 210.5608, 431.6591],\n",
            "        [139.6058, 327.9756, 191.3953, 437.3438]], device='cuda:0')\n",
            "-1571-_png_jpg.rf.ccf919d5ea025ddc24cf0a707b331249_person_0.jpg\n",
            "-1571-_png_jpg.rf.ccf919d5ea025ddc24cf0a707b331249_person_1.jpg\n",
            "-1571-_png_jpg.rf.ccf919d5ea025ddc24cf0a707b331249_person_2.jpg\n",
            "-1571-_png_jpg.rf.ccf919d5ea025ddc24cf0a707b331249_person_3.jpg\n",
            "\n",
            "0: 640x640 2 persons, 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[137.1689, 232.4385, 640.0000, 639.9637],\n",
            "        [289.2028, 242.3950, 636.7006, 639.9430]], device='cuda:0')\n",
            "-2390-_png_jpg.rf.fa4cf091a0bc051c044e2505719d3971_person_0.jpg\n",
            "-2390-_png_jpg.rf.fa4cf091a0bc051c044e2505719d3971_person_1.jpg\n",
            "\n",
            "0: 640x640 1 person, 20.2ms\n",
            "Speed: 2.5ms preprocess, 20.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[259.2754, 119.0960, 360.1757, 526.9873]], device='cuda:0')\n",
            "00977_jpg.rf.f95b8f2a8ddd0df6ee5f56d665ebbb55_person_0.jpg\n",
            "\n",
            "0: 640x640 3 persons, 20.7ms\n",
            "Speed: 2.5ms preprocess, 20.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[360.1627,   7.3801, 576.8059, 640.0000],\n",
            "        [336.3421, 284.1489, 398.3160, 396.9076],\n",
            "        [238.7375, 257.0320, 288.9532, 400.9001]], device='cuda:0')\n",
            "001333_jpg.rf.25550b8186ab6e741765efbb21e9e59e_person_0.jpg\n",
            "001333_jpg.rf.25550b8186ab6e741765efbb21e9e59e_person_1.jpg\n",
            "001333_jpg.rf.25550b8186ab6e741765efbb21e9e59e_person_2.jpg\n",
            "\n",
            "0: 640x640 2 persons, 16.3ms\n",
            "Speed: 3.8ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[204.2041,   2.8859, 538.1766, 640.0000],\n",
            "        [  3.3784,   3.6913, 267.6608, 640.0000]], device='cuda:0')\n",
            "02092_jpg.rf.934d13f377f95d9adae1f393f427ba32_person_0.jpg\n",
            "02092_jpg.rf.934d13f377f95d9adae1f393f427ba32_person_1.jpg\n",
            "\n",
            "0: 640x640 3 persons, 17.2ms\n",
            "Speed: 4.5ms preprocess, 17.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[5.0195e-01, 2.2880e+01, 5.7460e+02, 6.4000e+02],\n",
            "        [4.4994e+02, 6.5922e+01, 5.9210e+02, 4.2776e+02],\n",
            "        [4.4058e+02, 6.4538e+01, 5.9727e+02, 6.4000e+02]], device='cuda:0')\n",
            "-1477-_png_jpg.rf.bac8d06edca64da17ced23797d0e2339_person_0.jpg\n",
            "-1477-_png_jpg.rf.bac8d06edca64da17ced23797d0e2339_person_1.jpg\n",
            "-1477-_png_jpg.rf.bac8d06edca64da17ced23797d0e2339_person_2.jpg\n",
            "\n",
            "0: 640x640 1 person, 17.6ms\n",
            "Speed: 2.2ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[193.6973,  95.2650, 386.9453, 638.4568]], device='cuda:0')\n",
            "image_227_jpg.rf.0f48674aea1b8aaf3e7baac80abf9ea4_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.4ms\n",
            "Speed: 2.4ms preprocess, 16.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[236.5120, 119.2556, 451.8814, 499.0120]], device='cuda:0')\n",
            "Video2_42_jpg.rf.f8ab7627f1a6ff7bcb89500ce01f949a_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 3.0ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[254.5933,  30.4440, 479.9800, 541.8938]], device='cuda:0')\n",
            "Video3_234_jpg.rf.471c24f2553d586d17a85abce416276b_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 2.9ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[273.1120,  72.8345, 527.7828, 547.0660]], device='cuda:0')\n",
            "Video2_91_jpg.rf.faca99c76175b53a646f60aa1abc4b14_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 17.2ms\n",
            "Speed: 2.5ms preprocess, 17.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[274.6104,  96.3415, 406.7846, 320.5311]], device='cuda:0')\n",
            "Video2_150_jpg.rf.b9afc4a41d95211f77fb12a37629e211_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 16.3ms\n",
            "Speed: 3.7ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "tensor([[227.7565,  72.5411, 457.1775, 519.7913]], device='cuda:0')\n",
            "Video2_83_jpg.rf.3f002b5fe1217bb7937e1ac3eb8488ae_person_0.jpg\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "from ultralytics import YOLO\n",
        "def load_class_map(classes_file):\n",
        "    class_map = {}\n",
        "    with open(classes_file, 'r') as f:\n",
        "        for idx, class_name in enumerate(f.readlines()):\n",
        "            class_map[class_name.strip()] = idx\n",
        "    return class_map\n",
        "import os\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "from ultralytics import YOLO\n",
        "\n",
        "def crop_images_and_update_annotations(input_dir, output_dir, person_model_path):\n",
        "    # Load the person detection model\n",
        "    person_model = YOLO(person_model_path)\n",
        "\n",
        "    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'labels'), exist_ok=True)\n",
        "\n",
        "    for img_name in os.listdir(os.path.join(input_dir, 'images')):\n",
        "        img_path = os.path.join(input_dir, 'images', img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Detect persons in the image\n",
        "        results = person_model(img)\n",
        "        # print(type(person_model(img)))\n",
        "        # print(\"gaseuidfgiuasedgfhuisagedfuigh\",results[0].boxes.xyxy.shape, img_name)\n",
        "\n",
        "        if len(results) == 0 or results[0].boxes.xyxy.shape[0] == 0:  # Check if results are empty or no bounding boxes\n",
        "            print(f\"No detections found in image {img_name}\")\n",
        "            continue\n",
        "        for i, result in enumerate(results[0].boxes.xyxy):\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, result)\n",
        "\n",
        "            # Crop the image\n",
        "            cropped_img = img[y1:y2, x1:x2]\n",
        "\n",
        "            # Save the cropped image\n",
        "            cropped_img_name = f\"{os.path.splitext(img_name)[0]}_person_{i}.jpg\"\n",
        "            cv2.imwrite(os.path.join(output_dir, 'images', cropped_img_name), cropped_img)\n",
        "\n",
        "            # Update annotations for the cropped image\n",
        "        # import sys\n",
        "        # sys.exit()\n",
        "            update_annotations(input_dir, output_dir, img_name, cropped_img_name, x1, y1, x2, y2)\n",
        "\n",
        "def update_annotations(input_dir, output_dir, original_img_name, cropped_img_name, x1, y1, x2, y2):\n",
        "    # Load the original annotation file\n",
        "    xml_file = os.path.join(input_dir, 'xmls',  f\"{os.path.splitext(original_img_name)[0]}.xml\")\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    img_width = int(root.find('size/width').text)\n",
        "    img_height = int(root.find('size/height').text)\n",
        "    cropped_width = x2 - x1\n",
        "    cropped_height = y2 - y1\n",
        "    class_map = load_class_map(\"/content/drive/MyDrive/Syook/datasets/classes.txt\")\n",
        "    yolo_annotations = []\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text\n",
        "\n",
        "        # Only include PPE classes in the new annotations\n",
        "        if class_name in [\"hard-hat\", \"gloves\", \"mask\", \"glasses\", \"boots\", \"vest\", \"ppe-suit\", \"ear-protector\", \"safety-harness\"]:\n",
        "            bbox = obj.find('bndbox')\n",
        "            xmin = int(bbox.find('xmin').text)\n",
        "            ymin = int(bbox.find('ymin').text)\n",
        "            xmax = int(bbox.find('xmax').text)\n",
        "            ymax = int(bbox.find('ymax').text)\n",
        "\n",
        "            # Check if the PPE is within the person bounding box\n",
        "            if xmin >= x1 and xmax <= x2 and ymin >= y1 and ymax <= y2:\n",
        "                # Adjust coordinates relative to the cropped image\n",
        "                new_xmin = xmin - x1\n",
        "                new_ymin = ymin - y1\n",
        "                new_xmax = xmax - x1\n",
        "                new_ymax = ymax - y1\n",
        "\n",
        "                # Convert to YOLO format\n",
        "                x_center = (new_xmin + new_xmax) / 2 / cropped_width\n",
        "                y_center = (new_ymin + new_ymax) / 2 / cropped_height\n",
        "                width = (new_xmax - new_xmin) / cropped_width\n",
        "                height = (new_ymax - new_ymin) / cropped_height\n",
        "\n",
        "                class_id = class_map[class_name]\n",
        "                yolo_annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
        "\n",
        "    # Save the new annotations\n",
        "    annotation_file_path = os.path.join(output_dir, 'new', f\"{os.path.splitext(cropped_img_name)[0]}.txt\")\n",
        "    with open(annotation_file_path, 'w') as f:\n",
        "        f.write('\\n'.join(yolo_annotations))\n",
        "\n",
        "\n",
        "\n",
        "# class_map = load_class_map(\"/content/drive/MyDrive/Syook/datasets/classes.txt\")\n",
        "if __name__ == \"__main__\":\n",
        "    input_dir = '/content/drive/MyDrive/Syook/datasets/partitioned/val' # images ka path\n",
        "    output_dir = '/content/drive/MyDrive/Syook/datasets/partitioned/val/ppe' # ppe wala path\n",
        "    person_model_path = '/content/drive/MyDrive/Syook/runs/detect/yolov8_person_detection/weights/best.pt' # weights\n",
        "    crop_images_and_update_annotations(input_dir, output_dir, person_model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGORBKf8y_FY",
        "outputId": "bae344c8-a263-4b74-aee2-3bcfd3c0339c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.2.82 🚀 Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/drive/MyDrive/Syook/ppe_detedtion.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolov8_ppe_detection, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8_ppe_detection\n",
            "Overriding model.yaml nc=80 with nc=9\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119531  ultralytics.nn.modules.head.Detect           [9, [128, 256, 512]]          \n",
            "Model summary: 225 layers, 11,139,083 parameters, 11,139,067 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolov8_ppe_detection', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py:268: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1G6XwMABU-R-y_mct2BbnuWg3F_uHx6_-/Syook/datasets/partitioned/train/ppe/labels... 1069 images, 230 backgrounds, 2 corrupt: 100%|██████████| 1071/1071 [00:16<00:00, 64.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/.shortcut-targets-by-id/1G6XwMABU-R-y_mct2BbnuWg3F_uHx6_-/Syook/datasets/partitioned/train/ppe/images/001305_person_10.jpg: ignoring corrupt image/label: image size (20, 7) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/drive/.shortcut-targets-by-id/1G6XwMABU-R-y_mct2BbnuWg3F_uHx6_-/Syook/datasets/partitioned/train/ppe/images/001305_person_7.jpg: ignoring corrupt image/label: image size (20, 5) <10 pixels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1G6XwMABU-R-y_mct2BbnuWg3F_uHx6_-/Syook/datasets/partitioned/train/ppe/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1G6XwMABU-R-y_mct2BbnuWg3F_uHx6_-/Syook/datasets/partitioned/val/ppe/labels... 289 images, 94 backgrounds, 0 corrupt: 100%|██████████| 289/289 [00:04<00:00, 65.35it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1G6XwMABU-R-y_mct2BbnuWg3F_uHx6_-/Syook/datasets/partitioned/val/ppe/labels.cache\n",
            "Plotting labels to runs/detect/yolov8_ppe_detection/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/yolov8_ppe_detection\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      1/100      3.96G      1.492       4.15      1.482         44        640: 100%|██████████| 67/67 [00:31<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:05<00:00,  1.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.367      0.378      0.272      0.167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      2/100      4.07G      1.318      2.012      1.347         47        640: 100%|██████████| 67/67 [00:27<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:05<00:00,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359       0.48      0.305      0.241      0.154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      3/100      4.07G       1.32      1.779      1.334         41        640: 100%|██████████| 67/67 [00:26<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.411      0.347      0.285      0.171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      4/100      4.05G      1.349      1.735      1.378         40        640: 100%|██████████| 67/67 [00:29<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.472      0.274      0.276      0.163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      5/100      4.05G      1.314      1.574      1.344         44        640: 100%|██████████| 67/67 [00:29<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.349      0.353      0.334      0.194\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      6/100      4.07G      1.277      1.564      1.325         27        640: 100%|██████████| 67/67 [00:26<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:05<00:00,  1.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.479      0.358      0.311      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      7/100      4.02G      1.254      1.535      1.304         47        640: 100%|██████████| 67/67 [00:26<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.317       0.41      0.336      0.203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      8/100      3.84G      1.261      1.482      1.303         46        640: 100%|██████████| 67/67 [00:28<00:00,  2.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.643      0.331      0.322      0.199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      9/100      3.88G       1.22      1.412      1.276         41        640: 100%|██████████| 67/67 [00:29<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.454      0.473      0.349      0.217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     10/100      4.06G      1.192      1.369      1.266         44        640: 100%|██████████| 67/67 [00:27<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:05<00:00,  1.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.493      0.362      0.349      0.218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     11/100      4.02G       1.19      1.327      1.266         42        640: 100%|██████████| 67/67 [00:26<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359       0.56      0.487      0.368      0.214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     12/100      3.88G      1.162      1.327      1.251         28        640: 100%|██████████| 67/67 [00:27<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359       0.56      0.384      0.391      0.254\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     13/100      3.88G       1.17      1.286      1.233         65        640: 100%|██████████| 67/67 [00:29<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.518      0.421      0.374      0.241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     14/100      4.03G      1.147       1.25      1.226         43        640: 100%|██████████| 67/67 [00:29<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.686      0.382      0.377      0.223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     15/100      4.02G      1.137      1.208      1.235         33        640: 100%|██████████| 67/67 [00:26<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.544      0.324      0.362      0.229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     16/100      4.04G       1.12      1.199      1.207         44        640: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.479      0.426      0.352      0.221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     17/100      4.03G      1.127      1.164      1.213         30        640: 100%|██████████| 67/67 [00:30<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.556      0.595      0.545      0.349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     18/100      4.06G      1.078      1.086      1.185         44        640: 100%|██████████| 67/67 [00:29<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.539      0.415      0.386      0.243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     19/100      4.02G      1.064      1.088       1.18         37        640: 100%|██████████| 67/67 [00:27<00:00,  2.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:05<00:00,  1.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.527      0.438      0.375      0.242\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     20/100      4.04G      1.068      1.072      1.167         45        640: 100%|██████████| 67/67 [00:25<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.482       0.46      0.381      0.246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     21/100      4.04G      1.029      1.061      1.155         51        640: 100%|██████████| 67/67 [00:28<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  4.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.539      0.453      0.411      0.272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     22/100      4.06G      1.048      1.043      1.156         67        640: 100%|██████████| 67/67 [00:29<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.753      0.376       0.42      0.273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     23/100      4.02G      1.038      1.014      1.152         46        640: 100%|██████████| 67/67 [00:29<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.493      0.507      0.432       0.26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     24/100      4.05G     0.9889     0.9816      1.131         49        640: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.455      0.514      0.425      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     25/100      4.04G      1.004     0.9512      1.134         42        640: 100%|██████████| 67/67 [00:27<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.609      0.392      0.401      0.253\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     26/100      3.88G     0.9688     0.9336      1.108         29        640: 100%|██████████| 67/67 [00:28<00:00,  2.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.532      0.483      0.379      0.249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     27/100      4.02G      0.972       0.92      1.111         37        640: 100%|██████████| 67/67 [00:30<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.528      0.486      0.389      0.241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     28/100      4.02G     0.9824     0.9122      1.115         46        640: 100%|██████████| 67/67 [00:29<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.573      0.447      0.395      0.246\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     29/100      4.03G     0.9847     0.8987       1.11         60        640: 100%|██████████| 67/67 [00:28<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359       0.61      0.408      0.418      0.272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     30/100       3.9G     0.9506      0.868      1.103         42        640: 100%|██████████| 67/67 [00:26<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  3.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359        0.4      0.578      0.514      0.353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     31/100      4.02G     0.9559     0.8425      1.097         44        640: 100%|██████████| 67/67 [00:29<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.533      0.426      0.469      0.296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     32/100      3.89G     0.9501     0.8598      1.095         59        640: 100%|██████████| 67/67 [00:30<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.539      0.403      0.394      0.259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     33/100      4.03G     0.9432     0.8291      1.095         37        640: 100%|██████████| 67/67 [00:28<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.548      0.447      0.483      0.306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     34/100      4.05G     0.9267     0.8263      1.089         52        640: 100%|██████████| 67/67 [00:26<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.606      0.402      0.388      0.255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     35/100      4.02G     0.9233     0.8199      1.082         44        640: 100%|██████████| 67/67 [00:28<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.455      0.625      0.483      0.311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     36/100      3.89G     0.9082     0.7959      1.071         41        640: 100%|██████████| 67/67 [00:30<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.582      0.435      0.431      0.273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     37/100      4.04G     0.8929     0.7618      1.062         39        640: 100%|██████████| 67/67 [00:29<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.378      0.597      0.487       0.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     38/100      4.06G     0.8836     0.7559       1.06         42        640: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:05<00:00,  1.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.376      0.587      0.438      0.295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     39/100      4.02G     0.8843     0.7569      1.056         47        640: 100%|██████████| 67/67 [00:26<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.593      0.338      0.372      0.246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     40/100      4.04G     0.8794     0.7389      1.049         41        640: 100%|██████████| 67/67 [00:29<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.541       0.46      0.411      0.265\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     41/100      4.04G     0.8715     0.7313      1.049         43        640: 100%|██████████| 67/67 [00:30<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.341       0.47       0.39      0.259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     42/100       3.9G     0.8614     0.7065      1.048         60        640: 100%|██████████| 67/67 [00:28<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.543      0.425      0.384      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     43/100      4.02G     0.8326     0.7096      1.031         43        640: 100%|██████████| 67/67 [00:26<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.313      0.516      0.372      0.246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     44/100      3.89G     0.8463     0.7038      1.041         60        640: 100%|██████████| 67/67 [00:28<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.609      0.389      0.412      0.274\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     45/100      4.04G     0.8276     0.6854      1.036         44        640: 100%|██████████| 67/67 [00:30<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.327      0.508      0.401       0.26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     46/100      4.05G     0.8112     0.6726      1.015         43        640: 100%|██████████| 67/67 [00:28<00:00,  2.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.542      0.475      0.395      0.263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     47/100      4.02G     0.8043     0.6522      1.024         40        640: 100%|██████████| 67/67 [00:26<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.558      0.418      0.398      0.261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     48/100      3.89G     0.7831     0.6307       1.01         51        640: 100%|██████████| 67/67 [00:26<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.567      0.446      0.413      0.271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     49/100      3.84G     0.8058     0.6292      1.019         25        640: 100%|██████████| 67/67 [00:29<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.458       0.48      0.459      0.308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     50/100      3.91G     0.7935     0.6525      1.018         53        640: 100%|██████████| 67/67 [00:29<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.467      0.521      0.455      0.309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     51/100      4.16G     0.7904     0.6279      1.009         43        640: 100%|██████████| 67/67 [00:27<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:05<00:00,  1.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.366      0.523      0.396      0.261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     52/100      3.88G     0.7849     0.6198      1.014         56        640: 100%|██████████| 67/67 [00:26<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.552      0.582      0.526      0.362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     53/100      4.02G     0.7679     0.5971          1         52        640: 100%|██████████| 67/67 [00:28<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.478      0.506      0.434      0.281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     54/100      4.01G     0.7438     0.6023     0.9866         32        640: 100%|██████████| 67/67 [00:30<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.592      0.453      0.478      0.328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     55/100         4G     0.7654     0.5961     0.9987         55        640: 100%|██████████| 67/67 [00:28<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.437      0.506      0.424       0.29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     56/100      4.04G     0.7528     0.5768     0.9971         54        640: 100%|██████████| 67/67 [00:26<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.554      0.418      0.396       0.26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     57/100      4.04G     0.7545     0.5816     0.9945         41        640: 100%|██████████| 67/67 [00:28<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.548      0.491      0.476       0.31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     58/100      4.06G      0.745     0.5746     0.9833         58        640: 100%|██████████| 67/67 [00:30<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359       0.53      0.484      0.471      0.295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     59/100      4.02G     0.7406      0.563      0.988         37        640: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:05<00:00,  1.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.468      0.496      0.472      0.299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     60/100      4.05G     0.7225     0.5593     0.9897         40        640: 100%|██████████| 67/67 [00:26<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.716      0.457      0.513       0.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     61/100      4.03G     0.7126     0.5331     0.9706         41        640: 100%|██████████| 67/67 [00:29<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.567      0.444      0.503      0.329\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     62/100      4.06G     0.7077     0.5336     0.9774         53        640: 100%|██████████| 67/67 [00:30<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.395      0.501      0.409      0.266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     63/100      4.16G     0.6892     0.5296     0.9657         32        640: 100%|██████████| 67/67 [00:28<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.502      0.488      0.444      0.291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     64/100      3.89G     0.6924     0.5237     0.9596         48        640: 100%|██████████| 67/67 [00:26<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.546      0.473      0.466      0.321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     65/100      4.03G     0.6895     0.5228     0.9681         33        640: 100%|██████████| 67/67 [00:28<00:00,  2.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.509      0.469      0.442      0.296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     66/100      4.06G     0.6826      0.513     0.9572         48        640: 100%|██████████| 67/67 [00:30<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.572      0.437      0.447      0.298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     67/100      4.02G     0.6837      0.505     0.9653         34        640: 100%|██████████| 67/67 [00:29<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.422      0.557        0.5      0.319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     68/100      3.89G     0.6701     0.4961     0.9542         43        640: 100%|██████████| 67/67 [00:27<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.528      0.471      0.474      0.332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     69/100      3.88G      0.681     0.5019     0.9641         60        640: 100%|██████████| 67/67 [00:27<00:00,  2.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.348      0.524      0.418      0.281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     70/100      4.05G     0.6583     0.4759     0.9498         43        640: 100%|██████████| 67/67 [00:30<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.415      0.557       0.48       0.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     71/100      4.02G     0.6604     0.4772     0.9509         50        640: 100%|██████████| 67/67 [00:29<00:00,  2.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  3.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.459       0.48      0.467      0.327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     72/100      4.04G     0.6485     0.4721     0.9542         40        640: 100%|██████████| 67/67 [00:27<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.512      0.458      0.462      0.316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     73/100      4.04G     0.6465     0.4776     0.9521         45        640: 100%|██████████| 67/67 [00:26<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.495      0.467      0.409      0.269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     74/100      4.06G     0.6363     0.4577     0.9387         37        640: 100%|██████████| 67/67 [00:30<00:00,  2.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.528      0.481      0.457      0.311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     75/100      4.02G     0.6382     0.4625     0.9451         29        640: 100%|██████████| 67/67 [00:29<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.431      0.472      0.416      0.277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     76/100      4.04G     0.6232     0.4581     0.9405         50        640: 100%|██████████| 67/67 [00:26<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:05<00:00,  1.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359       0.49        0.5      0.422      0.281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     77/100      4.03G     0.6218     0.4447     0.9339         55        640: 100%|██████████| 67/67 [00:26<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.512      0.476      0.467      0.322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     78/100      4.06G     0.6133     0.4478     0.9299         45        640: 100%|██████████| 67/67 [00:29<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.455      0.494       0.47      0.315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     79/100      4.02G      0.622     0.4537     0.9344         68        640: 100%|██████████| 67/67 [00:30<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  3.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.548      0.463      0.477      0.318\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     80/100      4.05G     0.5832      0.415     0.9205         57        640: 100%|██████████| 67/67 [00:28<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:05<00:00,  1.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.425      0.465      0.423      0.277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     81/100      4.04G     0.5967     0.4167     0.9246         44        640: 100%|██████████| 67/67 [00:27<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.508      0.461      0.491      0.316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     82/100      4.04G     0.5895     0.4259     0.9238         35        640: 100%|██████████| 67/67 [00:28<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.392      0.543      0.423      0.272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     83/100      4.02G     0.5751      0.413     0.9183         31        640: 100%|██████████| 67/67 [00:29<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.598      0.418      0.485      0.317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     84/100      4.05G     0.5758     0.4035     0.9127         38        640: 100%|██████████| 67/67 [00:29<00:00,  2.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.476      0.452      0.459      0.302\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     85/100      3.99G     0.5848     0.4131     0.9179         41        640: 100%|██████████| 67/67 [00:26<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:05<00:00,  1.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.536      0.466      0.432      0.277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     86/100      4.06G     0.5633     0.4091     0.9183         43        640: 100%|██████████| 67/67 [00:28<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.442      0.458      0.421      0.273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     87/100      3.87G     0.5627     0.4037     0.9114         57        640: 100%|██████████| 67/67 [00:30<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.448      0.504       0.44      0.288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     88/100      4.05G     0.5505     0.3896     0.9076         52        640: 100%|██████████| 67/67 [00:29<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.584      0.436      0.483       0.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     89/100      4.05G     0.5597     0.3983     0.9073         50        640: 100%|██████████| 67/67 [00:26<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.535      0.471      0.486      0.315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     90/100      4.07G     0.5504     0.3925     0.9029         33        640: 100%|██████████| 67/67 [00:26<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.612      0.453      0.484      0.316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     91/100         4G     0.5743     0.3805     0.9149         20        640: 100%|██████████| 67/67 [00:31<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.542      0.455      0.476      0.326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     92/100      4.03G     0.5433     0.3701     0.9191         15        640: 100%|██████████| 67/67 [00:29<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.681       0.46       0.49      0.306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     93/100      4.03G     0.5298     0.3512     0.9038         16        640: 100%|██████████| 67/67 [00:26<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:05<00:00,  1.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.509      0.512      0.492      0.313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     94/100      4.04G      0.537     0.3556     0.9032         28        640: 100%|██████████| 67/67 [00:25<00:00,  2.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.532       0.49      0.482      0.314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     95/100         4G     0.5228     0.3522     0.9069         21        640: 100%|██████████| 67/67 [00:29<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.523        0.5      0.477       0.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     96/100      3.87G     0.5129     0.3386     0.8974         19        640: 100%|██████████| 67/67 [00:28<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:05<00:00,  2.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.508      0.495      0.474      0.312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     97/100      3.87G     0.5047     0.3348     0.9021         19        640: 100%|██████████| 67/67 [00:26<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.579       0.45      0.475      0.314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     98/100      4.03G     0.4944     0.3254     0.8794         23        640: 100%|██████████| 67/67 [00:28<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.609      0.438      0.476      0.324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     99/100         4G     0.5008     0.3285     0.8951         16        640: 100%|██████████| 67/67 [00:28<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.562      0.459      0.481      0.327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "    100/100      4.02G     0.4974     0.3209     0.9011         29        640: 100%|██████████| 67/67 [00:26<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359       0.54      0.463      0.483      0.322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "100 epochs completed in 0.932 hours.\n",
            "Optimizer stripped from runs/detect/yolov8_ppe_detection/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/detect/yolov8_ppe_detection/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/detect/yolov8_ppe_detection/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.82 🚀 Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 11,129,067 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:06<00:00,  1.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        289        359      0.552      0.584      0.526      0.362\n",
            "              hard-hat        136        141      0.619      0.908      0.761      0.606\n",
            "                gloves         39         48      0.404      0.333      0.304      0.172\n",
            "                  mask          2          2      0.592          1      0.828      0.663\n",
            "                 boots         85        119      0.641      0.605      0.681      0.384\n",
            "                  vest         27         29      0.697      0.517      0.483      0.296\n",
            "              ppe-suit         18         20      0.356      0.139     0.0979     0.0531\n",
            "Speed: 0.3ms preprocess, 3.6ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/yolov8_ppe_detection\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0, 1, 2, 4, 5, 6])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fb29c612a70>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.024686,    0.012343,           0],\n",
              "       [          1,           1,           1, ...,    0.000273,   0.0001365,           0],\n",
              "       [          1,           1,           1, ...,     0.66667,     0.66667,           0],\n",
              "       [          1,           1,           1, ...,   0.0030858,   0.0015429,           0],\n",
              "       [    0.76923,     0.76923,     0.76923, ...,  0.00054074,  0.00027037,           0],\n",
              "       [      0.375,       0.375,       0.375, ...,  0.00030181,   0.0001509,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.41379,     0.41379,     0.50684, ...,           0,           0,           0],\n",
              "       [   0.085106,    0.085106,     0.11405, ...,           0,           0,           0],\n",
              "       [   0.047619,    0.047619,    0.066654, ...,           0,           0,           0],\n",
              "       [    0.24629,     0.24629,     0.32364, ...,           0,           0,           0],\n",
              "       [    0.16309,     0.16309,     0.21907, ...,           0,           0,           0],\n",
              "       [    0.10959,     0.10959,     0.10557, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.26236,     0.26236,     0.34197, ...,           1,           1,           1],\n",
              "       [   0.045455,    0.045455,    0.062749, ...,           1,           1,           1],\n",
              "       [    0.02439,     0.02439,    0.034476, ...,           1,           1,           1],\n",
              "       [    0.14248,     0.14248,     0.19734, ...,           1,           1,           1],\n",
              "       [   0.093137,    0.093137,     0.13152, ...,           1,           1,           1],\n",
              "       [   0.060302,    0.060302,    0.060812, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.97872,     0.97872,     0.97872, ...,           0,           0,           0],\n",
              "       [    0.66667,     0.66667,       0.625, ...,           0,           0,           0],\n",
              "       [          1,           1,           1, ...,           0,           0,           0],\n",
              "       [    0.90756,     0.90756,     0.89916, ...,           0,           0,           0],\n",
              "       [    0.65517,     0.65517,     0.65517, ...,           0,           0,           0],\n",
              "       [        0.6,         0.6,         0.4, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: 0.3787543389206224\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.60609,     0.17235,     0.66267,     0.36241,     0.38435,     0.29591,    0.053081,     0.36241,     0.36241])\n",
              "names: {0: 'hard-hat', 1: 'gloves', 2: 'mask', 3: 'glasses', 4: 'boots', 5: 'vest', 6: 'ppe-suit', 7: 'ear-protector', 8: 'safety-harness'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.5515995367357277, 'metrics/recall(B)': 0.5837741364178204, 'metrics/mAP50(B)': 0.5258615624209534, 'metrics/mAP50-95(B)': 0.36240909186503006, 'fitness': 0.3787543389206224}\n",
              "save_dir: PosixPath('runs/detect/yolov8_ppe_detection')\n",
              "speed: {'preprocess': 0.27648140402401195, 'inference': 3.637628984286298, 'loss': 0.0005197360028857591, 'postprocess': 4.39764471615062}\n",
              "task: 'detect'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a YOLOv8 model (YOLOv8s in this case)\n",
        "model = YOLO('yolov8s.pt')\n",
        "\n",
        "# Train the model\n",
        "model.train(\n",
        "    data='/content/drive/MyDrive/Syook/ppe_detedtion.yaml',  # path to the dataset config file\n",
        "    epochs=100,                    # number of training epochs\n",
        "    imgsz=640,                     # image size for training\n",
        "    batch=16,                      # batch size\n",
        "    name='yolov8_ppe_detection' # name of the training session\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0UvU5Uj0VlP",
        "outputId": "3c912c8c-af14-4947-d17a-2769dc766666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 640x256 1 person, 10.6ms\n",
            "Speed: 1.2ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 hard-hat, 11.7ms\n",
            "Speed: 1.2ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 person, 9.2ms\n",
            "Speed: 1.5ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 (no detections), 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001790_person_1.jpg\n",
            "\n",
            "0: 640x288 2 persons, 89.3ms\n",
            "Speed: 4.9ms preprocess, 89.3ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 1 hard-hat, 28.7ms\n",
            "Speed: 1.8ms preprocess, 28.7ms inference, 11.6ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 (no detections), 14.1ms\n",
            "Speed: 2.3ms preprocess, 14.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001953_person_0.jpg\n",
            "\n",
            "0: 640x384 1 person, 52.1ms\n",
            "Speed: 2.5ms preprocess, 52.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x352 1 hard-hat, 50.9ms\n",
            "Speed: 3.2ms preprocess, 50.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x224 1 person, 10.3ms\n",
            "Speed: 1.1ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 hard-hat, 55.8ms\n",
            "Speed: 1.0ms preprocess, 55.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 person, 12.2ms\n",
            "Speed: 2.6ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 1 hard-hat, 1 boots, 13.2ms\n",
            "Speed: 1.4ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 person, 10.2ms\n",
            "Speed: 2.7ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 2 bootss, 9.4ms\n",
            "Speed: 0.9ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x128 1 person, 77.4ms\n",
            "Speed: 1.5ms preprocess, 77.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x128 1 hard-hat, 12.2ms\n",
            "Speed: 1.4ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x288 1 person, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 hard-hat, 1 vest, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x352 1 person, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x352 (no detections), 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 001082_person_1.jpg\n",
            "\n",
            "0: 640x576 1 person, 46.7ms\n",
            "Speed: 3.0ms preprocess, 46.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x480 1 hard-hat, 1 vest, 39.5ms\n",
            "Speed: 3.0ms preprocess, 39.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 1 person, 38.8ms\n",
            "Speed: 3.0ms preprocess, 38.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x416 1 hard-hat, 39.1ms\n",
            "Speed: 2.7ms preprocess, 39.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x256 1 person, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 11.8ms\n",
            "Speed: 1.2ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 person, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 13.2ms\n",
            "Speed: 1.3ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 person, 9.1ms\n",
            "Speed: 1.5ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 9.2ms\n",
            "Speed: 1.6ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x320 1 person, 62.0ms\n",
            "Speed: 2.3ms preprocess, 62.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x288 1 hard-hat, 14.4ms\n",
            "Speed: 1.5ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x640 1 person, 17.6ms\n",
            "Speed: 4.0ms preprocess, 17.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 hard-hat, 17.7ms\n",
            "Speed: 3.0ms preprocess, 17.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x192 2 persons, 17.8ms\n",
            "Speed: 1.3ms preprocess, 17.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 (no detections), 11.9ms\n",
            "Speed: 1.1ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 005250_person_0.jpg\n",
            "\n",
            "0: 640x96 (no detections), 65.9ms\n",
            "Speed: 0.7ms preprocess, 65.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 005250_person_0.jpg\n",
            "\n",
            "0: 640x256 2 persons, 15.0ms\n",
            "Speed: 3.1ms preprocess, 15.0ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 17.3ms\n",
            "Speed: 3.0ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x288 (no detections), 13.7ms\n",
            "Speed: 2.8ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 005250_person_1.jpg\n",
            "\n",
            "0: 640x256 2 persons, 13.3ms\n",
            "Speed: 1.7ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 2 bootss, 14.8ms\n",
            "Speed: 1.4ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x96 (no detections), 13.7ms\n",
            "Speed: 0.9ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 005250_person_2.jpg\n",
            "\n",
            "0: 640x160 1 person, 71.3ms\n",
            "Speed: 1.7ms preprocess, 71.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 hard-hat, 1 boots, 20.1ms\n",
            "Speed: 1.7ms preprocess, 20.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 person, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 2 bootss, 12.5ms\n",
            "Speed: 1.0ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 person, 10.3ms\n",
            "Speed: 1.0ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 hard-hat, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x320 1 person, 27.1ms\n",
            "Speed: 1.7ms preprocess, 27.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 (no detections), 17.2ms\n",
            "Speed: 3.4ms preprocess, 17.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 005250_person_6.jpg\n",
            "\n",
            "0: 640x96 1 person, 28.8ms\n",
            "Speed: 0.9ms preprocess, 28.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 96)\n",
            "\n",
            "0: 640x128 (no detections), 13.3ms\n",
            "Speed: 0.9ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 005250_person_7.jpg\n",
            "\n",
            "0: 640x352 1 person, 15.0ms\n",
            "Speed: 1.8ms preprocess, 15.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x224 1 hard-hat, 1 boots, 12.6ms\n",
            "Speed: 1.5ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x448 1 person, 15.1ms\n",
            "Speed: 1.9ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x448 1 hard-hat, 15.7ms\n",
            "Speed: 2.0ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x608 1 person, 85.2ms\n",
            "Speed: 4.4ms preprocess, 85.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x544 1 hard-hat, 78.5ms\n",
            "Speed: 2.5ms preprocess, 78.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x384 1 person, 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x352 1 hard-hat, 1 vest, 13.8ms\n",
            "Speed: 2.5ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x416 1 person, 14.6ms\n",
            "Speed: 2.0ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x416 2 hard-hats, 13.4ms\n",
            "Speed: 2.0ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x416 1 person, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x416 1 hard-hat, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x448 1 person, 22.9ms\n",
            "Speed: 2.4ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x384 1 hard-hat, 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x576 1 person, 16.7ms\n",
            "Speed: 2.8ms preprocess, 16.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 hard-hat, 16.7ms\n",
            "Speed: 3.3ms preprocess, 16.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x256 1 person, 12.4ms\n",
            "Speed: 1.2ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 1 boots, 14.3ms\n",
            "Speed: 1.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x480 2 persons, 16.7ms\n",
            "Speed: 2.5ms preprocess, 16.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 15.9ms\n",
            "Speed: 2.6ms preprocess, 15.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "No PPE detected in cropped image of 001501_person_0.jpg\n",
            "\n",
            "0: 640x320 (no detections), 16.4ms\n",
            "Speed: 2.1ms preprocess, 16.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 001501_person_0.jpg\n",
            "\n",
            "0: 640x320 1 person, 12.1ms\n",
            "Speed: 1.7ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 (no detections), 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 001501_person_1.jpg\n",
            "\n",
            "0: 640x256 1 person, 11.5ms\n",
            "Speed: 1.6ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 hard-hat, 10.6ms\n",
            "Speed: 1.1ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x448 1 person, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x416 2 hard-hats, 13.4ms\n",
            "Speed: 1.8ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x480 1 person, 15.5ms\n",
            "Speed: 2.0ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 (no detections), 12.7ms\n",
            "Speed: 1.9ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
            "No PPE detected in cropped image of 001858_person_2.jpg\n",
            "\n",
            "0: 640x192 1 person, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 1 gloves, 13.4ms\n",
            "Speed: 1.0ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 person, 8.9ms\n",
            "Speed: 1.5ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 1 hard-hat, 12.4ms\n",
            "Speed: 1.3ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x320 2 persons, 11.3ms\n",
            "Speed: 1.7ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x288 1 hard-hat, 11.1ms\n",
            "Speed: 1.7ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x160 1 hard-hat, 9.5ms\n",
            "Speed: 1.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x224 1 person, 11.7ms\n",
            "Speed: 1.2ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 9.3ms\n",
            "Speed: 1.3ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 person, 11.3ms\n",
            "Speed: 1.2ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 15.4ms\n",
            "Speed: 1.2ms preprocess, 15.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x576 1 person, 18.6ms\n",
            "Speed: 2.9ms preprocess, 18.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 608x640 1 hard-hat, 1 vest, 60.1ms\n",
            "Speed: 4.5ms preprocess, 60.1ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 640x512 2 persons, 67.1ms\n",
            "Speed: 2.6ms preprocess, 67.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x288 (no detections), 12.9ms\n",
            "Speed: 1.9ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001943_person_0.jpg\n",
            "\n",
            "0: 640x416 (no detections), 14.3ms\n",
            "Speed: 2.7ms preprocess, 14.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 416)\n",
            "No PPE detected in cropped image of 001943_person_0.jpg\n",
            "\n",
            "0: 640x320 2 persons, 12.5ms\n",
            "Speed: 2.7ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 1 hard-hat, 12.8ms\n",
            "Speed: 3.1ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x256 (no detections), 17.1ms\n",
            "Speed: 1.4ms preprocess, 17.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001943_person_1.jpg\n",
            "\n",
            "0: 640x416 1 person, 12.8ms\n",
            "Speed: 2.4ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x384 1 hard-hat, 1 vest, 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x416 1 person, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x384 1 hard-hat, 16.2ms\n",
            "Speed: 2.8ms preprocess, 16.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x416 1 person, 15.6ms\n",
            "Speed: 2.0ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x320 2 hard-hats, 18.9ms\n",
            "Speed: 3.1ms preprocess, 18.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x544 1 person, 18.7ms\n",
            "Speed: 2.5ms preprocess, 18.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x480 3 hard-hats, 15.8ms\n",
            "Speed: 2.0ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x352 1 person, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x352 2 hard-hats, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x608 1 person, 19.4ms\n",
            "Speed: 2.6ms preprocess, 19.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x640 (no detections), 17.5ms\n",
            "Speed: 2.7ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "No PPE detected in cropped image of 001751_person_3.jpg\n",
            "\n",
            "0: 640x416 1 person, 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x352 1 hard-hat, 1 gloves, 18.2ms\n",
            "Speed: 1.6ms preprocess, 18.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x96 1 person, 15.8ms\n",
            "Speed: 0.8ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 96)\n",
            "\n",
            "0: 640x96 (no detections), 14.5ms\n",
            "Speed: 0.8ms preprocess, 14.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 001645_person_1.jpg\n",
            "\n",
            "0: 640x512 1 person, 15.9ms\n",
            "Speed: 4.1ms preprocess, 15.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x480 1 hard-hat, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x384 1 person, 12.4ms\n",
            "Speed: 1.7ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x352 1 hard-hat, 1 gloves, 11.6ms\n",
            "Speed: 1.5ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x288 1 person, 12.0ms\n",
            "Speed: 1.3ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 hard-hat, 11.5ms\n",
            "Speed: 2.7ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x192 1 person, 12.2ms\n",
            "Speed: 1.0ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 10.4ms\n",
            "Speed: 1.1ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x384 1 person, 11.5ms\n",
            "Speed: 1.7ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 hard-hat, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 person, 13.2ms\n",
            "Speed: 1.7ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x352 (no detections), 15.9ms\n",
            "Speed: 1.6ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 001898_person_3.jpg\n",
            "\n",
            "0: 480x640 1 person, 80.3ms\n",
            "Speed: 2.5ms preprocess, 80.3ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x640 1 hard-hat, 20.2ms\n",
            "Speed: 2.9ms preprocess, 20.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 17.3ms\n",
            "Speed: 3.0ms preprocess, 17.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x608 2 hard-hats, 20.1ms\n",
            "Speed: 2.6ms preprocess, 20.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x352 1 person, 14.2ms\n",
            "Speed: 1.8ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x352 1 hard-hat, 15.2ms\n",
            "Speed: 4.0ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x384 2 persons, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 hard-hat, 1 gloves, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x256 1 hard-hat, 1 gloves, 14.3ms\n",
            "Speed: 1.5ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x320 1 person, 12.8ms\n",
            "Speed: 1.7ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x288 1 hard-hat, 14.1ms\n",
            "Speed: 1.5ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x448 1 person, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x448 1 hard-hat, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 608x640 4 persons, 17.1ms\n",
            "Speed: 3.1ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 640x448 2 hard-hats, 14.6ms\n",
            "Speed: 2.2ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x128 (no detections), 14.6ms\n",
            "Speed: 0.9ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 005126_person_4.jpg\n",
            "\n",
            "0: 640x416 1 hard-hat, 12.6ms\n",
            "Speed: 2.6ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x544 1 hard-hat, 16.9ms\n",
            "Speed: 3.8ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x256 1 person, 12.0ms\n",
            "Speed: 1.3ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 11.8ms\n",
            "Speed: 1.7ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 person, 12.8ms\n",
            "Speed: 1.2ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 15.1ms\n",
            "Speed: 3.1ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 person, 12.8ms\n",
            "Speed: 1.5ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 11.9ms\n",
            "Speed: 1.5ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 person, 20.3ms\n",
            "Speed: 1.4ms preprocess, 20.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 18.0ms\n",
            "Speed: 1.3ms preprocess, 18.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 2 persons, 19.8ms\n",
            "Speed: 1.1ms preprocess, 19.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 20.3ms\n",
            "Speed: 1.7ms preprocess, 20.3ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x128 (no detections), 18.1ms\n",
            "Speed: 0.8ms preprocess, 18.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 001339_person_4.jpg\n",
            "\n",
            "0: 640x256 1 person, 14.8ms\n",
            "Speed: 1.8ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 15.1ms\n",
            "Speed: 1.8ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 person, 13.1ms\n",
            "Speed: 1.2ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 (no detections), 9.9ms\n",
            "Speed: 1.2ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001339_person_6.jpg\n",
            "\n",
            "0: 480x640 (no detections), 14.7ms\n",
            "Speed: 2.7ms preprocess, 14.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "No persons detected in 001889_person_0.jpg\n",
            "\n",
            "0: 640x448 1 person, 12.8ms\n",
            "Speed: 2.8ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x480 1 hard-hat, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x512 1 person, 13.1ms\n",
            "Speed: 3.4ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x480 1 hard-hat, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x416 1 person, 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x448 1 hard-hat, 12.9ms\n",
            "Speed: 1.8ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x256 1 person, 10.0ms\n",
            "Speed: 1.3ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x384 1 person, 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 hard-hat, 11.7ms\n",
            "Speed: 1.7ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x256 2 persons, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 1 boots, 9.8ms\n",
            "Speed: 1.3ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 hard-hat, 10.0ms\n",
            "Speed: 1.1ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x384 1 person, 11.2ms\n",
            "Speed: 1.3ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x352 1 hard-hat, 1 gloves, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x384 2 persons, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x448 1 hard-hat, 3 glovess, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x288 1 hard-hat, 3 glovess, 10.9ms\n",
            "Speed: 1.6ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 1 person, 9.3ms\n",
            "Speed: 1.3ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 boots, 9.3ms\n",
            "Speed: 1.4ms preprocess, 9.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 person, 9.8ms\n",
            "Speed: 1.3ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 person, 10.1ms\n",
            "Speed: 1.2ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 (no detections), 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001302_person_1.jpg\n",
            "\n",
            "0: 640x320 1 person, 12.9ms\n",
            "Speed: 1.4ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 (no detections), 11.6ms\n",
            "Speed: 2.6ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 001302_person_2.jpg\n",
            "\n",
            "0: 640x416 1 person, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x384 1 hard-hat, 17.2ms\n",
            "Speed: 2.1ms preprocess, 17.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x192 (no detections), 11.4ms\n",
            "Speed: 1.2ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No persons detected in 001302_person_4.jpg\n",
            "\n",
            "0: 640x352 1 person, 11.5ms\n",
            "Speed: 2.4ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x320 1 hard-hat, 11.7ms\n",
            "Speed: 1.5ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x640 1 person, 17.4ms\n",
            "Speed: 2.5ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 hard-hat, 17.3ms\n",
            "Speed: 2.6ms preprocess, 17.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 person, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 1 hard-hat, 11.3ms\n",
            "Speed: 1.7ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x384 1 person, 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x256 1 hard-hat, 9.8ms\n",
            "Speed: 1.3ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x448 1 person, 12.5ms\n",
            "Speed: 2.7ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x384 1 hard-hat, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x224 1 person, 9.1ms\n",
            "Speed: 1.6ms preprocess, 9.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 1 boots, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x480 1 person, 13.0ms\n",
            "Speed: 3.4ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 1 hard-hat, 1 gloves, 1 ppe-suit, 14.6ms\n",
            "Speed: 2.6ms preprocess, 14.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x384 1 person, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x352 1 hard-hat, 1 ppe-suit, 11.4ms\n",
            "Speed: 2.0ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x416 1 person, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x416 1 hard-hat, 1 vest, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 512x640 1 person, 38.0ms\n",
            "Speed: 2.4ms preprocess, 38.0ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 640x640 1 hard-hat, 17.1ms\n",
            "Speed: 3.2ms preprocess, 17.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x544 2 persons, 16.6ms\n",
            "Speed: 3.3ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x608 2 hard-hats, 16.6ms\n",
            "Speed: 3.9ms preprocess, 16.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x640 2 hard-hats, 17.1ms\n",
            "Speed: 2.8ms preprocess, 17.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x320 1 person, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 1 hard-hat, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x480 1 person, 12.0ms\n",
            "Speed: 2.5ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 2 hard-hats, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x576 1 person, 15.2ms\n",
            "Speed: 3.4ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 hard-hat, 15.2ms\n",
            "Speed: 3.6ms preprocess, 15.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x608 1 person, 15.4ms\n",
            "Speed: 3.1ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x224 (no detections), 9.2ms\n",
            "Speed: 1.9ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001807_person_1.jpg\n",
            "\n",
            "0: 640x384 1 person, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x352 (no detections), 14.8ms\n",
            "Speed: 1.7ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 001807_person_2.jpg\n",
            "\n",
            "0: 640x224 1 person, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 1 boots, 11.0ms\n",
            "Speed: 1.5ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x416 1 person, 11.3ms\n",
            "Speed: 2.9ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x416 (no detections), 11.4ms\n",
            "Speed: 1.7ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 416)\n",
            "No PPE detected in cropped image of 001646_person_1.jpg\n",
            "\n",
            "0: 640x544 1 person, 15.3ms\n",
            "Speed: 2.5ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x544 1 hard-hat, 1 ppe-suit, 15.3ms\n",
            "Speed: 2.2ms preprocess, 15.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x256 1 person, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 hard-hat, 1 vest, 10.4ms\n",
            "Speed: 1.1ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 1 person, 10.2ms\n",
            "Speed: 1.4ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 hard-hat, 1 boots, 1 vest, 11.6ms\n",
            "Speed: 0.9ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x544 2 persons, 15.2ms\n",
            "Speed: 2.2ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x416 1 hard-hat, 1 gloves, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x448 1 hard-hat, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x448 1 person, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x416 1 hard-hat, 11.1ms\n",
            "Speed: 2.5ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x288 1 person, 10.0ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 hard-hat, 10.3ms\n",
            "Speed: 1.5ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x320 1 person, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x352 (no detections), 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "No PPE detected in cropped image of 001713_person_3.jpg\n",
            "\n",
            "0: 640x352 1 person, 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x320 1 hard-hat, 10.5ms\n",
            "Speed: 1.5ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 1 person, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x288 1 hard-hat, 10.3ms\n",
            "Speed: 1.5ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 3 persons, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 1 ppe-suit, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x320 1 hard-hat, 1 gloves, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x256 1 hard-hat, 8.7ms\n",
            "Speed: 1.2ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 person, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 hard-hat, 1 ppe-suit, 8.2ms\n",
            "Speed: 2.6ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 384x640 3 persons, 48.4ms\n",
            "Speed: 2.9ms preprocess, 48.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x480 (no detections), 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "No PPE detected in cropped image of 005280_person_0.jpg\n",
            "\n",
            "0: 384x640 1 hard-hat, 16.0ms\n",
            "Speed: 1.9ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x480 (no detections), 14.3ms\n",
            "Speed: 2.3ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "No PPE detected in cropped image of 005280_person_0.jpg\n",
            "\n",
            "0: 640x288 1 person, 10.5ms\n",
            "Speed: 2.8ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 hard-hat, 1 boots, 14.6ms\n",
            "Speed: 1.6ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x416 (no detections), 14.6ms\n",
            "Speed: 2.1ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 416)\n",
            "No persons detected in 005280_person_2.jpg\n",
            "\n",
            "0: 640x416 1 person, 10.3ms\n",
            "Speed: 2.7ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x416 1 hard-hat, 1 gloves, 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x352 1 person, 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x352 1 hard-hat, 13.8ms\n",
            "Speed: 1.7ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x608 2 persons, 15.1ms\n",
            "Speed: 3.6ms preprocess, 15.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 608x640 1 hard-hat, 1 gloves, 14.9ms\n",
            "Speed: 3.3ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 416x640 1 hard-hat, 42.0ms\n",
            "Speed: 2.8ms preprocess, 42.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 640x352 2 persons, 9.9ms\n",
            "Speed: 2.7ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x352 1 hard-hat, 2 bootss, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x96 (no detections), 8.7ms\n",
            "Speed: 0.8ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 005228_person_0.jpg\n",
            "\n",
            "0: 640x288 1 person, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 1 hard-hat, 1 boots, 13.6ms\n",
            "Speed: 1.3ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x288 1 person, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 1 hard-hat, 1 boots, 7.8ms\n",
            "Speed: 1.5ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 person, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 hard-hat, 1 boots, 9.8ms\n",
            "Speed: 1.5ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 person, 8.0ms\n",
            "Speed: 1.4ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 1 boots, 8.0ms\n",
            "Speed: 1.3ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 1 person, 8.3ms\n",
            "Speed: 1.4ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 hard-hat, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 person, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 9.3ms\n",
            "Speed: 1.4ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 person, 7.5ms\n",
            "Speed: 1.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 hard-hat, 8.4ms\n",
            "Speed: 1.2ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 1 person, 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 hard-hat, 10.4ms\n",
            "Speed: 1.1ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 person, 9.6ms\n",
            "Speed: 1.6ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 10.3ms\n",
            "Speed: 1.3ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 person, 10.5ms\n",
            "Speed: 1.7ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 hard-hat, 9.8ms\n",
            "Speed: 1.2ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x640 2 persons, 16.0ms\n",
            "Speed: 3.1ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x608 1 hard-hat, 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x416 1 hard-hat, 12.1ms\n",
            "Speed: 4.8ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x384 1 person, 10.5ms\n",
            "Speed: 2.6ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 hard-hat, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x192 1 person, 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 11.7ms\n",
            "Speed: 1.0ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x288 1 person, 10.2ms\n",
            "Speed: 1.5ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 hard-hat, 14.0ms\n",
            "Speed: 1.4ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x544 1 person, 14.8ms\n",
            "Speed: 3.4ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x512 1 hard-hat, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x192 1 person, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 1 gloves, 12.1ms\n",
            "Speed: 1.1ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x320 1 person, 11.0ms\n",
            "Speed: 2.5ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 (no detections), 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 001921_person_0.jpg\n",
            "\n",
            "0: 640x288 1 person, 11.2ms\n",
            "Speed: 2.5ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 (no detections), 10.4ms\n",
            "Speed: 1.5ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001921_person_1.jpg\n",
            "\n",
            "0: 640x224 1 person, 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 1 gloves, 2 bootss, 8.7ms\n",
            "Speed: 1.1ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 person, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 1 boots, 8.8ms\n",
            "Speed: 1.3ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 person, 8.6ms\n",
            "Speed: 1.2ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 1 boots, 9.9ms\n",
            "Speed: 1.1ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 1 person, 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 hard-hat, 1 boots, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 person, 9.3ms\n",
            "Speed: 1.4ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 1 hard-hat, 1 boots, 10.3ms\n",
            "Speed: 1.2ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x224 1 person, 9.5ms\n",
            "Speed: 1.3ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 (no detections), 10.3ms\n",
            "Speed: 1.0ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 005031_person_5.jpg\n",
            "\n",
            "0: 640x192 1 person, 9.1ms\n",
            "Speed: 1.4ms preprocess, 9.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 2 bootss, 12.8ms\n",
            "Speed: 1.1ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x288 1 person, 11.3ms\n",
            "Speed: 1.6ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 hard-hat, 10.2ms\n",
            "Speed: 1.1ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 person, 10.9ms\n",
            "Speed: 1.7ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 boots, 12.1ms\n",
            "Speed: 1.0ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 1 person, 10.3ms\n",
            "Speed: 1.4ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 (no detections), 17.4ms\n",
            "Speed: 2.8ms preprocess, 17.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001739_person_0.jpg\n",
            "\n",
            "0: 640x160 1 person, 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 boots, 12.9ms\n",
            "Speed: 1.0ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x192 1 person, 13.1ms\n",
            "Speed: 1.1ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 1 boots, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 person, 13.6ms\n",
            "Speed: 1.3ms preprocess, 13.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 boots, 16.4ms\n",
            "Speed: 2.1ms preprocess, 16.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 person, 12.1ms\n",
            "Speed: 1.6ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 2 bootss, 12.0ms\n",
            "Speed: 1.2ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x288 1 person, 11.6ms\n",
            "Speed: 1.6ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 hard-hat, 1 boots, 11.0ms\n",
            "Speed: 1.2ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 person, 14.7ms\n",
            "Speed: 1.9ms preprocess, 14.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 (no detections), 10.0ms\n",
            "Speed: 1.2ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001739_person_6.jpg\n",
            "\n",
            "0: 640x224 2 persons, 10.7ms\n",
            "Speed: 1.4ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 1 boots, 12.4ms\n",
            "Speed: 1.4ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 (no detections), 11.3ms\n",
            "Speed: 0.8ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001739_person_7.jpg\n",
            "\n",
            "0: 640x160 1 person, 11.5ms\n",
            "Speed: 1.0ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 hard-hat, 1 boots, 12.1ms\n",
            "Speed: 0.9ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x192 1 person, 9.2ms\n",
            "Speed: 1.1ms preprocess, 9.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 1 boots, 8.5ms\n",
            "Speed: 1.1ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 person, 8.9ms\n",
            "Speed: 1.4ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 hard-hat, 1 boots, 8.9ms\n",
            "Speed: 0.9ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x256 1 person, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 (no detections), 10.4ms\n",
            "Speed: 1.5ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001739_person_11.jpg\n",
            "\n",
            "0: 576x640 1 person, 39.1ms\n",
            "Speed: 3.4ms preprocess, 39.1ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
            "\n",
            "0: 608x640 (no detections), 16.6ms\n",
            "Speed: 3.3ms preprocess, 16.6ms inference, 0.5ms postprocess per image at shape (1, 3, 608, 640)\n",
            "No PPE detected in cropped image of 005081_person_0.jpg\n",
            "\n",
            "0: 640x224 1 person, 10.1ms\n",
            "Speed: 1.4ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 (no detections), 11.1ms\n",
            "Speed: 1.2ms preprocess, 11.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 005081_person_1.jpg\n",
            "\n",
            "0: 640x608 3 persons, 16.7ms\n",
            "Speed: 3.5ms preprocess, 16.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x576 (no detections), 16.6ms\n",
            "Speed: 2.6ms preprocess, 16.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "No PPE detected in cropped image of 005081_person_2.jpg\n",
            "\n",
            "0: 640x192 (no detections), 15.8ms\n",
            "Speed: 1.1ms preprocess, 15.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 005081_person_2.jpg\n",
            "\n",
            "0: 640x192 (no detections), 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 005081_person_2.jpg\n",
            "\n",
            "0: 640x192 1 person, 15.6ms\n",
            "Speed: 1.3ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 (no detections), 10.1ms\n",
            "Speed: 1.1ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 005081_person_3.jpg\n",
            "\n",
            "0: 640x288 1 person, 11.4ms\n",
            "Speed: 4.7ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 hard-hat, 1 boots, 12.4ms\n",
            "Speed: 1.7ms preprocess, 12.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 person, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 boots, 9.7ms\n",
            "Speed: 1.8ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x224 1 person, 10.9ms\n",
            "Speed: 1.2ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 11.1ms\n",
            "Speed: 1.1ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 person, 9.3ms\n",
            "Speed: 1.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 2 bootss, 9.5ms\n",
            "Speed: 1.5ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 person, 14.8ms\n",
            "Speed: 1.4ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 3 bootss, 12.0ms\n",
            "Speed: 1.2ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 person, 10.6ms\n",
            "Speed: 1.4ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 2 bootss, 10.4ms\n",
            "Speed: 1.6ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 person, 10.2ms\n",
            "Speed: 1.4ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 boots, 11.1ms\n",
            "Speed: 1.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 person, 10.1ms\n",
            "Speed: 1.2ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 boots, 11.4ms\n",
            "Speed: 1.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x352 1 person, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x320 3 bootss, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x224 1 person, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 (no detections), 13.0ms\n",
            "Speed: 1.2ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001837_person_0.jpg\n",
            "\n",
            "0: 640x192 1 person, 15.0ms\n",
            "Speed: 2.2ms preprocess, 15.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 (no detections), 15.5ms\n",
            "Speed: 1.1ms preprocess, 15.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001837_person_1.jpg\n",
            "\n",
            "0: 640x192 1 person, 8.0ms\n",
            "Speed: 2.0ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 (no detections), 9.1ms\n",
            "Speed: 1.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001837_person_2.jpg\n",
            "\n",
            "0: 640x192 2 persons, 8.3ms\n",
            "Speed: 1.9ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 (no detections), 10.2ms\n",
            "Speed: 1.1ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001837_person_3.jpg\n",
            "\n",
            "0: 640x128 (no detections), 8.8ms\n",
            "Speed: 0.8ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 001837_person_3.jpg\n",
            "\n",
            "0: 640x192 1 person, 9.1ms\n",
            "Speed: 1.0ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 (no detections), 9.0ms\n",
            "Speed: 1.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001837_person_4.jpg\n",
            "\n",
            "0: 640x192 1 person, 8.0ms\n",
            "Speed: 2.1ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 (no detections), 9.2ms\n",
            "Speed: 1.0ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001837_person_5.jpg\n",
            "\n",
            "0: 640x192 1 person, 8.7ms\n",
            "Speed: 1.2ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 2 bootss, 10.0ms\n",
            "Speed: 1.2ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 1 person, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 (no detections), 12.8ms\n",
            "Speed: 1.4ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001837_person_7.jpg\n",
            "\n",
            "0: 640x160 1 person, 11.7ms\n",
            "Speed: 1.5ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 boots, 14.1ms\n",
            "Speed: 1.2ms preprocess, 14.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x128 1 person, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x128 (no detections), 10.6ms\n",
            "Speed: 0.9ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 001837_person_9.jpg\n",
            "\n",
            "0: 640x416 1 person, 19.6ms\n",
            "Speed: 3.4ms preprocess, 19.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x384 (no detections), 11.8ms\n",
            "Speed: 2.8ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 001837_person_10.jpg\n",
            "\n",
            "0: 640x160 1 person, 10.0ms\n",
            "Speed: 1.1ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 boots, 13.0ms\n",
            "Speed: 0.9ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x192 1 person, 9.9ms\n",
            "Speed: 1.0ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x128 (no detections), 14.4ms\n",
            "Speed: 0.8ms preprocess, 14.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 001837_person_12.jpg\n",
            "\n",
            "0: 640x192 2 persons, 13.8ms\n",
            "Speed: 1.3ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 (no detections), 9.6ms\n",
            "Speed: 1.7ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001837_person_13.jpg\n",
            "\n",
            "0: 640x224 (no detections), 17.1ms\n",
            "Speed: 2.4ms preprocess, 17.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001837_person_13.jpg\n",
            "\n",
            "0: 640x160 1 person, 9.8ms\n",
            "Speed: 0.9ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 gloves, 1 boots, 9.5ms\n",
            "Speed: 1.3ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x224 1 person, 8.7ms\n",
            "Speed: 2.6ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 2 bootss, 10.1ms\n",
            "Speed: 1.1ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 person, 8.4ms\n",
            "Speed: 1.4ms preprocess, 8.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 2 bootss, 10.5ms\n",
            "Speed: 1.2ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 1 person, 9.8ms\n",
            "Speed: 1.2ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 gloves, 2 bootss, 9.8ms\n",
            "Speed: 1.2ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 person, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 (no detections), 9.1ms\n",
            "Speed: 1.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001788_person_3.jpg\n",
            "\n",
            "0: 640x256 1 person, 9.0ms\n",
            "Speed: 1.6ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 (no detections), 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001788_person_4.jpg\n",
            "\n",
            "0: 640x224 1 person, 15.4ms\n",
            "Speed: 2.1ms preprocess, 15.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 boots, 10.3ms\n",
            "Speed: 1.2ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 person, 7.9ms\n",
            "Speed: 2.5ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 (no detections), 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001788_person_6.jpg\n",
            "\n",
            "0: 640x320 1 person, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 1 gloves, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x288 2 persons, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 (no detections), 9.8ms\n",
            "Speed: 1.5ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001788_person_8.jpg\n",
            "\n",
            "0: 640x192 (no detections), 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 001788_person_8.jpg\n",
            "\n",
            "0: 640x320 2 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 (no detections), 12.2ms\n",
            "Speed: 1.4ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 005113_person_0.jpg\n",
            "\n",
            "0: 640x192 (no detections), 10.7ms\n",
            "Speed: 1.6ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 192)\n",
            "No PPE detected in cropped image of 005113_person_0.jpg\n",
            "\n",
            "0: 640x640 1 person, 17.1ms\n",
            "Speed: 4.6ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x608 1 hard-hat, 1 gloves, 16.6ms\n",
            "Speed: 2.8ms preprocess, 16.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x288 1 person, 12.2ms\n",
            "Speed: 1.7ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 2 glovess, 12.1ms\n",
            "Speed: 1.6ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x352 1 person, 11.6ms\n",
            "Speed: 2.5ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x320 1 gloves, 13.8ms\n",
            "Speed: 2.1ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 2 persons, 11.6ms\n",
            "Speed: 1.5ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 (no detections), 10.8ms\n",
            "Speed: 1.6ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 005113_person_4.jpg\n",
            "\n",
            "0: 640x160 1 gloves, 11.4ms\n",
            "Speed: 0.9ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x640 2 persons, 17.8ms\n",
            "Speed: 3.8ms preprocess, 17.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 576x640 (no detections), 17.1ms\n",
            "Speed: 4.0ms preprocess, 17.1ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n",
            "No PPE detected in cropped image of 005113_person_5.jpg\n",
            "\n",
            "0: 640x256 (no detections), 15.6ms\n",
            "Speed: 1.4ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 005113_person_5.jpg\n",
            "\n",
            "0: 640x160 1 person, 10.6ms\n",
            "Speed: 0.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x128 (no detections), 12.3ms\n",
            "Speed: 0.8ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 128)\n",
            "No PPE detected in cropped image of 005113_person_6.jpg\n",
            "\n",
            "0: 640x288 1 person, 12.0ms\n",
            "Speed: 1.6ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 (no detections), 14.5ms\n",
            "Speed: 1.8ms preprocess, 14.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of 001687_person_0.jpg\n",
            "\n",
            "0: 640x192 1 person, 10.9ms\n",
            "Speed: 1.3ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 1 boots, 10.0ms\n",
            "Speed: 0.9ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x256 1 person, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 2 bootss, 10.7ms\n",
            "Speed: 1.1ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 person, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 2 bootss, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 1 person, 9.6ms\n",
            "Speed: 1.0ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 (no detections), 10.4ms\n",
            "Speed: 1.1ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of 001687_person_4.jpg\n",
            "\n",
            "0: 640x224 1 person, 9.9ms\n",
            "Speed: 1.6ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 (no detections), 10.8ms\n",
            "Speed: 1.1ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of 001687_person_5.jpg\n",
            "\n",
            "0: 640x160 2 persons, 11.0ms\n",
            "Speed: 1.0ms preprocess, 11.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x96 2 bootss, 9.0ms\n",
            "Speed: 0.9ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 96)\n",
            "\n",
            "0: 640x160 2 bootss, 11.4ms\n",
            "Speed: 0.8ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x224 1 person, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 3 bootss, 10.1ms\n",
            "Speed: 1.1ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 person, 9.0ms\n",
            "Speed: 1.4ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 1 boots, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 1 person, 11.3ms\n",
            "Speed: 1.7ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 2 bootss, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 1 person, 10.6ms\n",
            "Speed: 1.6ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 2 hard-hats, 11.9ms\n",
            "Speed: 1.3ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 person, 11.4ms\n",
            "Speed: 1.5ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 12.4ms\n",
            "Speed: 1.5ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 2 persons, 9.5ms\n",
            "Speed: 1.3ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 10.8ms\n",
            "Speed: 1.4ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x96 (no detections), 10.1ms\n",
            "Speed: 1.4ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 005000_person_5.jpg\n",
            "\n",
            "0: 640x128 1 person, 10.7ms\n",
            "Speed: 1.6ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x128 1 hard-hat, 12.1ms\n",
            "Speed: 1.1ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x192 1 person, 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 2 hard-hats, 2 bootss, 9.5ms\n",
            "Speed: 3.4ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 person, 11.5ms\n",
            "Speed: 1.0ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 12.7ms\n",
            "Speed: 1.6ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x128 1 person, 16.5ms\n",
            "Speed: 0.8ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x128 1 hard-hat, 13.7ms\n",
            "Speed: 1.1ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x160 1 person, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 hard-hat, 9.0ms\n",
            "Speed: 0.9ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x416 1 person, 12.4ms\n",
            "Speed: 2.9ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x384 (no detections), 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 001395_person_0.jpg\n",
            "\n",
            "0: 640x384 1 person, 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of 001395_person_1.jpg\n",
            "\n",
            "0: 640x256 1 person, 11.6ms\n",
            "Speed: 1.5ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 (no detections), 12.5ms\n",
            "Speed: 1.6ms preprocess, 12.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of 001363_person_0.jpg\n",
            "\n",
            "0: 640x192 1 person, 9.5ms\n",
            "Speed: 1.3ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 boots, 11.5ms\n",
            "Speed: 1.1ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 1 person, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 boots, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x288 1 person, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x384 1 hard-hat, 11.4ms\n",
            "Speed: 2.3ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x96 (no detections), 8.3ms\n",
            "Speed: 2.7ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No persons detected in 001363_person_4.jpg\n",
            "\n",
            "0: 640x128 2 persons, 8.6ms\n",
            "Speed: 1.0ms preprocess, 8.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x160 1 boots, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x96 (no detections), 9.1ms\n",
            "Speed: 0.9ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 96)\n",
            "No PPE detected in cropped image of 001363_person_5.jpg\n",
            "\n",
            "0: 640x224 1 person, 9.7ms\n",
            "Speed: 1.3ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 10.5ms\n",
            "Speed: 1.2ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 1 person, 11.7ms\n",
            "Speed: 1.1ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x192 1 hard-hat, 12.2ms\n",
            "Speed: 1.2ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x576 1 person, 16.9ms\n",
            "Speed: 2.4ms preprocess, 16.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x576 1 gloves, 1 ppe-suit, 16.8ms\n",
            "Speed: 2.3ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x224 1 person, 12.1ms\n",
            "Speed: 1.3ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 1 hard-hat, 1 boots, 10.4ms\n",
            "Speed: 1.0ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 1 person, 10.3ms\n",
            "Speed: 1.1ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 12.8ms\n",
            "Speed: 1.2ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x160 1 person, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 (no detections), 15.2ms\n",
            "Speed: 1.0ms preprocess, 15.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of -4379-_png_jpg.rf.03c410bbf91f791a4bade1f8673fa79c_person_5.jpg\n",
            "\n",
            "0: 640x192 1 person, 18.0ms\n",
            "Speed: 1.3ms preprocess, 18.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 person, 16.4ms\n",
            "Speed: 1.1ms preprocess, 16.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 20.7ms\n",
            "Speed: 1.2ms preprocess, 20.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 1 person, 19.7ms\n",
            "Speed: 1.5ms preprocess, 19.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 1 boots, 1 vest, 17.3ms\n",
            "Speed: 1.4ms preprocess, 17.3ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 person, 10.8ms\n",
            "Speed: 1.6ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 10.4ms\n",
            "Speed: 1.3ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 person, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 2 hard-hats, 1 vest, 16.4ms\n",
            "Speed: 1.3ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 person, 12.3ms\n",
            "Speed: 1.3ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 2 hard-hats, 14.1ms\n",
            "Speed: 2.6ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 person, 11.1ms\n",
            "Speed: 1.4ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 10.6ms\n",
            "Speed: 1.2ms preprocess, 10.6ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x128 1 person, 12.0ms\n",
            "Speed: 0.9ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x128 1 hard-hat, 1 boots, 10.3ms\n",
            "Speed: 1.0ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x512 1 person, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x544 1 vest, 17.4ms\n",
            "Speed: 2.5ms preprocess, 17.4ms inference, 19.6ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x320 1 person, 25.0ms\n",
            "Speed: 2.1ms preprocess, 25.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x288 1 hard-hat, 1 gloves, 2 bootss, 2 vests, 18.9ms\n",
            "Speed: 3.3ms preprocess, 18.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x352 1 person, 13.1ms\n",
            "Speed: 2.4ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x320 1 hard-hat, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 1 person, 11.8ms\n",
            "Speed: 3.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 1 hard-hat, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x224 1 person, 12.2ms\n",
            "Speed: 1.6ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 13.4ms\n",
            "Speed: 1.4ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x576 1 person, 16.8ms\n",
            "Speed: 3.5ms preprocess, 16.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x544 1 hard-hat, 1 ppe-suit, 17.7ms\n",
            "Speed: 3.9ms preprocess, 17.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x544 1 person, 17.6ms\n",
            "Speed: 4.6ms preprocess, 17.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x544 1 hard-hat, 1 ppe-suit, 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x512 2 persons, 13.1ms\n",
            "Speed: 3.2ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x288 (no detections), 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of -1597-_png_jpg.rf.3bd5df66feaa51e0d65197b4acaf356f_person_0.jpg\n",
            "\n",
            "0: 640x384 (no detections), 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No PPE detected in cropped image of -1597-_png_jpg.rf.3bd5df66feaa51e0d65197b4acaf356f_person_0.jpg\n",
            "\n",
            "0: 640x224 (no detections), 14.4ms\n",
            "Speed: 1.4ms preprocess, 14.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No persons detected in 001302_jpg.rf.6e51fb4e9255ceda9bca16f35d4ae32b_person_0.jpg\n",
            "\n",
            "0: 640x320 1 person, 13.6ms\n",
            "Speed: 1.9ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 (no detections), 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of 001302_jpg.rf.6e51fb4e9255ceda9bca16f35d4ae32b_person_1.jpg\n",
            "\n",
            "0: 640x192 1 person, 14.6ms\n",
            "Speed: 1.1ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 1 hard-hat, 9.8ms\n",
            "Speed: 1.0ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x192 1 person, 8.4ms\n",
            "Speed: 1.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 1 boots, 1 vest, 12.3ms\n",
            "Speed: 1.5ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x416 2 persons, 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 640x384 1 hard-hat, 11.5ms\n",
            "Speed: 2.3ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x256 1 hard-hat, 11.0ms\n",
            "Speed: 1.5ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 person, 14.1ms\n",
            "Speed: 3.3ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 12.9ms\n",
            "Speed: 1.3ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 2 persons, 12.6ms\n",
            "Speed: 1.7ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x192 1 hard-hat, 12.6ms\n",
            "Speed: 1.2ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 1 hard-hat, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x160 (no detections), 23.6ms\n",
            "Speed: 1.0ms preprocess, 23.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No persons detected in -2293-_png_jpg.rf.b1d581d625ae74bb60b5d56e7b562654_person_0.jpg\n",
            "\n",
            "0: 640x576 2 persons, 18.3ms\n",
            "Speed: 2.5ms preprocess, 18.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x608 1 hard-hat, 18.7ms\n",
            "Speed: 3.5ms preprocess, 18.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x544 2 hard-hats, 17.6ms\n",
            "Speed: 1.7ms preprocess, 17.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "0: 640x640 1 person, 17.5ms\n",
            "Speed: 3.6ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 608x640 (no detections), 18.0ms\n",
            "Speed: 2.9ms preprocess, 18.0ms inference, 0.8ms postprocess per image at shape (1, 3, 608, 640)\n",
            "No PPE detected in cropped image of -2293-_png_jpg.rf.b1d581d625ae74bb60b5d56e7b562654_person_2.jpg\n",
            "\n",
            "0: 640x448 1 person, 16.7ms\n",
            "Speed: 2.1ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x448 (no detections), 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
            "No PPE detected in cropped image of -2293-_png_jpg.rf.b1d581d625ae74bb60b5d56e7b562654_person_3.jpg\n",
            "\n",
            "0: 640x224 1 person, 11.5ms\n",
            "Speed: 1.2ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 19.5ms\n",
            "Speed: 1.1ms preprocess, 19.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x288 1 person, 14.6ms\n",
            "Speed: 1.4ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 2 hard-hats, 18.5ms\n",
            "Speed: 1.6ms preprocess, 18.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x256 1 person, 14.3ms\n",
            "Speed: 1.2ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 (no detections), 13.6ms\n",
            "Speed: 4.3ms preprocess, 13.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 256)\n",
            "No PPE detected in cropped image of -1571-_png_jpg.rf.ccf919d5ea025ddc24cf0a707b331249_person_2.jpg\n",
            "\n",
            "0: 640x320 1 person, 16.2ms\n",
            "Speed: 2.3ms preprocess, 16.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x320 (no detections), 21.5ms\n",
            "Speed: 1.5ms preprocess, 21.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 320)\n",
            "No PPE detected in cropped image of -1571-_png_jpg.rf.ccf919d5ea025ddc24cf0a707b331249_person_3.jpg\n",
            "\n",
            "0: 544x640 3 persons, 123.9ms\n",
            "Speed: 3.1ms preprocess, 123.9ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 640x576 (no detections), 19.8ms\n",
            "Speed: 3.8ms preprocess, 19.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 576)\n",
            "No PPE detected in cropped image of -2390-_png_jpg.rf.fa4cf091a0bc051c044e2505719d3971_person_0.jpg\n",
            "\n",
            "0: 608x640 1 hard-hat, 1 ppe-suit, 16.8ms\n",
            "Speed: 4.8ms preprocess, 16.8ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n",
            "\n",
            "0: 640x288 (no detections), 13.7ms\n",
            "Speed: 1.6ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of -2390-_png_jpg.rf.fa4cf091a0bc051c044e2505719d3971_person_0.jpg\n",
            "\n",
            "0: 640x576 2 persons, 19.5ms\n",
            "Speed: 3.1ms preprocess, 19.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x512 2 hard-hats, 2 glovess, 16.8ms\n",
            "Speed: 2.5ms preprocess, 16.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x288 (no detections), 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 288)\n",
            "No PPE detected in cropped image of -2390-_png_jpg.rf.fa4cf091a0bc051c044e2505719d3971_person_1.jpg\n",
            "\n",
            "0: 640x160 1 person, 17.3ms\n",
            "Speed: 1.1ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x160 1 hard-hat, 1 gloves, 16.2ms\n",
            "Speed: 1.0ms preprocess, 16.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x224 1 person, 18.3ms\n",
            "Speed: 1.7ms preprocess, 18.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 2 glovess, 18.0ms\n",
            "Speed: 1.4ms preprocess, 18.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x384 (no detections), 18.7ms\n",
            "Speed: 2.0ms preprocess, 18.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "No persons detected in 001333_jpg.rf.25550b8186ab6e741765efbb21e9e59e_person_1.jpg\n",
            "\n",
            "0: 640x224 1 person, 18.9ms\n",
            "Speed: 1.2ms preprocess, 18.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 1 hard-hat, 11.8ms\n",
            "Speed: 4.6ms preprocess, 11.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x352 1 person, 11.8ms\n",
            "Speed: 4.6ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x320 1 hard-hat, 14.1ms\n",
            "Speed: 4.2ms preprocess, 14.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 640x288 1 person, 12.4ms\n",
            "Speed: 2.6ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 hard-hat, 1 vest, 11.1ms\n",
            "Speed: 1.7ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x608 1 person, 16.8ms\n",
            "Speed: 3.6ms preprocess, 16.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x608 1 hard-hat, 16.8ms\n",
            "Speed: 3.7ms preprocess, 16.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n",
            "\n",
            "0: 640x256 2 persons, 10.4ms\n",
            "Speed: 1.6ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 gloves, 10.6ms\n",
            "Speed: 1.4ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x160 (no detections), 9.6ms\n",
            "Speed: 1.0ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 160)\n",
            "No PPE detected in cropped image of -1477-_png_jpg.rf.bac8d06edca64da17ced23797d0e2339_person_1.jpg\n",
            "\n",
            "0: 640x192 1 person, 10.1ms\n",
            "Speed: 1.3ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x224 (no detections), 12.1ms\n",
            "Speed: 1.4ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 224)\n",
            "No PPE detected in cropped image of -1477-_png_jpg.rf.bac8d06edca64da17ced23797d0e2339_person_2.jpg\n",
            "\n",
            "0: 640x256 1 person, 10.9ms\n",
            "Speed: 4.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x256 1 mask, 2 bootss, 1 vest, 10.9ms\n",
            "Speed: 1.5ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x384 1 person, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 hard-hats, 2 glovess, 2 masks, 2 bootss, 1 vest, 22.0ms\n",
            "Speed: 3.0ms preprocess, 22.0ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x288 1 person, 18.6ms\n",
            "Speed: 1.7ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 1 hard-hat, 2 glovess, 1 mask, 1 vest, 15.6ms\n",
            "Speed: 1.7ms preprocess, 15.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x352 1 person, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x352 1 hard-hat, 2 glovess, 1 boots, 1 vest, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x384 1 person, 11.7ms\n",
            "Speed: 2.3ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 hard-hat, 2 bootss, 1 vest, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x352 1 person, 12.7ms\n",
            "Speed: 2.6ms preprocess, 12.7ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 640x288 1 boots, 1 vest, 18.5ms\n",
            "Speed: 4.2ms preprocess, 18.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 288)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "def inference(input_dir, output_dir, person_model_path, ppe_model_path):\n",
        "    # Load models\n",
        "    person_model = YOLO(person_model_path)\n",
        "    ppe_model = YOLO(ppe_model_path)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for img_name in os.listdir(input_dir):\n",
        "        img_path = os.path.join(input_dir, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Run person detection model\n",
        "        results = person_model(img)\n",
        "\n",
        "        if len(results) == 0 or results[0].boxes.xyxy.shape[0] == 0:\n",
        "            print(f\"No persons detected in {img_name}\")\n",
        "            continue\n",
        "\n",
        "        person_boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)  # Convert tensor to numpy array and ensure it is integer\n",
        "        ppe_boxes = []\n",
        "        ppe_labels = []\n",
        "\n",
        "        for (x1, y1, x2, y2) in person_boxes:\n",
        "            # Crop person from image\n",
        "            cropped_img = img[y1:y2, x1:x2]\n",
        "\n",
        "            # Run PPE detection model\n",
        "            ppe_results = ppe_model(cropped_img)\n",
        "\n",
        "            if len(ppe_results) == 0 or ppe_results[0].boxes.xyxy.shape[0] == 0:\n",
        "                print(f\"No PPE detected in cropped image of {img_name}\")\n",
        "                continue\n",
        "\n",
        "            for ppe_result in ppe_results:\n",
        "                for box in ppe_result.boxes:\n",
        "                    # Convert tensor index to integer\n",
        "                    class_idx = int(box.cls.item())\n",
        "                    ppe_x1, ppe_y1, ppe_x2, ppe_y2 = map(int, box.xyxy[0].cpu().numpy())\n",
        "                    ppe_boxes.append([ppe_x1 + x1, ppe_y1 + y1, ppe_x2 + x1, ppe_y2 + y1])\n",
        "                    ppe_labels.append(ppe_result.names[class_idx])\n",
        "\n",
        "        draw_boxes(img, ppe_boxes, ppe_labels)\n",
        "\n",
        "        # Save the output image with drawn bounding boxes\n",
        "        output_img_path = os.path.join(output_dir, img_name)\n",
        "        cv2.imwrite(output_img_path, img)\n",
        "\n",
        "def draw_boxes(img, boxes, labels):\n",
        "    for (box, label) in zip(boxes, labels):\n",
        "        x1, y1, x2, y2 = box\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # parser = argparse.ArgumentParser(description='Perform inference using YOLO models.')\n",
        "    # parser.add_argument('input_dir', type=str, help='Directory of input images.')\n",
        "    # parser.add_argument('output_dir', type=str, help='Directory to save annotated images.')\n",
        "    # parser.add_argument('person_det_model', type=str, help='Path to person detection model weights.')\n",
        "    # parser.add_argument('ppe_detection_model', type=str, help='Path to PPE detection model weights.')\n",
        "    # args = parser.parse_args()\n",
        "    class args():\n",
        "        pass\n",
        "    args.input_dir, args.output_dir, args.person_det_model, args.ppe_detection_model = \"/content/drive/MyDrive/Syook/datasets/partitioned/val/ppe/images\", \"/content/drive/MyDrive/Syook/datasets/partitioned/val/ppe/results\", \"/content/drive/MyDrive/Syook/runs/detect/yolov8_person_detection/weights/best.pt\", \"/content/drive/MyDrive/Syook/ppe/runs/detect/yolov8_ppe_detection/weights/best.pt\"\n",
        "    inference(args.input_dir, args.output_dir, args.person_det_model, args.ppe_detection_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIrvyai6e9TP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "import albumentations as A\n",
        "from albumentations.augmentations import transforms\n",
        "import numpy as np\n",
        "\n",
        "def load_class_map(classes_file):\n",
        "    class_map = {}\n",
        "    with open(classes_file, 'r') as f:\n",
        "        for idx, class_name in enumerate(f.readlines()):\n",
        "            class_map[class_name.strip()] = idx\n",
        "    return class_map\n",
        "\n",
        "def get_minority_class_images(input_dir, class_map, minority_classes):\n",
        "    \"\"\"\n",
        "    Identify images containing minority classes based on annotations.\n",
        "    \"\"\"\n",
        "    minority_images = []\n",
        "    annotations_dir = os.path.join(input_dir, 'xmls')\n",
        "    for xml_file in os.listdir(annotations_dir):\n",
        "        xml_path = os.path.join(annotations_dir, xml_file)\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        for obj in root.findall('object'):\n",
        "            class_name = obj.find('name').text\n",
        "            if class_name in minority_classes:\n",
        "                image_name = os.path.splitext(xml_file)[0] + '.jpg'\n",
        "                minority_images.append(image_name)\n",
        "                break\n",
        "\n",
        "    return minority_images\n",
        "\n",
        "def augment_image(image, bbox, transforms):\n",
        "    \"\"\"\n",
        "    Apply augmentation to the image and adjust bounding box coordinates accordingly.\n",
        "    \"\"\"\n",
        "    if not bbox:\n",
        "        return image, bbox\n",
        "\n",
        "    augmented = transforms(image=image, bboxes=[bbox], class_labels=[0])\n",
        "\n",
        "    # Ensure bboxes is not empty\n",
        "    if len(augmented['bboxes']) == 0:\n",
        "        return image, bbox\n",
        "\n",
        "    return augmented['image'], augmented['bboxes'][0]\n",
        "\n",
        "def save_augmented_image_and_annotations(aug_image, aug_bbox, output_image_path, output_annotation_path, class_id, class_map):\n",
        "    \"\"\"\n",
        "    Save the augmented image and annotations in XML format.\n",
        "    \"\"\"\n",
        "    # Save augmented image\n",
        "    cv2.imwrite(output_image_path, aug_image)\n",
        "\n",
        "    # Convert bbox to XML format\n",
        "    x_min, y_min, x_max, y_max = aug_bbox\n",
        "    img_h, img_w, _ = aug_image.shape\n",
        "\n",
        "    # Update the XML file\n",
        "    root = ET.Element(\"annotation\")\n",
        "    ET.SubElement(root, \"folder\").text = \"images\"\n",
        "    ET.SubElement(root, \"filename\").text = os.path.basename(output_image_path)\n",
        "    size = ET.SubElement(root, \"size\")\n",
        "    ET.SubElement(size, \"width\").text = str(img_w)\n",
        "    ET.SubElement(size, \"height\").text = str(img_h)\n",
        "    ET.SubElement(size, \"depth\").text = \"3\"\n",
        "\n",
        "    obj = ET.SubElement(root, \"object\")\n",
        "    ET.SubElement(obj, \"name\").text = class_map.get(class_id, 'unknown')\n",
        "    bbox = ET.SubElement(obj, \"bndbox\")\n",
        "    ET.SubElement(bbox, \"xmin\").text = str(int(x_min))\n",
        "    ET.SubElement(bbox, \"ymin\").text = str(int(y_min))\n",
        "    ET.SubElement(bbox, \"xmax\").text = str(int(x_max))\n",
        "    ET.SubElement(bbox, \"ymax\").text = str(int(y_max))\n",
        "\n",
        "    tree = ET.ElementTree(root)\n",
        "    tree.write(output_annotation_path)\n",
        "\n",
        "def draw_boxes_on_image(image, bboxes, class_map, class_id):\n",
        "    \"\"\"\n",
        "    Draw bounding boxes on an image.\n",
        "    \"\"\"\n",
        "    for bbox in bboxes:\n",
        "        x_min, y_min, x_max, y_max = map(int, bbox)\n",
        "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
        "        label = [key for key in class_map if class_map[key] == class_id][0]\n",
        "        cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "def augment_minority_classes(input_dir, output_dir, classes_file, minority_classes, n_augmentations=5):\n",
        "    \"\"\"\n",
        "    Perform data augmentation on images containing minority classes.\n",
        "    \"\"\"\n",
        "    class_map = load_class_map(classes_file)\n",
        "    minority_images = get_minority_class_images(input_dir, class_map, minority_classes)\n",
        "\n",
        "    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'xmls'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'verification'), exist_ok=True)\n",
        "\n",
        "    # Define augmentations\n",
        "    transforms = A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.2),\n",
        "        A.Blur(p=0.1),\n",
        "        A.Rotate(limit=30, p=0.5),\n",
        "        A.ColorJitter(p=0.2)\n",
        "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
        "\n",
        "    for img_name in minority_images:\n",
        "        img_path = os.path.join(input_dir, 'images', img_name)\n",
        "        xml_path = os.path.join(input_dir, 'xmls', f\"{os.path.splitext(img_name)[0]}.xml\")\n",
        "        img = cv2.imread(img_path)\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        for i, obj in enumerate(root.findall('object')):\n",
        "            class_name = obj.find('name').text\n",
        "            if class_name in minority_classes:\n",
        "                bbox = obj.find('bndbox')\n",
        "                x_min = int(bbox.find('xmin').text)\n",
        "                y_min = int(bbox.find('ymin').text)\n",
        "                x_max = int(bbox.find('xmax').text)\n",
        "                y_max = int(bbox.find('ymax').text)\n",
        "\n",
        "                original_bbox = [x_min, y_min, x_max, y_max]\n",
        "                class_id = class_map[class_name]\n",
        "\n",
        "                for j in range(n_augmentations):\n",
        "                    aug_img, aug_bbox = augment_image(img, original_bbox, transforms)\n",
        "\n",
        "                    if not aug_bbox:\n",
        "                        continue\n",
        "\n",
        "                    aug_img_name = f\"{os.path.splitext(img_name)[0]}_{class_name}_aug_{i}_{j}.jpg\"\n",
        "                    aug_label_name = f\"{os.path.splitext(img_name)[0]}_{class_name}_aug_{i}_{j}.xml\"\n",
        "                    aug_img_path = os.path.join(output_dir, 'images', aug_img_name)\n",
        "                    aug_label_path = os.path.join(output_dir, 'xmls', aug_label_name)\n",
        "\n",
        "                    save_augmented_image_and_annotations(aug_img, aug_bbox, aug_img_path, aug_label_path, class_id, class_map)\n",
        "\n",
        "                    # Draw boxes and save to verification folder\n",
        "                    verification_img = draw_boxes_on_image(aug_img.copy(), [aug_bbox], class_map, class_id)\n",
        "                    verification_img_path = os.path.join(output_dir, 'verification', aug_img_name)\n",
        "                    cv2.imwrite(verification_img_path, verification_img)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_dir = '/content/drive/MyDrive/Syook/datasets/partitioned/train'\n",
        "    output_dir = '/content/drive/MyDrive/Syook/datasets/partitioned/augmented'\n",
        "    classes_file = \"/content/drive/MyDrive/Syook/datasets/classes.txt\"\n",
        "    minority_classes = [\"mask\", \"vest\", \"glasses\", \"ear-protector\"]\n",
        "    augment_minority_classes(input_dir, output_dir, classes_file, minority_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItJ_KabMBVPp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Replace 'your_folder_path' with the path to your folder\n",
        "folder_path = '/content/drive/MyDrive/Syook/datasets/xmls'\n",
        "\n",
        "# Get a list of all files in the folder with 'aug_' in their names\n",
        "files_to_remove = glob.glob(os.path.join(folder_path, '*aug_*'))\n",
        "\n",
        "# Remove each file\n",
        "for file_path in files_to_remove:\n",
        "    os.remove(file_path)\n",
        "    print(f'Removed: {file_path}')\n",
        "\n",
        "print('All matching files have been removed.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIZQ2KGkaJpt",
        "outputId": "8725c3ee-c048-49d3-d850-679227bf653e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 631/631 [02:08<00:00,  4.91it/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "import albumentations as A\n",
        "from albumentations.augmentations import transforms\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Augment dataset\n",
        "def load_class_map(classes_file):\n",
        "    class_map = {}\n",
        "    with open(classes_file, 'r') as f:\n",
        "        for idx, class_name in enumerate(f.readlines()):\n",
        "            class_map[class_name.strip()] = idx\n",
        "    return class_map\n",
        "\n",
        "def get_minority_class_images(input_dir, class_map, minority_classes):\n",
        "    \"\"\"\n",
        "    Identify images containing minority classes based on annotations.\n",
        "    \"\"\"\n",
        "    minority_images = []\n",
        "    annotations_dir = os.path.join(input_dir, 'xmls')\n",
        "    for xml_file in os.listdir(annotations_dir):\n",
        "        xml_path = os.path.join(annotations_dir, xml_file)\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        for obj in root.findall('object'):\n",
        "            class_name = obj.find('name').text\n",
        "            if class_name in minority_classes:\n",
        "                image_name = os.path.splitext(xml_file)[0] + '.jpg'\n",
        "                minority_images.append(image_name)\n",
        "                break\n",
        "\n",
        "    return minority_images\n",
        "\n",
        "def augment_image(image, bboxes, class_labels, transforms):\n",
        "    \"\"\"\n",
        "    Apply augmentation to the image and adjust bounding box coordinates accordingly.\n",
        "    \"\"\"\n",
        "    if not bboxes:\n",
        "        return image, bboxes\n",
        "\n",
        "    augmented = transforms(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "\n",
        "    # Ensure bboxes is not empty\n",
        "    if len(augmented['bboxes']) == 0:\n",
        "        return image, bboxes\n",
        "\n",
        "    return augmented['image'], augmented['bboxes']\n",
        "\n",
        "def save_augmented_image_and_annotations(aug_image, aug_bboxes, output_image_path, output_annotation_path, class_labels, class_map):\n",
        "    \"\"\"\n",
        "    Save the augmented image and annotations in XML format.\n",
        "    \"\"\"\n",
        "    # Save augmented image\n",
        "    cv2.imwrite(output_image_path, aug_image)\n",
        "\n",
        "    # Update the XML file\n",
        "    root = ET.Element(\"annotation\")\n",
        "    ET.SubElement(root, \"folder\").text = \"images\"\n",
        "    ET.SubElement(root, \"filename\").text = os.path.basename(output_image_path)\n",
        "    size = ET.SubElement(root, \"size\")\n",
        "    ET.SubElement(size, \"width\").text = str(aug_image.shape[1])\n",
        "    ET.SubElement(size, \"height\").text = str(aug_image.shape[0])\n",
        "    ET.SubElement(size, \"depth\").text = \"3\"\n",
        "\n",
        "    for bbox, class_label in zip(aug_bboxes, class_labels):\n",
        "        x_min, y_min, x_max, y_max = bbox\n",
        "        obj = ET.SubElement(root, \"object\")\n",
        "        ET.SubElement(obj, \"name\").text = [key for key in class_map.keys() if class_map[key] == class_label][0]\n",
        "        bbox_xml = ET.SubElement(obj, \"bndbox\")\n",
        "        ET.SubElement(bbox_xml, \"xmin\").text = str(int(x_min))\n",
        "        ET.SubElement(bbox_xml, \"ymin\").text = str(int(y_min))\n",
        "        ET.SubElement(bbox_xml, \"xmax\").text = str(int(x_max))\n",
        "        ET.SubElement(bbox_xml, \"ymax\").text = str(int(y_max))\n",
        "\n",
        "    tree = ET.ElementTree(root)\n",
        "    tree.write(output_annotation_path)\n",
        "\n",
        "def draw_boxes_on_image(image, bboxes, class_labels, class_map):\n",
        "    \"\"\"\n",
        "    Draw bounding boxes on an image.\n",
        "    \"\"\"\n",
        "    for bbox, class_label in zip(bboxes, class_labels):\n",
        "        x_min, y_min, x_max, y_max = map(int, bbox)\n",
        "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
        "        label = [key for key in class_map.keys() if class_map[key] == class_label][0]\n",
        "        cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "def augment_minority_classes(input_dir, output_dir, classes_file, minority_classes, n_augmentations=5):\n",
        "    \"\"\"\n",
        "    Perform data augmentation on images containing minority classes.\n",
        "    \"\"\"\n",
        "    class_map = load_class_map(classes_file)\n",
        "    minority_images = get_minority_class_images(input_dir, class_map, minority_classes)\n",
        "\n",
        "    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'xmls'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_dir, 'verification'), exist_ok=True)\n",
        "\n",
        "    # Define augmentations\n",
        "    transforms = A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.2),\n",
        "        A.Blur(p=0.1),\n",
        "        A.Rotate(limit=30, p=0.5),\n",
        "        A.ColorJitter(p=0.2)\n",
        "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
        "\n",
        "    for img_name in tqdm(minority_images):\n",
        "        img_path = os.path.join(input_dir, 'images', img_name)\n",
        "        xml_path = os.path.join(input_dir, 'xmls', f\"{os.path.splitext(img_name)[0]}.xml\")\n",
        "        img = cv2.imread(img_path)\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # Gather all bounding boxes and their class labels\n",
        "        bboxes = []\n",
        "        class_labels = []\n",
        "\n",
        "        for obj in root.findall('object'):\n",
        "            class_name = obj.find('name').text\n",
        "            bbox = obj.find('bndbox')\n",
        "            x_min = int(bbox.find('xmin').text)\n",
        "            y_min = int(bbox.find('ymin').text)\n",
        "            x_max = int(bbox.find('xmax').text)\n",
        "            y_max = int(bbox.find('ymax').text)\n",
        "\n",
        "            bboxes.append([x_min, y_min, x_max, y_max])\n",
        "            class_labels.append(class_map[class_name])\n",
        "\n",
        "        for j in range(n_augmentations):\n",
        "            aug_img, aug_bboxes = augment_image(img, bboxes, class_labels, transforms)\n",
        "\n",
        "            if not aug_bboxes:\n",
        "                continue\n",
        "\n",
        "            aug_img_name = f\"{os.path.splitext(img_name)[0]}_aug_{j}.jpg\"\n",
        "            aug_label_name = f\"{os.path.splitext(img_name)[0]}_aug_{j}.xml\"\n",
        "            aug_img_path = os.path.join(output_dir, 'images', aug_img_name)\n",
        "            aug_label_path = os.path.join(output_dir, 'xmls', aug_label_name)\n",
        "\n",
        "            save_augmented_image_and_annotations(aug_img, aug_bboxes, aug_img_path, aug_label_path, class_labels, class_map)\n",
        "\n",
        "            # Draw boxes and save to verification folder\n",
        "            verification_img = draw_boxes_on_image(aug_img.copy(), aug_bboxes, class_labels, class_map)\n",
        "            verification_img_path = os.path.join(output_dir, 'verification', aug_img_name)\n",
        "            cv2.imwrite(verification_img_path, verification_img)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_dir = '/content/drive/MyDrive/Syook/datasets/'\n",
        "    output_dir = '/content/drive/MyDrive/Syook/datasets/'\n",
        "    classes_file = \"/content/drive/MyDrive/Syook/datasets/classes.txt\"\n",
        "    minority_classes = [\"mask\", \"vest\", \"glasses\", \"ear-protector\"]\n",
        "    augment_minority_classes(input_dir, output_dir, classes_file, minority_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "Mo03HNmkB1R6",
        "outputId": "e5d71aeb-39f3-4d59-c08b-cbe6c9b0ac98"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Syook/datasets/labels/001890.txt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-aeca5e61f016>\u001b[0m in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Syook/datasets/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Syook/datasets/partitioned'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0msplit_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-aeca5e61f016>\u001b[0m in \u001b[0;36msplit_dataset\u001b[0;34m(data_dir, output_dir, split_ratio)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mmove_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mmove_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mmove_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmls_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_xmls_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-aeca5e61f016>\u001b[0m in \u001b[0;36mmove_files\u001b[0;34m(files, src_dir, dst_dir, ext)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mdst_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Warning: {src_file_path} does not exist and will be skipped.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopystat\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS_IMODE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     lookup(\"utime\")(dst, ns=(st.st_atime_ns, st.st_mtime_ns),\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Syook/datasets/labels/001890.txt'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "# partition\n",
        "def split_dataset(data_dir, output_dir, split_ratio=0.8):\n",
        "    # Paths for images, labels, and xml files\n",
        "    images_dir = os.path.join(data_dir, 'images')\n",
        "    labels_dir = os.path.join(data_dir, 'labels')\n",
        "    xmls_dir = os.path.join(data_dir, 'xmls')\n",
        "\n",
        "    # Paths for output directories\n",
        "    train_images_dir = os.path.join(output_dir, 'train', 'images')\n",
        "    val_images_dir = os.path.join(output_dir, 'val', 'images')\n",
        "    train_labels_dir = os.path.join(output_dir, 'train', 'labels')\n",
        "    val_labels_dir = os.path.join(output_dir, 'val', 'labels')\n",
        "    train_xmls_dir = os.path.join(output_dir, 'train', 'xmls')\n",
        "    val_xmls_dir = os.path.join(output_dir, 'val', 'xmls')\n",
        "\n",
        "    # Create output directories\n",
        "    os.makedirs(train_images_dir, exist_ok=True)\n",
        "    os.makedirs(val_images_dir, exist_ok=True)\n",
        "    os.makedirs(train_labels_dir, exist_ok=True)\n",
        "    os.makedirs(val_labels_dir, exist_ok=True)\n",
        "    os.makedirs(train_xmls_dir, exist_ok=True)\n",
        "    os.makedirs(val_xmls_dir, exist_ok=True)\n",
        "\n",
        "    # List of all images\n",
        "    image_files = os.listdir(images_dir)\n",
        "    # image_files = [f for f in image_files if f.endswith('.jpg')]  # Filter only jpg files\n",
        "    image_files.sort()\n",
        "\n",
        "    # Shuffle images for randomness\n",
        "    random.shuffle(image_files)\n",
        "\n",
        "    # Split the dataset\n",
        "    split_index = int(len(image_files) * split_ratio)\n",
        "    train_files = image_files[:split_index]\n",
        "    val_files = image_files[split_index:]\n",
        "\n",
        "    # Helper function to move files\n",
        "    def move_files(files, src_dir, dst_dir, ext):\n",
        "        for file_name in files:\n",
        "            if ext != \".jpg\":\n",
        "                file_path = f\"{os.path.splitext(file_name)[0]}{ext}\" # file_name.replace('.jpg', ext)\n",
        "            else:\n",
        "                file_path = file_name\n",
        "            src_file_path = os.path.join(src_dir, file_path)\n",
        "            dst_file_path = os.path.join(dst_dir, file_path)\n",
        "            if os.path.exists(src_file_path):\n",
        "                shutil.copy2(src_file_path, dst_file_path)\n",
        "            else:\n",
        "                print(f\"Warning: {src_file_path} does not exist and will be skipped.\")\n",
        "\n",
        "    # Move images and corresponding labels and xml files\n",
        "    for train_file in train_files:\n",
        "        move_files([train_file], images_dir, train_images_dir, '.jpg')\n",
        "        move_files([train_file], labels_dir, train_labels_dir, '.txt')\n",
        "        move_files([train_file], xmls_dir, train_xmls_dir, '.xml')\n",
        "\n",
        "    for val_file in val_files:\n",
        "        move_files([val_file], images_dir, val_images_dir, '.jpg')\n",
        "        move_files([val_file], labels_dir, val_labels_dir, '.txt')\n",
        "        move_files([val_file], xmls_dir, val_xmls_dir, '.xml')\n",
        "\n",
        "    print(f\"Dataset split completed. {len(train_files)} files for training and {len(val_files)} files for validation.\")\n",
        "\n",
        "    # Verification step\n",
        "    verify_dataset(train_images_dir, train_labels_dir, train_xmls_dir)\n",
        "    verify_dataset(val_images_dir, val_labels_dir, val_xmls_dir)\n",
        "\n",
        "def verify_dataset(images_dir, labels_dir, xmls_dir):\n",
        "    image_files = os.listdir(images_dir)\n",
        "    missing_files = False\n",
        "\n",
        "    for image_file in image_files:\n",
        "        label_file = f\"{os.path.splitext(image_file)[0]}.txt\"\n",
        "        xml_file = f\"{os.path.splitext(image_file)[0]}.xml\"\n",
        "\n",
        "        if not os.path.exists(os.path.join(labels_dir, label_file)):\n",
        "            print(f\"Missing label file for image: {image_file}\")\n",
        "            missing_files = True\n",
        "        if not os.path.exists(os.path.join(xmls_dir, xml_file)):\n",
        "            print(f\"Missing XML file for image: {image_file}\")\n",
        "            missing_files = True\n",
        "\n",
        "    if not missing_files:\n",
        "        print(f\"All files verified for directory {images_dir}.\")\n",
        "    else:\n",
        "        print(f\"Some files are missing in the dataset for directory {images_dir}.\")\n",
        "\n",
        "# Example usage\n",
        "data_dir = '/content/drive/MyDrive/Syook/datasets/'\n",
        "output_dir = '/content/drive/MyDrive/Syook/datasets/partitioned'\n",
        "split_dataset(data_dir, output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmJuXm__40ko"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import argparse\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def load_class_map(classes_file):\n",
        "    class_map = {}\n",
        "    with open(classes_file, 'r') as f:\n",
        "        for idx, class_name in enumerate(f.readlines()):\n",
        "            class_map[class_name.strip()] = idx\n",
        "    return class_map\n",
        "\n",
        "def convert_voc_to_yolo(input_dir, output_dir, classes_file):\n",
        "    class_map = load_class_map(classes_file)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    for xml_file in os.listdir(input_dir):\n",
        "        if xml_file.endswith('.xml'):\n",
        "            tree = ET.parse(os.path.join(input_dir, xml_file))\n",
        "            root = tree.getroot()\n",
        "            image_name = root.find('filename').text\n",
        "            img_width = int(root.find('size/width').text)\n",
        "            img_height = int(root.find('size/height').text)\n",
        "            yolo_annotations = []\n",
        "            for obj in root.findall('object'):\n",
        "                class_name = obj.find('name').text\n",
        "                if class_name not in class_map or class_name != \"person\":\n",
        "                    continue  # Skip classes not in our defined classes list\n",
        "                class_id = class_map[class_name]\n",
        "                bbox = obj.find('bndbox')\n",
        "                xmin = int(bbox.find('xmin').text)\n",
        "                ymin = int(bbox.find('ymin').text)\n",
        "                xmax = int(bbox.find('xmax').text)\n",
        "                ymax = int(bbox.find('ymax').text)\n",
        "                x_center = (xmin + xmax) / 2 / img_width\n",
        "                y_center = (ymin + ymax) / 2 / img_height\n",
        "                width = (xmax - xmin) / img_width\n",
        "                height = (ymax - ymin) / img_height\n",
        "                yolo_annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
        "\n",
        "            with open(os.path.join(output_dir, f\"{os.path.splitext(image_name)[0]}.txt\"), 'w') as f:\n",
        "                f.write('\\n'.join(yolo_annotations))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # parser = argparse.ArgumentParser(description='Convert PascalVOC to YOLO format.')\n",
        "    # parser.add_argument('--input_dir', default=\"datasets\\xmls\", type=str, help='Input directory path containing PascalVOC annotations.')\n",
        "    # parser.add_argument('--output_dir', default=\"datasets\\labels\", type=str, help='Output directory path to save YOLO annotations.')\n",
        "    # parser.add_argument('--classes_file', default=\"datasets\\classes.txt\", type=str, help='Path to the classes.txt file containing class names.')\n",
        "    # args = parser.parse_args()\n",
        "    class args():\n",
        "      pass\n",
        "    args.input_dir, args.output_dir, args.classes_file = '/content/drive/MyDrive/Syook/datasets/xmls', '/content/drive/MyDrive/Syook/datasets/labels', \"/content/drive/MyDrive/Syook/datasets/classes.txt\"\n",
        "    convert_voc_to_yolo(args.input_dir, args.output_dir, args.classes_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
